{
  "$schema": "https://vega.github.io/schema/vega/v5.json",
  "autosize": "pad",
  "padding": 5,
  "data": [
    {"name": "paintbrush_store"},
    {
      "name": "source_0",
      "values": [
        {
          "start_datetime": "2019-07-24T11:50:00",
          "end_datetime": "2019-07-24T12:00:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Towards Faster Sorting and Group-by operations",
          "text": "Julia is increasingly being recognized as one of the big three data science programming languages alongside R and Python. However, Julia’s data ecosystem has had less time to mature when compared to R’s or Python’s. Hence it’s not surprising that some data operations in Julia are slower than their counterparts in R and Python, e.g. group-by. \nThis talk discusses how under-utilized fast sorting methods, such as radix sort, can be used to speed up group-by operations in Julia so that Julia’s group-by operations can match (or even surpass) the speed of optimized C-based group-by implementations in R and Python. ",
          "url": "https://pretalx.com/juliacon2019/talk/AGNHPU/",
          "index": 1,
          "speaker": "Dai ZJ"
        },
        {
          "start_datetime": "2019-07-25T15:00:00",
          "end_datetime": "2019-07-25T15:30:00",
          "duration": 30,
          "location": "Room 349",
          "title": "How We Wrote a Textbook using Julia",
          "text": "The speaker's experience writing a full-length optimization textbook with Julia-generated figures and typeset julia code, how to all works. My coauthor (Prof. Mykel Kochenderfer) and I wrote a full-length, fully-featured, academic textbook. It is full of beautiful Julia-generated figures and typeset Julia code snippets. Everything is source controlled .tex files, and everything else is generated on compile. This talk covers how we did it and why you might want to do it too. ",
          "url": "https://pretalx.com/juliacon2019/talk/WFVWES/",
          "index": 2,
          "speaker": "Tim Wheeler"
        },
        {
          "start_datetime": "2019-07-23T11:00:00",
          "end_datetime": "2019-07-23T11:30:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Intelligent Tensors in Julia",
          "text": "We present ITensors.jl, a ground-up rewrite of the C++ ITensor package for tensor network simulations in Julia. We will motivate the use of tensor networks in physics and give some examples for how ITensors.jl can help make the use and development of tensor network algorithms easier for researchers, users, and developers. Tensor network methods are an extremely useful class of simulation algorithms in physics. They work by constructing a graph of tensors -- of which matrices and vectors are low-dimensional examples -- and making local optimizations to these tensors to capture the essential physics of a many-body system. ITensor (Intelligent Tensor) is a leading C++ package created to make tensor network methods accessible to a wider group of scientists and programmers. In this talk, we present ITensors.jl, a ground-up rewrite of ITensor in Julia, which uses the lessons from the C++ project to offer much of the same powerful functionality in a more concise and elegant format, substantially lowering the \"barrier to entry\" for using tensor network techniques. We will present some usage examples that are common in physics applications to exemplify the ITensors.jl user interface and design philosophy. Using Julia, we can create a tensor network package expressive enough to capture a variety of physics that's also accessible enough for more physicists and computer scientists to use. ",
          "url": "https://pretalx.com/juliacon2019/talk/BNSCFK/",
          "index": 3,
          "speaker": "Katharine Hyatt, Matthew Fishman"
        },
        {
          "start_datetime": "2019-07-23T11:30:00",
          "end_datetime": "2019-07-23T11:40:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Counting On Floating Point",
          "text": "DoubleFloats.jl offers performant types, Double64 and Double32, with twice the precision of Float64 and Float32. Attendees will gain a working knowledge of how to apply the package in support of more reliably accurate results. Relax into more reliable floating point.  Get more good digits, keep the ones that count. \nRobustly accurate,   DoubleFloats  offers a way to develop resilient numerics reliably. ",
          "url": "https://pretalx.com/juliacon2019/talk/VN7TVD/",
          "index": 4,
          "speaker": "Jeffrey Sarnoff"
        },
        {
          "start_datetime": "2019-07-23T11:50:00",
          "end_datetime": "2019-07-23T12:00:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Smart House with JuliaBerry",
          "text": "Hardware and software scale model of a smart house that utilises the functions of a Raspberry Pi. It has several functions that could be transferred to a full-scale model using the same hardware. This project is a miniaturised smart house that uses a Raspberry Pi and Julia to automatically run a small model home. This smart house uses a Raspberry Pi with a Sense HAT and Explorer HAT Pro to create several functions that could be used on a real house. This includes a motion sensor that opens a door; a photoresistor that turns lights on and off and a Sense HAT taking readings and scrolling through them on an LED matrix. All these are functions which are used on houses and have been scaled down using the Raspberry Pi and the Julia Language. ",
          "url": "https://pretalx.com/juliacon2019/talk/G9Z3AG/",
          "index": 5,
          "speaker": "Ahan Sengupta"
        },
        {
          "start_datetime": "2019-07-23T11:30:00",
          "end_datetime": "2019-07-23T11:40:00",
          "duration": 10,
          "location": "Elm A",
          "title": "A general-purpose toolbox for efficient Kronecker-based learning",
          "text": "Pairwise learning is a machine learning paradigm where the goal is to predict properties of pairs of objects. Applications include recommender systems, such as used by Amazon, molecular network inference and ecological interaction prediction. Kronecker-based learning systems provide a simple, yet elegant method to learn from such pairs. Using tricks from linear algebra, these models can be trained, tuned and validated on large datasets. The Julia package Kronecker.jl aggregates these tricks, such that it is easy to build such learning systems. I would like to introduce the Kronecker kernel-based framework I developed during my PhD and explain why I would switch from Python to Julia for this. ",
          "url": "https://pretalx.com/juliacon2019/talk/QAAUCS/",
          "index": 6,
          "speaker": "Michiel Stock"
        },
        {
          "start_datetime": "2019-07-25T17:15:00",
          "end_datetime": "2019-07-25T17:25:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Gen: a general-purpose probabilistic programming system with programmable inference built on Julia",
          "text": "This talk introduces a new flexible and extensible probabilistic programming system called Gen, that is built on top of Julia. Gen's extensible set of modeling DSLs can express probabilistic models that combine Bayesian networks, black box simulators, deep learning, structure learning, and Bayesian nonparametrics; and Gen's inference library supports custom algorithms that combine Markov chain Monte Carlo, particle filtering, variational inference, and numerical optimization. Probabilistic modeling and inference are central to many fields. Probabilistic programming systems aim to make probabilistic modeling and inference techniques accessible to a broader audience, and to make it easier for experts in these techniques to develop more complex applications. A key challenge for wider adoption of probabilistic programming languages is designing systems that are both flexible and performant. This talk introduces Gen, a new probabilistic programming system, built on top of Julia, that includes novel language constructs for modeling and for end-user customization and optimization of inference. Gen makes it practical to write probabilistic programs that solve problems from multiple fields. Gen programs can combine generative models written in Julia, neural networks written in TensorFlow, and custom inference algorithms based on an extensible library of Monte Carlo and numerical optimization techniques. The talk will also present techniques that enable Gen’s combination of flexibility and performance: (i) the generative function interface, an abstraction for encapsulating probabilistic and/or differentiable computations; (ii) domain-specific languages with custom compilers that strike different flexibility/performance tradeoffs; (iii) combinators that encode common patterns of conditional independence and repeated computation, enabling speedups from caching; and (iv) a standard inference library that supports custom proposal distributions also written as programs in Gen. This talk shows that Gen outperforms state-of-the-art probabilistic programming systems, sometimes by multiple orders of magnitude, on problems such as nonlinear state-space modeling, structure learning for real-world time series data, robust regression, and 3D body pose estimation from depth images. ",
          "url": "https://pretalx.com/juliacon2019/talk/GVYCEL/",
          "index": 7,
          "speaker": "Marco Cusumano-Towner"
        },
        {
          "start_datetime": "2019-07-23T15:10:00",
          "end_datetime": "2019-07-23T15:20:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Formatting Julia",
          "text": "Ever wish your code automatically beautiful? Tired of spacing out commas, wrangling parenthesis and indenting? Julia's formatter can do all this and more! Come find out how to use it your everyday workflow. Formatting code has recently gained significant trackion amongst the programming community. The most notable \nformatters being  gofmt  (Go),  remft  (Reason/Ocaml), and  prettier  (JS/CSS/HTML,etc). In this talk I'll present \nJulia's own formatter, which formats Julia code into a canonical, width-aware output. I'll go over: Why you should format your code. How the Julia formatter works and how you can use it in your workflow. Lots of demos showing beautifully formatted code! ",
          "url": "https://pretalx.com/juliacon2019/talk/RUYDYR/",
          "index": 8,
          "speaker": "Dominique Luna"
        },
        {
          "start_datetime": "2019-07-23T17:05:00",
          "end_datetime": "2019-07-23T17:35:00",
          "duration": 30,
          "location": "Elm A",
          "title": "A Showcase for Makie",
          "text": "Makie is a new plotting library written a 100% in Julia. \nIt offers a GPU accelerated drawing backend that can draw huge amounts of data at interactive speeds. \nOther backends for SVG, PDF and the Web are available as well, so Makie can be used in a many different scenarios. \nThis talk will give an overview of how Makie works and will present the most outstanding plotting examples from the areas of Interactivity, Data Science, Geology and Simulations. ",
          "url": "https://pretalx.com/juliacon2019/talk/ZCWD9M/",
          "index": 9,
          "speaker": "Simon Danisch"
        },
        {
          "start_datetime": "2019-07-25T17:25:00",
          "end_datetime": "2019-07-25T17:35:00",
          "duration": 10,
          "location": "Elm B",
          "title": "PackageCompiler",
          "text": "With PackageCompiler, one can ahead of time compile binaries for Julia packages. This includes the ability to create an executable for a  Julia script. \nIn this talk, I will give a short overview of how PackageCompiler works and how it can be used to ship your Julia package or eliminate JIT overhead. ",
          "url": "https://pretalx.com/juliacon2019/talk/RMNXL7/",
          "index": 10,
          "speaker": "Simon Danisch"
        },
        {
          "start_datetime": "2019-07-24T11:00:00",
          "end_datetime": "2019-07-24T11:30:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Yao.jl: Extensible, Efficient Quantum Algorithm Design for Humans.",
          "text": "Quantum computation is the future of computing. However, writing quantum program can be hard for developers living in a classical world. We developed Yao.jl to help scientists test and explore their quantum ideas in a simple way. Introduction Yao is an open source framework for quantum algorithm design; quantum  software 2.0 ; quantum computation education. Motivation Comparing with state of art quantum simulators, our library is inspired by quantum circuit optimization. \nVariational quantum optimization algorithms like quantum circuit Born machine ( QCBM ), quantum approximate optimization algorithm ( QAOA ), variational quantum eigensolver ( VQE ) and quantum circuit learning ( QCL ) et. al. are promising killer apps on a near term quantum computers. \nThese algorithms require the flexibility to tune parameters and have well defined patterns such as \"Arbitrary Rotation Block\" and \"CNOT Entangler\". In Yao, we call these patterns \"blocks\". If we regard every gate or gate pattern as a \"block\", then the framework can be flexible to dispatch parameters, cache matrices of blocks to speed up future runs, allow hierarchical design of quantum algorithms Thanks to Julia's duck type and multiple dispatch features, user can easily  extend  the block system by overloading specific interfaces quantum circuit blocks can be dispatched to some  special method  to improve the performance in specific case (e.g. customized repeat block of H gate). Features Yao is a framework that is about to have the following features: Extensibility define new operations with a minimum number of methods in principle. extend with new operations on different hardware should be easy, (e.g GPUs, near term quantum devices, FPGAs, etc.) Efficiency comparing with python, julia have no significant overhead on small scale circuit. special optimized methods are dispatched to frequently used blocks. double interfaces \"apply!\" and \"cache server + mat\" allow us to choose freely when to sacrifice memory for faster simulation and when to sacrifice the speed to simulate more qubits. Easy to Use As a white-box simulator, rather than using a black box, users will be aware of what their simulation are doing right through the interface. Hierarchical APIs  from  low abstraction quantum operators  to  highly abstract  circuit block objects. The whole framework is highly  modularized , researchers can extend this framework for different purposes. Author This project is an effort of QuantumBFS, an open source organization for quantum science. All the contributors are listed in the  contributors . ",
          "url": "https://pretalx.com/juliacon2019/talk/8AM9JC/",
          "index": 11,
          "speaker": "Roger Luo"
        },
        {
          "start_datetime": "2019-07-25T11:50:00",
          "end_datetime": "2019-07-25T12:00:00",
          "duration": 10,
          "location": "Room 349",
          "title": "JuliaCN: A community driven localization group for Julia in China",
          "text": "JuliaCN was founded by early Chinese Julia developers for Julia localization in Chinese. We started it by providing Chinese translation on Julia documentation known as  JuliaZH.jl / julia_zh_cn . Introduction JuliaCN  was founded when Julia was still newly born. Its early member includes several developers in the community, e.g Jiahao Chen, Yichao Yu.  We provided the first translation on Julia's documentation in v0.3, known as  julia_zh_cn . Later, we provided  the Chinese discourse  to let non-English speakers communicate freely and get support when they are in trouble.  Activities Annual Julia User Meetup in China: This is more like a small workshop held each year. Holding and providing resource for Julia User Meetups Community driven translation project: we built a transifex based translation project  JuliaZH.jl Project Emerged in JuliaCN Community Jetbrain IDE for Julia Py2JI.jl ",
          "url": "https://pretalx.com/juliacon2019/talk/D7NVW8/",
          "index": 12,
          "speaker": "Roger Luo"
        },
        {
          "start_datetime": "2019-07-24T14:30:00",
          "end_datetime": "2019-07-24T15:00:00",
          "duration": 30,
          "location": "Elm A",
          "title": "SemanticModels.jl: not just another modeling framework",
          "text": "SemanticModels.jl is a library for analyzing scientific and mathematical models written in julia. We apply techniques from program analysis to understand and manipulate scientific modeling code. This allows you to write programs that write novel models. SemanticModels is a system for extracting semantic information from scientific code and reconciling it with conceptual descriptions to automate machine understanding of scientific ideas. We represent the connections between elements of code (variables, values, functions, and expressions) and elements of scientific understanding (concepts, terms, relations), to facilitate several metamodeling tasks, including model augmentation, synthesis, and validation. We show how SemanticModels can be used to augment scientific workflows in the epidemiological domain.  SemanticModels builds on such great Julia packages as Cassette, Flux, DifferentialEquations, and LightGraphs. It conducts static and dynamic analysis of programs to increase the productivity of scientist-developers. SemanticModels is a complimentary technology to the modeling languages like ModelingToolkit.jl and other DSLs used within the DiffEq ecosystem. ",
          "url": "https://pretalx.com/juliacon2019/talk/QFEHQS/",
          "index": 13,
          "speaker": "Christine R Herlihy, James Fairbanks"
        },
        {
          "start_datetime": "2019-07-24T11:50:00",
          "end_datetime": "2019-07-24T12:00:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Julia for Battery Model Parameter Estimation",
          "text": "High-fidelity battery modeling requires the estimation of numerous physical parameters in order to properly capture the physics of the electrochemical, thermodynamic and chemical processes that underlie the system. Using Julia, the parameters for this model were able to be estimated by speeding up the code such that a Markov Chain Monte Carlo approach (Hamiltonian Monte Carlo) could be used, combined with a high-performance computing cluster, to sample the vast search domain and reach the global error minima. The particular battery model employed in this application predicts the voltage, temperature, state-of-charge, and degradation (i.e. lithium lost due to aging factors). Due to the complex interactions among these properties --- along with other dynamic, codependent cell properties --- the behavior of the cell over the course of an arbitrary load cannot be accurately characterized from an initial state without simulating these interactions over time.  As a result, the model implementation discretely progresses the cell through discharge and charge using a time-step of 2 seconds, predicting forward the state properties. The only time-dependent input is a load profile, which can come in the form of the power over time or current over time associated with the discharge due to the load and charging protocol. Beyond that, user inputs are only required for the initial cell state.   Looking at an individual step, the mole fraction of lithium in different parts of the cell is found using either the initial conditions or the prediction from a prior step. Calculating the open circuit potential for both the anode and cathode depends on these mole fractions and the current cell temperature. Following this step the mole fractions for the next state are calculated by approximating their rate of change, which relies on the input current, and multiplying the rate by the 2-second time-step. The state-of-charge for the next step is also calculated at this point.  The cell voltage depends on a set of overpotentials on top of the open circuit potential already estimated. As with the mole fractions, these come from initial conditions or a previous step. To predict the overpotentials for the next state, properties from the current state are used to calculate the current rate of change, which is then multiplied by the time-step. Temperature is predicted for the next state in a similar manner, as is the cell voltage.  The computational challenge derives in part from the vast parameter space necessary to characterize the model to a real cell based on testing data. The model depends on roughly 20 parameters for a single discharge-charge cycle to predict the state over time. On top of this, keeping track of cell degradation requires an additional 5 parameters.  Working from the state-of-charge model described above, a state-of-health model can be set up using these additional parameters and running the discharge model for hundreds of cycles, updating the input parameters at the beginning of each cycle. At each state during an individual cycle, the amount of lithium lost either to reactions with the electrolyte or isolation into inactive lithium metal is added to a running total for the cycle. After a cycle completes, this total is removed from the initial lithium available to the cell. Resistance and diffusivity also change over multiple cycles, and the contribution to their decay is also maintained as a running total within each cycle. Since local minima are pervasive in this parameter space, and error-minimizing strategies are too strongly influenced by initial guesses, a Monte Carlo implementation is necessary to properly train the model. This becomes prohibitively expensive computationally within Matlab, where the model was first implemented, because each cycle lasts for up to 10,000 seconds, and up to 2,000 cycles can be required to compare the aging model to the available aging data.  The search space defined by the parameters requires that the Monte Carlo be able to perform several thousand iterations. Under the Matlab implementation, each Monte Carlo iteration would take approximately 0.03 seconds. This means that the algorithm can do 1 million iterations in 500 minutes or about 8 hours. While this seems sufficient, there are 20 parameters which means that on average, there are only 50,000 changes to each variable which is likely not enough iterations per variable to properly sample the space. In addition, more complex Monte Carlo models such as the Hamilton Monte Carlo take significantly more time to run, thus limiting the number of iterations that can be run. By implementing the same code in Julia, the algorithm got a significant speed up in addition to other benefits. Compared to the Matlab implementation, the Julia implementation had one Monte Carlo iteration complete in about 0.003 seconds. This means that there was a 10X speed up, allowing for 10X more iterations to be completed in the same time. Thus, in about 8 hours, 10 million Monte Carlo iterations could be performed. In addition, Julia enabled the code to be run in parallel on Arjuna, a high-performance computing cluster at Carnegie Mellon University. This means that in 8 hours, several of these algorithms can be run in parallel in which each performs a phase space search using 10 million iterations. Since each algorithm has enough iterations to properly sample the space, the minimum error found from the collection of Monte Carlo simulations can be assumed to be the global minimum of the search space. The large amount of Monte Carlo iterations also allows for the algorithm to use a simulated annealing function to allow the algorithm to not get stuck in local minima. ",
          "url": "https://pretalx.com/juliacon2019/talk/JYLQ8H/",
          "index": 14,
          "speaker": "William L Fredericks, Venkat Viswanathan, Shashank Sripad, Matthew Guttenberg"
        },
        {
          "start_datetime": "2019-07-23T14:30:00",
          "end_datetime": "2019-07-23T15:00:00",
          "duration": 30,
          "location": "Elm B",
          "title": "A New Breed of Vehicle Simulation",
          "text": "When you design an aircraft or spacecraft, it generally has to work the first time or the consequences are fiery destruction. You simulate a lot. Julia enables not merely a flexible and fast way to write a custom simulation, but in fact an entirely new and powerful breed of simulation architecture. We’ll see how Julia’s combination of mathy notation, built-in numerical tools, compilation, and metaprogramming opens up new possibilities for creating a simulation environment fit for aircraft, spacecraft, autonomous underwater vehicles, and the like. We’ll examine the special requirements for these types of applications, why elegant solutions have historically been out of reach, and how that picture is beginning to change. Finally, we’ll see how one such simulation environment in Julia has become the backbone of flight algorithm development and testing for a large fleet of autonomous aircraft that deliver life-saving medical supplies in Rwanda and Ghana. ",
          "url": "https://pretalx.com/juliacon2019/talk/9D933F/",
          "index": 15,
          "speaker": "Tucker McClure"
        },
        {
          "start_datetime": "2019-07-23T16:55:00",
          "end_datetime": "2019-07-23T17:05:00",
          "duration": 10,
          "location": "Room 349",
          "title": "SIMD and cache-aware sorting with ChipSort.jl",
          "text": "ChipSort.jl is a sorting package that exploits instruction-level parallelism and cache memory seeking the best performance in any system. To attain the best performance with a modern computer, programmers are required to exploit thread and instruction level parallelism and make sure memory access follows suitable patterns. ChipSort.jl is a sorting package that implements techniques exploiting parallelism and memory locality. It uses SIMD instructions to implement  basic operations such as sorting networks, merging networks, and in-place matrix transpose. These operations can be used to sort large arrays using merge-sort exploiting SIMD and cache memory for improved performance. The implementation is largely based on unique Julia features such as generated functions and parametric methods, allowing Julia to generate optimized custom machine code for different architectures based on the same high-level Julia code. Experiments were made with both Intel (AVX2 and AVX512) and AMD (NEON) processors, achieving speedups from 2 up to 17 times in different benchmarks. Project documentation:  https://nlw0.github.io/ChipSort.jl ",
          "url": "https://pretalx.com/juliacon2019/talk/YDVQKM/",
          "index": 16,
          "speaker": "Nicolau Leal Werneck"
        },
        {
          "start_datetime": "2019-07-25T16:45:00",
          "end_datetime": "2019-07-25T16:55:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Static walks through dynamic programs -- a conversation with type-inference.",
          "text": "Efficient performance engineering for Julia programs heavily relies on understanding the result of type-inference on your program, this talk will introduce a tool to have a conversation with type-inference. Efficient performance engineering for Julia programs heavily relies on understanding the result of type-inference on your program, type-inference as process is sensitive to local information or call-context. Many Julia users use the information provided by  @code_typed  to analyse the behaviour of type-inference on  a  function. This method becomes cumbersome and inefficient with deeply nested programs where the user needs to reconstruct local information to inspect called methods. This talk introduces a tool that streamlines this process and allows users to take a static walk through their dynamic program. It simplifies the performance engineering process and is capable of handling code that uses tasks, threads and GPUs. ",
          "url": "https://pretalx.com/juliacon2019/talk/WJZJXS/",
          "index": 17,
          "speaker": "Valentin Churavy"
        },
        {
          "start_datetime": "2019-07-25T16:55:00",
          "end_datetime": "2019-07-25T17:05:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Concolic Fuzzing -- Or how to run a theorem prover on your Julia code",
          "text": "Concolic testing is a technique that uses concrete execution to create a symbolic representation of a program, which can be used to prove properties of programs or do provable exhaustive fuzzing. In this talk we will explore how to use Cassette to extract a symbolic trace from a Julia program and using that capability to prove properties of Julia programs . This also enables fuzzing and automated test-case development. ",
          "url": "https://pretalx.com/juliacon2019/talk/RVXF7L/",
          "index": 18,
          "speaker": "Valentin Churavy"
        },
        {
          "start_datetime": "2019-07-24T09:50:00",
          "end_datetime": "2019-07-24T10:00:00",
          "duration": 10,
          "location": "NS Room 130",
          "title": "Using Julia in Secure Environments",
          "text": "As a product of the academic community, Julia has been developed with certain assumptions relating to source code availability and access. In secure environments, however, access to public (and even private) package repositories can be deliberately limited. It is still possible to use Julia in these environments: this talk will provide an overview of the challenges in deploying Julia in secure/controlled environments and discuss lessons learned from a real-world deployment on a secure system. This talk stems from the author's (eventually successful) attempt to deploy Julia along with associated packages on a secure network. Last year there was a fairly long discourse thread on this subject; this talk will serve as a followup to the initial attempts and will discuss lessons learned and advice for those seeking to use Julia in restricted environments. ",
          "url": "https://pretalx.com/juliacon2019/talk/JANJFM/",
          "index": 19,
          "speaker": "Seth Bromberger"
        },
        {
          "start_datetime": "2019-07-25T16:15:00",
          "end_datetime": "2019-07-25T16:45:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Simulation and estimation of Nonlinear Mixed Effects Models with PuMaS.jl",
          "text": "The talk will introduce the use of PuMaS.jl for simulation and estimation of Nonlinear Mixed Effects Models used in systems pharmacology. Pharmacokinetic/Pharmacodynamic (PKPD) models are empirical models of the physiological and pharmacological systems often used to describe the kinetics and behavior of drugs in the human body. Nonlinear Mixed Effects (NLME) statistical methods help identify the parameters of the PKPD models and quantify the differences between individuals by integrating models at the population and individual scales. In this talk I introduce PuMaS.jl, a Julia based software for simulating and estimating PKPD, physiology based PK (PBPK), quantitative systems pharmacology (QSP), etc. models used in pharmacology. I will begin by describing approximations to the marginal likelihood which are used to make the quantities efficiently computable and demonstrate on real data how these models can be fit with Optim.jl to reveal population-level characteristics. Additionally, I will demonstrate the ability to utilize DynamicHMC.jl to perform Bayesian estimation of population and individual parameters.  Together, this demonstrates a Julia-based data-driven approach to handle complex problems in individualizing dosing. ",
          "url": "https://pretalx.com/juliacon2019/talk/38EHTQ/",
          "index": 20,
          "speaker": "Vaibhav Dixit"
        },
        {
          "start_datetime": "2019-07-24T15:00:00",
          "end_datetime": "2019-07-24T15:30:00",
          "duration": 30,
          "location": "Room 349",
          "title": "“Online” Estimation of Macroeconomic Models",
          "text": "Medium-large Dynamic Stochastic General Equilibrium models such as those used for forecasting and policy analysis by central banks take a substantial amount of time to estimate using standard approaches such as Random Walk Metropolis Hastings. Our new Sequential Monte Carlo sampler in DSGE.jl makes it possible to estimate DSGE models in parallel, reducing computational time, and “online,” that is efficiently including new data in the estimation as they become available. In this talk, I will present DSGE.jl’s new Sequential Monte Carlo (SMC) sampler. SMC is a method of generating draws from a posterior distribution when direct sampling is not possible. In the past, modern macroeconomists have used Random Walk Metropolis Hastings for this purpose, however as our models have become more complex, Metropolis Hastings’ shortcomings have become more apparent: the algorithm produces serially correlated draws, has difficulties characterizing multimodal distributions, is slow and unable to be parallelized, and interfaces poorly with new data arrivals.  SMC resolves these problems. Instead of starting from scratch with every new piece of information, we initialize the sampling algorithm at the entire posterior distribution of an older estimation. This “online estimation” allows frequent re-estimation of our models as new data become available rather than waiting months for enough new data to justify a full re-estimation. The algorithm is fast and parallelizable, reducing runtimes from days to just hours. These massive speedups make possible estimation of a new class of heterogenous agent models (which are simply infeasible to estimate using Metropolis Hastings) and allow more rigorous forecast evaluations (by allowing us to estimate a larger suite of comparison models on different data).  I will discuss lessons learned regarding parallelization and improvements we’ve made to the algorithm including parameter blocking, utilization of the Chandrasekhar recursions for likelihood evaluation, and fully-adaptive hyper-parameter tuning (allowing the algorithm to flexibly accommodate the business cycle: it spends more time exploring the distribution when economic conditions are novel than when conditions are similar to those in the past). Our SMC methods may prove useful to any Julia users who conduct Bayesian estimation, and many of our developments can also be easily applied to alternative applications. Finally, I will present comparative performance benchmarks of the algorithm in Matlab, FORTRAN, and Julia and discuss approaches we’ve taken to optimize code performance.  Disclaimer: This talk reflects the experience of the author and does not represent an endorsement by the Federal Reserve Bank of New York or the Federal Reserve System of any particular product or service. The views expressed in this talk are those of the authors and do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System. Any errors or omissions are the responsibility of the authors. ",
          "url": "https://pretalx.com/juliacon2019/talk/N3BKPS/",
          "index": 21,
          "speaker": "Ethan Matlin"
        },
        {
          "start_datetime": "2019-07-24T11:40:00",
          "end_datetime": "2019-07-24T11:50:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Brain Tumour Classification with Julia",
          "text": "I will be talking about my work on brain tumour classification using gene expression data, and how Julia as a tool aided this process. In this study, I have taken up a multi-class classification problem in order to distinguish four types of brain tumours from each other, in particular, medulloblastoma, malignant glioma, Atypical Teratoid Rhabdoid Tumor (ATRT), and normal cerebellar. The dataset describes a few thousand genes, and their numerical levels of expression in each tumour sample. The aim of the study is to predict a tumour class, given the gene expression data for that tumour. The insights from this study will be particularly useful, especially for tumours like ATRT which are difficult to diagnose. Survival rates of such types of cancer are considerably higher with an early correct diagnosis. ",
          "url": "https://pretalx.com/juliacon2019/talk/U9XTE7/",
          "index": 22,
          "speaker": "Amita Varma"
        },
        {
          "start_datetime": "2019-07-23T14:30:00",
          "end_datetime": "2019-07-23T15:30:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "JuliaDB Code and Chat",
          "text": "JuliaDB is an analytical data framework that offers typed dataframes, parallel processing, and limited out-of-core support.  This session gives JuliaDB users and contributors the opportunity to discuss how JuliaDB works for them, tackle issues, and discuss the future of JuliaDB. Possible topics of conversation/things to work on: JuliaDB wishlist Utilities for feature engineering/other ML tasks Fixing bugs Creating benchmarks ",
          "url": "https://pretalx.com/juliacon2019/talk/GPZYS7/",
          "index": 23,
          "speaker": "Josh Day"
        },
        {
          "start_datetime": "2019-07-24T11:30:00",
          "end_datetime": "2019-07-24T11:40:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Guaranteed constrained and unconstrained global optimisation in Julia",
          "text": "Set computations with interval arithmetic allow us to write surprisingly efficient software for guaranteed unconstrained and constrained global optimisation in pure Julia. We will show how set computations, using interval-based methods, enable us to find the global minimum for difficult nonlinear, non-convex optimization problems of functions $f:\\mathbb{R}^n \\to \\mathbb{R}$, even when the number of local minima is huge, with guaranteed bounds on the optimum value and on the set of minimizers. We can often also find all stationary points in a given box. We will explain the underlying ideas and some details of the Julia implementation in IntervalOptimisation.jl, which relies on spatial branch and bound, as well as showing examples. We can tackle some \"weakly non-convex\" functions ranging up to a few hundred variables, whereas highly oscillatory functions can be very challenging even for $n < 10$. For constrained optimization, we apply  constraint propagation , as implemented in  IntervalConstraintProgramming.jl , to eliminate infeasible regions and prove the existence of feasible points. We will show how the above techniques are combined to allow efficient and guaranteed calculations for optimization problems. The  CharibdeOptim.jl  package combines these methods with the heuristic Differential Evolution technique to get an efficient global optimisation tool. ",
          "url": "https://pretalx.com/juliacon2019/talk/7BKBZJ/",
          "index": 24,
          "speaker": "David P. Sanders"
        },
        {
          "start_datetime": "2019-07-25T11:00:00",
          "end_datetime": "2019-07-25T11:30:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Interval methods for scientific computing in Julia",
          "text": "We will survey the use of numerical methods built on interval arithmetic and their use for solving nonlinear equations, minimizing nonlinear functions, approximating functions, and solving ordinary differential equations. We will give an overview of the suite of inter-related packages making up the  JuliaIntervals  organization. These are package which use  set calculations  to solve nonlinear equations, minimize nonlinear functions, and solve ordinary differential equations with results that are (in principle, modulo coding errors!)  guaranteed  to be correct.  The underlying technique for calculating with sets is  interval arithmetic . Here, mathematical operations, such as  x -> x^2  and  x + y  are defined on sets, represented as intervals of all real numbers between two endpoints. By defining these operations carefully, we can guarantee that  f(X)  is guaranteed to contain  f(x)  for all  x  in the set  X , even though we use floating-point arithmetic for the calculations. A key technique is  interval contraint propagation , which allows us to calculate enclosures of the  inverse  of a given function. We will show how this can accelerate optimisation and root finding using interval methods. The presentation will be based on practical applications. ",
          "url": "https://pretalx.com/juliacon2019/talk/KDBXKD/",
          "index": 25,
          "speaker": "David P. Sanders"
        },
        {
          "start_datetime": "2019-07-23T17:15:00",
          "end_datetime": "2019-07-23T17:25:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Array Data Distribution with ArrayChannels.jl",
          "text": "We introduce the ArrayChannels.jl library, which allows communication between distributed nodes to occur between fixed buffers in memory. We explore the effects of in-place serialisation on cache usage and communication performance, and consider its suitability for high performance scientific computing. We introduce a library to the language, 'ArrayChannels.jl', encapsulating several data parallelism patterns which causes serialisation of arrays between processes to occur in-place. This provides for better handling of processor cache, while retaining the synchronous semantics of Julia's RemoteChannel constructs. We then evaluate the performance of the library by comparison to MPI and standard Julia on a number of microbenchmarks and HPC kernels. ",
          "url": "https://pretalx.com/juliacon2019/talk/AADAJW/",
          "index": 26,
          "speaker": "Rohan McLure"
        },
        {
          "start_datetime": "2019-07-25T17:15:00",
          "end_datetime": "2019-07-25T17:25:00",
          "duration": 10,
          "location": "Elm A",
          "title": "MendelIHT.jl: How to fit Generalized Linear Models for High Dimensional Genetics (GWAS) Data",
          "text": "GWAS data are extremely high dimensional, large (>100GB), dense, and typically contains rare and correlated predictors. In this talk we discuss its unique data structures, how to efficiently represent it with Julia, how  MendelIHT.jl  in conjunction with  Distributions.jl  and  GLM.jl  fits generalized linear models for GWAS data, and the role of parallel computing. Background:  Marginal regression is widely employed by the genomics community to identify variants associated with complex traits. Ideally one would consider all covariates in tandem, but existing multivariate methods are sub-ideal to handle common issues of a modern genome wide association study (GWAS). Here we fill the gap with a new multivariate algorithm - iterative hard thresholding (IHT). Method:  We introduce a novel coefficient estimation scheme based on maximum likelihoods, extending the IHT algorithm to perform multivariate model estimation for any exponential family. We further discuss and implement doubly-sparse and prior knowledge-aided variants of IHT to tackle specific problems in genetics, such as linkage disequilibrium. Results:  We show how to apply IHT for any generalized linear model, and explicitly derive the updating algorithm and optimal step length for logistic and Poisson models. We provide an efficient implementation of IHT in Julia to analyze GWAS data as a module under  OpenMendel . We tested our algorithm on real and simulated data to demonstrate model quality, algorithm robustness, and scalability. Then we investigate when and how (group)-(within-group) sparsity and knowledge-aided projections may help in discovering rare genetic variants with small effect size. Our implementation enjoys built-in parallelism, operates directly on raw genotype files, and is completely  open sourced . Significance:  For geneticists, our method offers enhanced multivariate model selection for big data GWAS. For theorists, we demonstrate how to use IHT to find GLM coefficients, and we derive 2 variants of the thresholding operators and show when they are expected to perform better. ",
          "url": "https://pretalx.com/juliacon2019/talk/DLQMQU/",
          "index": 27,
          "speaker": "benjamin chu"
        },
        {
          "start_datetime": "2019-07-24T15:45:00",
          "end_datetime": "2019-07-24T16:15:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Differentiate All The Things!",
          "text": "Explore Flux's brand-new compiler integration, and how this lets us turn anything in the Julia ecosystem into a machine learning model. Last JuliaCon I announced the  Zygote  tool for analytical differentiation (AD) of Julia code. Flux has now uses Zygote as its default AD,* enabling both a more elegant interface and all kinds of new models that weren't possible before. Flux's new APIs are powerful and let us easily express advanced concepts like backpropagation through time. But really, Julia's power is in its awesome open-source ecosystem, with state of the art tools for differential equations, mathematical optimisation, and even colour theory! Come and see how we can take advantage of all of these tools in machine learning models, enabling \"theory-driven\" ML to tackle harder problems than ever. In theory; I write this from 4 months in the past, so who knows. ",
          "url": "https://pretalx.com/juliacon2019/talk/JPNYCR/",
          "index": 28,
          "speaker": "Mike Innes"
        },
        {
          "start_datetime": "2019-07-25T11:00:00",
          "end_datetime": "2019-07-25T11:30:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Julia + JavaScript = <3",
          "text": "Julia and JavaScript come together like peanut butter and chocolate \nThis talk is an overview of the JuliaGizmos ecosystem. It starts with the basics of creating a simple page, showing it in various forms, to Interact.jl and beyond. I will present work done by many people that have been aggregated in this github niche, mainly that of Mike Innes, Pietro Vertechi, Joel Mason, Travis DePrato, Sebastian Pfitzner and myself. This talk is an overview of the JuliaGizmos ecosystem. It starts with the basics of creating a simple page, showing it in various forms, to Interact.jl and beyond. I will present work done by many people that have been aggregated in this github niche, mainly that of Mike Innes, Pietro Vertechi, Joel Mason, Travis DePrato, Sebastian Pfitzner and myself. \n•••••••••••••• \nOutline of the talk: Showing any Julia object, serving it on a web server Executing and talking to JavaScript: the  @js  syntax Interact.jl -- past and future Syntax: Building your own JavaScript based library with seamless Julia bindings Deploying a native-looking app as a Julia script A brief update on (other people's) work on transpiling Julia to JS. A common question we get asked on Slack is -- \"is there a replacement for R's shiny in Julia?\". The answer is YES, and you can help us build it out! ",
          "url": "https://pretalx.com/juliacon2019/talk/7SDCJU/",
          "index": 29,
          "speaker": "Shashi Gowda"
        },
        {
          "start_datetime": "2019-07-24T14:30:00",
          "end_datetime": "2019-07-24T15:30:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Diversity and Inclusion in Julia Community",
          "text": "We’ll have a birds of a feather session to discuss and brainstorm diversity and inclusion in the Julia community. All are welcome! JuliaCon 2018 was the most diverse JuliaCon yet. Though the success of this event demonstrated progress in the diversity and inclusivity of our community, the continued underrepresentation of individuals identifying as female or as racial/ethnic minorities, for example, indicates that we have a long way to go. As greater language stability increases the confidence of our community members to recruit new users and to invest further in the language and its community, interest in diversity efforts tied to the language seem to be gaining momentum. We would like to hold a birds of a feather session to discuss and brainstorm diversity and inclusion in the Julia community. ",
          "url": "https://pretalx.com/juliacon2019/talk/PSAX8D/",
          "index": 30,
          "speaker": "Nathan Daly, Kelly Shen"
        },
        {
          "start_datetime": "2019-07-25T11:50:00",
          "end_datetime": "2019-07-25T12:00:00",
          "duration": 10,
          "location": "Elm A",
          "title": "The Julia Language 1.0 Ephemeris and Physical Constants Reader for Solar System Bodies",
          "text": "The Julia Language 1.0 Ephemeris and Physical Constants Reader for Solar System Bodies is an ephemeris reader, written in the programming language of Julia, is a new tool intended for use in astrodynamic applications. With computation time being a critical factor in trajectory optimization, this code has aimed for and accomplished a higher computational efficiency than the original code designed in MATLAB®. The ephemeris reader acquires necessary data for mission design from public JPL websites and calculates positions, velocities, accelerations, and other characteristics of major and small bodies at any user-defined times using the extracted data. Additionally, the second generation of this ephemeris reader introduces shape models of known asteroids as well as spherical harmonics capabilities to support gravitational potential models. This version of the ephemeris reader is also compatible with Julia 1.0 which was released in August of 2018. This second-generation version continues to support the obtainment of critical information needed for mission and trajectory design faster and with added efficiency. This lightning talk will discuss a more detailed overview as well as why Julia was chosen for this project. ",
          "url": "https://pretalx.com/juliacon2019/talk/EKTAAY/",
          "index": 31,
          "speaker": "Renee Spear"
        },
        {
          "start_datetime": "2019-07-25T15:00:00",
          "end_datetime": "2019-07-25T15:30:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Transducers: data-oriented abstraction for sequential and parallel algorithms on containers",
          "text": "Transducers are composable algorithms that operate on collections of inputs.  This concept is first introduced in Clojure language by Rich Hickey for a fully reusable code for mapping, filtering, concatenation, and similar operations that can be modeled a succession of steps.  By this nature, transducers superficially look like iterators that are used by the majority of programming languages for a similar purpose.  However, the protocol used by transducers is quite different from iterators and results in different characteristics: (1) Transducers are driven by a \"generalized\"  foldl  function.  It can implement a specialized looping strategy that is most friendly to the way the data is laid out in memory for a given collection (e.g., two nested loops for vector-of-vectors). (2) Some transducers like  Map ,  Filter ,  Cat  and  Scan  can support parallel execution.  Importantly, this is done without re-writing any of the code for those transducers. (3) The code composed by transducers is close to the way code is written manually using raw loops.  It seems to result in a good machine code generation.  This also means that enabling SIMD using the  @simd  macro is straight forward. In this talk, I explain the formalism of the transducers and discuss the pros and cons for Julia ecosystem based on my experience in implementing  Transducers.jl . ",
          "url": "https://pretalx.com/juliacon2019/talk/UUC9UJ/",
          "index": 32,
          "speaker": "Takafumi Arakaki"
        },
        {
          "start_datetime": "2019-07-25T11:40:00",
          "end_datetime": "2019-07-25T11:50:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Computational topology and Boolean operations with Julia sparse arrays",
          "text": "This talk introduces computational topology algorithms to generate the 2D/3D space partition induced by a collection of 1D/2D/3D geometric objects. Methods and language are those of basic geometric and algebraic topology. Only sparse arrays are used to compute spaces and maps (the chain complex) from dimension zero to three. This approach to computation of space arrangements may be used in disparate subdomains of geometric and visual computing, including geo-mapping, computer vision, computer graphics, medical imaging, geometric and solid modeling, and finite elements. In all such domains one must compute incidences, adjacencies and ordering of cells, generally using disparate and often incompatible data structures and algorithms.  E.g., most of earlier algorithms for space decomposition and Boolean operations work with data structures optimized for selected classes of geometric objects.  \nConversely, we introduce a computational architecture based only on linear algebra with sparse arrays and basic matrix operations. Therefore our formulation, cast in terms of (co)chain complexes of (co)boundary maps, may be applied to very different geometric objects, ranging from solid models to engineering meshes, geographical systems, and biomedical images. In particular, we use rather general cellular complexes, with cells homeomorphic to polyhedra, i.e., to triangulable spaces, and hence possibly non convex and with holes.  \nThe main stage of our computational pipeline operates independently on each 2-cell of the input data sets, according to an embarrassingly parallel data-driven approach. It is remarkable that the approach works with collections of 2-manifolds with- or without-boundary, sets of non-manifolds, sets of 3-manifolds, etc., and not only with triangle meshes.  \nExtending this approach to Boolean solid operations is straightforward. Among other strong points we cite: the compact representation of cellular complexes; the combinable nature of maps, allowing for multiple queries about the local topology, by a single matrix multiplication; the parallel fragmentation of input cells empowered by cell congruence; and what we call \"topological gift wrapping\" algorithm. ",
          "url": "https://pretalx.com/juliacon2019/talk/3BKGNU/",
          "index": 33,
          "speaker": "Alberto Paoluzzi"
        },
        {
          "start_datetime": "2019-07-24T15:00:00",
          "end_datetime": "2019-07-24T15:30:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Queryverse - Under the Hood",
          "text": "This talk will give a brief overview of the  Queryverse  functionality and some new features that were added over the last year, and then dive deep into the internal design of  Query.jl ,  TableTraits.jl  and many other packages from the  Queryverse . This talk will start with a quick end-to-end data science example that exercises all parts of the  Queryverse  (file IO, data manipulation and plotting). I will then briefly introduce a number of new features that were added over the course of the last year (a native Queryverse table type, various new tabular query operators, some new UI tools and the fastest Julia CSV parsing). The bulk of the talk will center on the internal design of  Queryverse . Topics will include the monadic design of  Query.jl  (inherited from LINQ) that allows us to easily bridge the tabular world with many other julia data structures, the design principles behind  TableTraits.jl  and how it manages to combine extreme simplicity with great performance, the underlying architecture in  Query.jl  that allows full query analysis, rewrites and optimization, and the engineering principles (in terms of backwards compatibility and testing infrastructure) that drive the  Queryverse . ",
          "url": "https://pretalx.com/juliacon2019/talk/QYG3BZ/",
          "index": 34,
          "speaker": "David Anthoff"
        },
        {
          "start_datetime": "2019-07-23T11:00:00",
          "end_datetime": "2019-07-23T11:30:00",
          "duration": 30,
          "location": "Elm B",
          "title": "The Linguistics of Puzzles: Solving Cryptic Crosswords in Julia",
          "text": "If you like using serious scientific tools to do silly things, then this talk is for you. Join me as I explore the intersection of computational linguistics, algorithm design, and machine learning in an effort to seriously overthink cryptic crossword clues. Cryptic (or British-style) crosswords are designed to be intentionally vague, misleading, or ambiguous. Each clue  \ncombines a standard crossword clue with wordplay elements like anagrams, reversals, or homophones, so solving the clue requires understanding both crossword definitions and a combinatorial explosion of possible wordplays. Here are a couple of easy examples:  Clue: \"Spin broken shingle\" \nAnswer: \"english\" \nExplanation: \"broken\" means to take an anagram of \"shingle\", which produces \"english\", and \"english\" can mean \"spin\" (at least in billiards).  Clue: \"Initially babies are naked\" \nAnswer \"bare\" \nExplanation: \"initially\" means to take the first letter of \"babies\", giving \"b\". Combining \"b\" and \"are\" gives \"bare\", which means \"naked\".  We could try to enumerate every possible thing a word might mean, and every way those meanings might combine, but doing so would result in billions of possibilities, most of which are nonsense. instead, I'll show how we can use tools from computational linguistics to attack this silly problem in a serious way, and I'll show how Julia makes doing so even easier.  In particular, I will talk about: Developing a formal grammar for cryptic crossword clues Implementing probabilistic parsers which can parse cryptic crossword grammars (or any other grammar, I suppose) Squeezing as much performance as possible out of string manipulation in Julia Analyzing the meaning of words and phrases with WordNet.jl and machine learning To learn more, check out the code, all of which is available online right now. You can find the parsing code at  https://github.com/rdeits/ChartParsers.jl  and the solver itself at  https://github.com/rdeits/CrypticCrosswords.jl ",
          "url": "https://pretalx.com/juliacon2019/talk/RAKLRV/",
          "index": 35,
          "speaker": "Robin Deits"
        },
        {
          "start_datetime": "2019-07-23T15:00:00",
          "end_datetime": "2019-07-23T15:10:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Merging machine learning and econometric algorithms to improve feature selection with Julia",
          "text": "Working on our previous contributions for JuliaCon 2018 (see  GlobalSearchRegresssion.jl ,  GlobalSearchRegressionGUI.jl , and [our JuliaCon 2018 Lighting Talk] ( https://bit.ly/2UC7dr1 )) we develop a new GlobalSearchRegression.jl version merging LASSO and QR-OLS algorithms, and including new outcome capabilities. Combining machine learning (ML) and econometric (EC) procedures allows us to deal with a much larger set of potential covariates (e.g. from 30 to hundresds) preserving most of the original advantages of all-subset regression approaches (in-sample and out-of sample optimality, model averaging results and residuals tests for coefficient robustness). Additionally, the new version of GlobalSearchRegression.jl allows users to obtain LATEX and PDF outcomes with best model results, model averaging estimations and key statistics distributions Applied scientific research increasingly uses Fat-Data (e.g. large number of explanatory variables relative to number of observations) for feature selection purposes. Previous version of our all-subset-regression Julia package was unable to deal with such databases. Existing ML packages (e.g.  Lasso.jl ) overcome this problem paying a cost in terms of statistical inference, coefficient robustness and feature selection optimality (because ML algorithms focus on prediction not on explanation or causal-prediction). The new GlobalSearchRegression.jl version combines regularization pre-processsing with all-subset-regression algorithms to efficiently work with Fat Data without losing EC-strengths in terms of sensitivity analysis, residual properties and coefficient robustness. \nIn the first 3 minutes, our Lighting talk will discuss GlobalSearchRegression.jl new capabilities. We will focus on the main advantages of merging ML and EC algorithms for feature selection when the number of potential covariates is relatively large: ML provides efficiency and sub-sample uncertainty assessment while EC guarantees in-sample and out-of-sample optimality with covariate uncertainty assessment. \nThen, we will show different benchmarks for the new GlobalSearchRegression.jl package against R and Stata counterparts, as well as against their own original version. Our updated ML-EC- algorithm written in Julia is up to 100 times faster than similar R or Stata programs, and allows working with hundreds of potential covariates (while the upper limit for the original GlobalSearchRegression.jl version was 28). \nFinally, we will use the last 4 minutes for a live hands-on example to show the Graphical User Interface, execute the ML-EC algorithm with fat data and analyze main results using new output capabilities in Latex-PDF. ",
          "url": "https://pretalx.com/juliacon2019/talk/7NRBXW/",
          "index": 36,
          "speaker": "Valentin Mari, Nicolás Monzón, Adán Mauri Ungaro, Demian Panigo"
        },
        {
          "start_datetime": "2019-07-24T16:15:00",
          "end_datetime": "2019-07-24T16:25:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Differentiable Rendering and its Applications in Deep Learning",
          "text": "RayTracer.jl is a package designed for differentiable rendering. In this talk, I shall discuss the inverse graphics problem and how differentiable rendering can help solve it. Apart from this we will see how differentiable rendering can be used in differentiable programming pipelines along with neural networks to solve classical deep learning problems. ",
          "url": "https://pretalx.com/juliacon2019/talk/JGY7KC/",
          "index": 37,
          "speaker": "Avik Pal"
        },
        {
          "start_datetime": "2019-07-23T14:30:00",
          "end_datetime": "2019-07-23T15:00:00",
          "duration": 30,
          "location": "Room 349",
          "title": "MLJ - Machine Learning in Julia",
          "text": "We present MLJ, Machine Learning in Julia, a new toolbox for combining and systematically tuning machine learning models. MLJ, an open-source machine learning toolbox written in Julia, has evolved from an early proof of concept, to a functioning well-featured prototype. Features include:  \n1. A flexible API for complex model composition, such as stacking. \n2. Repository of externally implemented model metadata, for facilitating composite model design, and for matching models to problems through a MLR-like task interface. \n3. Systematic tuning and benchmarking of models having possibly nested hyperparameters. \n4. Unified interface for handling probabilistic predictors and multivariate targets. \n5. Agnostic data containers \n6. Careful handling of categorical data types. In addition to demonstrating some of these features, we discuss relationships with other Julia projects in the data science domain. ",
          "url": "https://pretalx.com/juliacon2019/talk/JWEAN3/",
          "index": 38,
          "speaker": "Anthony Blaom"
        },
        {
          "start_datetime": "2019-07-23T15:00:00",
          "end_datetime": "2019-07-23T15:10:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Modia3D: Modeling and Simulation of 3D-Systems in Julia",
          "text": "Model and simulate mechanical 3D-systems with hierarchical components, kinematic loops, and collision handling of convex bodies. The talk is about modeling and simulating mechanical 3D-systems with the Julia package Modia3D.jl. Modia3D initially supports mechanical systems and it shall be expanded into other domains in the future. The package uses the multiple dispatch and metaprogramming concepts of Julia to implement features of modern game engines and multi-body programs such as component-based design, hierarchical structuring, and closed kinematic loops. The mechanical systems are treated as Differential Algebraic Equations which are solved with the variable-step integrator IDA of the Sundials.jl package. Modia3D performs collision handling with elastic response calculation for convex geometries or shapes approximated by a set of convex geometries. A broad phase is executed where each geometry is approximated by a bounding box and only if the bounding boxes are intersecting, the Euclidean distance or the penetration depth is computed in the narrow phase with an improved Minkowski Portal Refinement algorithm.  It is planned to combine 3D modeling closely with equation-based modeling. Therefore, the Julia packages Modia3D and Modia needs to interact, for example a joint of a Modia3D system is driven by a Modia model of an electrical motor and gearbox. ",
          "url": "https://pretalx.com/juliacon2019/talk/WNWNYK/",
          "index": 39,
          "speaker": "Andrea Neumayr"
        },
        {
          "start_datetime": "2019-07-23T16:15:00",
          "end_datetime": "2019-07-23T16:45:00",
          "duration": 30,
          "location": "Elm A",
          "title": "LightQuery.jl",
          "text": "Introducting LightQuery.jl, a new querying package which combines performance with flexibility. LightQuery.jl is a new package for querying tabular data. I'll discuss a number of things which make it special. 1) Careful use of constant propagation, so that named-tuple level operations are type stable when wrapped in a functions. \n2) The ability to simultaneously collect into (and iteratively widen) several sinks at once. \n3) Very few macros: only two, one for chaining and one for anonymizing. Compare the number of macros required for Query, DataFramesMeta, and JuliaDBMeta. \n4) Careful tracking and propagation of line number information. \n5) Huge speed-ups when sources are pre-sorted. \n6) Flexibility. Row-wise operations work with arbitrary containers, provided they can be indexed out of order. Column-wise operations work for anything which has propertynames. ",
          "url": "https://pretalx.com/juliacon2019/talk/8WT7C8/",
          "index": 40,
          "speaker": "Brandon Taylor"
        },
        {
          "start_datetime": "2019-07-25T16:15:00",
          "end_datetime": "2019-07-25T16:45:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Gaussian Process Probabilistic Programming with Stheno.jl",
          "text": "Stheno.jl is a probabilistic programming framework specifically designed for constructing probabilistic models based around Gaussian processes. Come to this talk to find out what that means, why you should care, and how you can use it with Flux.jl and Turing.jl to do cool things. Gaussian processes (GPs) are probabilistic models for nonlinear functions that are flexible, easy to interpret, and enable the modeller to straightforwardly encode high-level assumptions about the properties of the function in question. In short, they're a really useful component of the probabilistic modelling tool box. Implementations to date have not made possible to fully exploit the interpretability of GPs, making it harder than necessary encode prior knowledge and interpret results. Based on the ideas in our recently proposed GP probabilistic programming framework, we have developed Stheno.jl to provide an implementation that is straightforward for the user interested in applying GPs to their problem to use, while remaining hackable for experts and researchers. This talk will provide an intuitive introduction GPs using Stheno.jl. We'll then show how Stheno.jl can be used solve extensions of a classical non-linear regression problem and explore structure in the solution, how it can be used in conjunction with Turing.jl to embed GPs as a component in a larger non-Gaussian probabilistic programme, and to explore how it can be combined with Flux.jl to hardness the complementary strengths of deep learning and probabilistic modelling. ",
          "url": "https://pretalx.com/juliacon2019/talk/GEJT9H/",
          "index": 41,
          "speaker": "Will Tebbutt"
        },
        {
          "start_datetime": "2019-07-24T11:40:00",
          "end_datetime": "2019-07-24T11:50:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Pyodide: The scientific Python stack compiled to WebAssembly",
          "text": "Pyodide is a project from Mozilla to build a performant scientific Python stack running entirely in the web browser using WebAssembly. Unlike the traditional data science interaction model where the web browser only acts as a front end to computation happening on a remote server, Pyodide allows the computation to happen right within the user's web browser.  This makes interactivity more performant, and allows easier sharing of notebooks without using potentially costly or privacy-violating cloud services. I hope to present this at JuliaCon as a success story in the hopes that a similar tool can be built for Julia. ",
          "url": "https://pretalx.com/juliacon2019/talk/LHU9UM/",
          "index": 42,
          "speaker": "Michael Droettboom"
        },
        {
          "start_datetime": "2019-07-23T15:10:00",
          "end_datetime": "2019-07-23T15:20:00",
          "duration": 10,
          "location": "Elm B",
          "title": "TrajectoryOptimization.jl: A testbed for optimization-based robotic motion planning",
          "text": "Trajectory optimization is a fundamental tool for controlling robots with complex, nonlinear dynamics. TrajectoryOptimization.jl is devoted to providing a unified testbed for developing, comparing, and deploying algorithms for trajectory optimization. Trajectory optimization is a powerful tool for motion planning, enabling the synthesis of dynamic motion for complex underactuated robotic systems. This general framework can be applied to robots with nonlinear dynamics and constraints where other motion planning paradigms---such as sample-based planning, inverse dynamics, or differential flatness---are impractical or ineffective. TrajectoryOptimization.jl has been developed for the purpose of collecting and developing state-of-the-art algorithms for trajectory optimization under a single, unified platform that offers the user state-of-the-art performance, an intuitive interface, and versatility. Initial results using a novel algorithm written in Julia already beat previous methods leveraging NLP solvers such as Ipopt and Snopt. ",
          "url": "https://pretalx.com/juliacon2019/talk/UPLPQW/",
          "index": 43,
          "speaker": "Brian Jackson"
        },
        {
          "start_datetime": "2019-07-25T11:40:00",
          "end_datetime": "2019-07-25T11:50:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Differential Programming Tensor Networks",
          "text": "A package about einsum, as well as differentiable tensor network algorithms built on top of it. Why we need automatic differentiating tensor networks and how to achieve this goal. A tensor network is a contraction of tensors, it has wide applications in fields of physics, big data and machine learning. It can be used to represent a quantum wave function ansatz, compress data and model probabilities. Supporting automatic differentiation brings hope for many difficult problems like training project entangled pair states. We provide a unified, dispatchable interface for  einsum  as the middleware to port tensor contraction libraries and tensor network applications and a through support to back-propagation through linear algebra functions. Based on these supporting libraries, we show some tensor network algorithms as examples. References:\n* Differentiable Programming Tensor Networks, Hai-Jun Liao, Jin-Guo Liu, Lei Wang, and Tao Xiang [under preparation]\n* Unsupervised Generative Modeling Using Matrix Product States, Zhao-Yu Han, Jun Wang, Heng Fan, Lei Wang, and Pan Zhang Phys. Rev. X 8, 031012 ",
          "url": "https://pretalx.com/juliacon2019/talk/XH89CV/",
          "index": 44,
          "speaker": "JinGuo Liu"
        },
        {
          "start_datetime": "2019-07-24T14:30:00",
          "end_datetime": "2019-07-24T15:00:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Heterogeneous Agent Dynamic Stochastic General Equilibrium (DSGE) Models in Julia at the Federal Reserve Bank of New York",
          "text": "This talk will provide an overview of the Federal Reserve Bank of New York's heterogeneous agent dynamic stochastic general equilibrium (DSGE) model development process in Julia, walking through our navigation of Julia-specific functionality in the process. Comparisons of performance relative to MATLAB and FORTRAN will be provided. Abstract:  Over the past few decades, income and wealth inequality have emerged as defining fixtures of the modern U.S. economy. Born of a desire to study the differential effects of policy decisions on a variegated group of economic actors, heterogeneous agent (HA) models enable researchers to incorporate critical differentiation in household income, wealth, and consumption behavior into their analyses of economic phenomena. Yet, while great academic progress has been made developing such models, many policy institutions have been slow to shift from the “representative agent” paradigm. This is due, in large part, to computational strain surrounding HA models' solution and estimation. However, thanks to speed gains made possible by innovations in computing languages like Julia, what was once too computationally taxing for policy purposes has become both feasible to run and elegant to implement. This talk will provide an overview of the Federal Reserve Bank of New York's (NY Fed) HA dynamic stochastic general equilibrium (DSGE) model development process in Julia, walking through our navigation of Julia-specific functionality in the process. Comparisons of performance relative to MATLAB and FORTRAN will be provided. Description:  Heterogeneous agent models, in contrast to representative agent models, allow for heterogeneity in various features among agents in an economy, at both the household and firm level. Examples of such heterogeneity might include age, risk-tolerance, skills, and discounting of the future --- features that manifest themselves in heterogeneity in the wealth distribution. Recent work in macroeconomic literature reveals the monetary and fiscal policy implications for HA models can differ widely from their representative counterparts. Such models may be implemented in either discrete or continuous time, posing challenges for their intuitive out-of-the-box deployment as well as succinct tailoring of model-specific solution methods. The solving of large-scale macroeconomic models is sufficiently complex in the representative agent case; the dimensionality of problems increases considerably with the addition of heterogeneity, especially in continuous-time, lending itself well to Julia’s strengths. In the past year, our team has ported several HA models—along with algorithms to discretize, linearize, and solve them—from both MATLAB and FORTRAN for integration into our codebase. package. This addition comes at the heals of the release of our  DSGE.jl  package, whose other components, such as representative agent model solution, estimation, and forecasting, were the subject of past presentations at JuliaCons 2016-2018. I will discuss the respects Julia has provided us technical flexibility in constructing coherent type hierarchies, employing multiple dispatch, and utilizing distributed computing, as well as how we managed various design decisions pertaining to variable scope, typing, and parallelization, so as to optimize for memory usage and runtime. I will cover the technical constraints and considerations imposed by our production environment at the NY Fed, and offer advice for what we found accommodated our cluster setup. Finally, I will shed light on how HA models may expand the toolkit for policymakers and academics. Disclaimer: This talk reflects the experience of the author and does not represent an endorsement by the Federal Reserve Bank of New York or the Federal Reserve System of any particular product or service, The views expressed in this talk are those of the authors and do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System. Any errors or omissions are the responsibility of the authors. ",
          "url": "https://pretalx.com/juliacon2019/talk/K9BBNX/",
          "index": 45,
          "speaker": "Rebecca Sarfati"
        },
        {
          "start_datetime": "2019-07-25T11:50:00",
          "end_datetime": "2019-07-25T12:00:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Geometric algebra in Julia with Grassmann.jl",
          "text": "The  Grassmann.jl  package provides tools for doing computations based on multi-linear algebra, differential geometry, and spin groups using the extended tensor algebra known as Grassmann-Clifford-Hestenes-Taylor geometric algebra. The primary operations are  ∧, ∨, ⋅, *, ×, ⋆, ', ~  (which are the outer, regressive, inner, geometric, and cross products along with the Hodge star, adjoint, and multivector reversal operations). Any operations are truly extensible with high dimensional support for up to 62 indices and staged caching / precompilation, where the code generation enables the fairly automated task of making more definitions. The  DirectSum.jl  multivector parametric type polymorphism is based on tangent bundle vector spaces and conformal projective geometry to make the dispatch highly extensible for many applications. Additionally, interoperability between different sub-algebras is enabled by  AbstractTensors.jl , on which the type system is built. The design of  Grassmann.jl  is based on the  TensorAlgebra  abstract type system interoperability from  AbstractTensors.jl  with a  VectorSpace  parameter from  DirectSum.jl . Abstract tangent vector space type operations happen at compile-time, resulting in a differential conformal geometric algebra of hyper-dual multivector forms. The abstract nature of the product algebra code generation enables one to automate the extension of the product operations to any specific number field type (including symbolic coefficients with  Reduce.jl  or SymPy.jl), by taking advantage of Julia's type system. With the type system, it is possible to construct mixed tensor products from the mixed tangent vector basis and its dual basis, such as bivector elements of Lie groups.  Grassmann  can be used to study unitary groups used in quantum computing by building efficient computational representations of their algebras. Applicability of the Grassmann computational package not only maps to quantum computing, but has the potential of impacting countless other engineering and scientific computing applications. It can be used to work with automatic differentiation and differential geometry, algebraic forms and invariant theory, electric circuits and wave scattering, spacetime geometry and relativity, computer graphics and photogrammetry, and much more. ",
          "url": "https://pretalx.com/juliacon2019/talk/CES8P9/",
          "index": 46,
          "speaker": "Michael Reed"
        },
        {
          "start_datetime": "2019-07-23T15:45:00",
          "end_datetime": "2019-07-23T16:15:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Cleaning messy data with Julia and Gen",
          "text": "Julia is home to a growing ecosystem of probabilistic programming languages—but how can we put them to use for practical, everyday tasks? In this talk, we'll discuss our ongoing effort to automate common-sense data cleaning by building a declarative modeling language for messy datasets on top of  Gen . Julia is home to a growing ecosystem of probabilistic programming languages—but how can we put them to use for practical, everyday tasks? In this talk, we'll discuss our ongoing effort to automate common-sense data cleaning by building a declarative dataset description language on top of  Gen . Users of the language can encode domain knowledge about their dataset and the ways in which it might be unclean in short, declarative probabilistic scripts, which are compiled to Gen programs that infer locations of probable errors, impute missing values, and propose likely corrections in tabular data. ",
          "url": "https://pretalx.com/juliacon2019/talk/EHG87D/",
          "index": 47,
          "speaker": "Alex Lew"
        },
        {
          "start_datetime": "2019-07-23T16:15:00",
          "end_datetime": "2019-07-23T16:45:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Open Source Power System Production Cost Modeling in Julia",
          "text": "Operating a power system on a day to day basis involves optimizing the operation of the given energy system. Modeling these operations requires solving a Mixed Integer Linear Programming problem. In this talk, we will present methods for solving a production cost model in Julia and JuMP using PowerSimulations.jl Production Cost Modeling (PCM) of power systems captures all the costs of operating a fleet of generators. This model captures hourly chronological security constrained unit commitment and economic dispatch simulation while minimizing costs and adhering to a wide variety of operating constraints. In this talk, we will cover the basics of Production Cost Modeling, and will explain how we have implemented this in Julia using JuMP. We will also discuss our experiences using Julia and JuMP and express the benefits to our users and some challenges we faced. ",
          "url": "https://pretalx.com/juliacon2019/talk/8DTHDK/",
          "index": 48,
          "speaker": "Dheepak"
        },
        {
          "start_datetime": "2019-07-24T11:00:00",
          "end_datetime": "2019-07-24T11:30:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Why writing C interfaces in Julia is so easy*",
          "text": "Julia allows interfacing with shared libraries using  ccall . This allows calling into compiled binaries that could be written in any language that exposes the C ABI. In this talk, I'll describe best practices to follow for interfacing with C libraries. This talk is titled why writing C interfaces in Julia is so easy, but as anyone that has written interfaces to C ABI will know, interfacing with the C ABI is never easy. There can be segfaults, memory leaks, uninitialized memory issues and a host of other challenges to deal with when working through this process. In this talk, I'll briefly describe how the C ABI works, and then describe how  ccall  can be used. I'll also go through many best practices that I've used to ensure a nice clean Julian interface to a shared library. I will show how some best practices regarding writing interfaces to a large number of functions, you can use Julia's type system to guarantee that the users of your Julia library don't accidentally pass the wrong pointer to a function using  unsafe_convert , and some general advice for programmers interested in writing their own libraries in a lower level language (such as C, C++, Rust, Nim etc) and how to ensure that they can be provided as pre-compiled binaries for Julia packages (using BinaryBuilder and alternatives). ",
          "url": "https://pretalx.com/juliacon2019/talk/ARX8CY/",
          "index": 49,
          "speaker": "Dheepak"
        },
        {
          "start_datetime": "2019-07-23T15:20:00",
          "end_datetime": "2019-07-23T15:30:00",
          "duration": 10,
          "location": "Room 349",
          "title": "TSML (Time Series Machine Learning)",
          "text": "TSML is a package for time series data processing, classification, and prediction. It provides common API for ML libraries from Python's ScikitLearn, R's caret, and native Julia MLs for seamless integration of heterogenous libraries to create complex ensembles for robust time-series preprocessing, prediction, clustering, and classification. Over the past years, the industrial sector has seen many innovations brought about by automation. Inherent in this automation is the installation of sensor networks for status monitoring and data collection. One of the major challenges in these data-rich environments is how to extract and exploit information from these large volume of data to detect anomalies, discover patterns to reduce downtimes and manufacturing errors, reduce energy usage, etc. To address these issues, we developed TSML package. It leverages AI and ML libraries from ScikitLearn, Caret, and Julia as building blocks in processing huge amount of industrial time series data. It has the following characteristics: \n- TS data type clustering/classification for automatic data discovery \n- TS aggregation based on date/time interval \n- TS imputation based on symmetric Nearest Neighbors \n- TS statistical metrics for data quality assessment \n- TS ML wrapper with more than 100+ libraries from caret, scikitlearn, and julia \n- TS date/value matrix conversion of 1-D TS using sliding windows for ML input \n- Common API wrappers for ML libs from JuliaML, PyCall, and RCall \n- Pipeline API allows high-level description of the processing workflow \n- Specific cleaning/normalization workflow based on data type \n- Automatic selection of optimised ML model \n- Automatic segmentation of time-series data into matrix form for ML training and prediction \n- Easily extensible architecture by using just two main interfaces: fit and transform \n- Meta-ensembles for robust prediction \n- Support for distributed computation, for scalability, and speed TSML uses a pipeline which iteratively calls the fit and transform families of functions relying on multiple dispatch to select the correct algorithm. Machine learning functions in TSML are wrappers to the corresponding Scikit-learn, Caret, and native Julia ML libraries. There are more than hundred classifiers and regression functions available using a common API. Full TSML documentation:  https://ibm.github.io/TSML.jl/stable/ ",
          "url": "https://pretalx.com/juliacon2019/talk/9GAZTS/",
          "index": 50,
          "speaker": "Paulito Palmes"
        },
        {
          "start_datetime": "2019-07-24T11:30:00",
          "end_datetime": "2019-07-24T11:40:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Backticks and the Glorious Command  Literal",
          "text": "Julia command literals are one of the most compelling abstractions for dealing with processes in any programming language. This talk will show what these command literals offer that similar constructs in other languages do not and how they can be used to write safer, more robust shell scripts. Like Perl, Ruby and Bash, Julia offers backtick syntax as an abstraction for dealing with processes. However, while other languages use this syntax to invoke a shell and grab the output, backticks in Julia invoke a mini-parser for it's own safe version of a shell language and they evaluate to a command literal just waiting to be run, never invoking a shell. This talk will go over the details of how command literals are parsed in Julia, what the resulting object looks like, and why the Julia approach to commands is a significant improvement over what shell wrappers in other languages provide (including and especially the POSIX shell itself). Of course, it will also include many examples of how to use command literals effectively. ",
          "url": "https://pretalx.com/juliacon2019/talk/VANP8R/",
          "index": 51,
          "speaker": "Aaron Christianson"
        },
        {
          "start_datetime": "2019-07-23T11:50:00",
          "end_datetime": "2019-07-23T12:00:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Recommendation.jl: Building Recommender Systems in Julia",
          "text": "This talk demonstrates  Recommendation.jl , a Julia package for building recommender systems. We will eventually see (1) a brief overview of common recommendation techniques, (2) advantages and use cases of their Julia implementation, and (3) design principles behind the easy-to-use, extensible package. Recommendation.jl  allows you to easily implement and experiment your recommender systems, by fully leveraging Julia's efficiency and applicability. This talk demonstrates the package as follows. The speaker first gives a brief overview of theoretical background in the field of recommender systems, along with corresponding Recommendation.jl functionalities. The package supports a variety of well-know recommendation techniques, including k-nearest-neighbors and matrix factorization. Meanwhile, their dedicated evaluation metrics (e.g., recall, precision) and non-personalized baseline methods are available for your experiments. Next, this talk discusses pros and cons of using Julia for recommendation. On the one hand, a number of algorithms fits well into Julia's capability of high-performance scientific computing in this field, but at the same time, it is challenging to make Julia-based recommenders production-grade at scale. The discussion ends up with future ideas of how to improve the package. We will finally see the extensibility of the package with an example of building our own custom recommendation method. In practice, Recommendation.jl is designed to provide separated, flexible  data access layer ,  algorithm layer , and  recommender layer  to the end users. Consequently, the users can quickly build and test their custom recommendation model with less efforts. Reference:  Recommendation.jl: Building Recommender Systems in Julia , an article written by the speaker. ",
          "url": "https://pretalx.com/juliacon2019/talk/FFXKCX/",
          "index": 52,
          "speaker": "Takuya Kitazawa"
        },
        {
          "start_datetime": "2019-07-23T15:20:00",
          "end_datetime": "2019-07-23T15:30:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Non-Gaussian State-estimation with JuliaRobotics/Caesar.jl",
          "text": "Navigation and mapping for robots require data fusion from various sensors, each producing uncertain and opportunistic measurement data. \nWe are continuing with a multi-year, native Julia factor graph based simultaneous localization and mapping (SLAM) inference system that grew out of research work on non-Gaussian state-estimation, and is the primary implementation of the \"multimodal-iSAM\" algorithm from robotics literature. We are actively using Julia in algorithmic research and development work for robotic navigation.  In robotic navigation, multiple sensor data are combined such as odometers, cameras, inertial measurement units, lidars, GPS, sonar acoustics, etc.  The dream is to build factor graph based non-Gaussian state-estimation into real-time capable systems.  Julia has enabled the development of newer non-Gaussian inference techniques that would otherwise have been near intractable if attempted with older languages.  Most SLAM systems today are built in C++ with some Python integration while others are using MATLAB with an eye on later C++ implementations.  Switching to Julia has been worth it;  our ongoing efforts are to formalize the benefits of the one-language / fast / distributed / high-level-numerical-syntax of Julia with an open-source development model.  Our approach not only includes on-board computations but also distributed inference with a cloud server model.  JuliaRobotics/Caesar.jl is an umbrella framework alongside dedicated packages such as RoME.jl / IncrementalInference.jl / Arena.jl / ApproxManifoldProducts.jl / GraffSDK.jl.  The JuliaRobotics/Caesar.jl package depends on over 100 other Julia packages, creating challenges with first run compile times and debugging efforts.  Our challenge now is to continue software development, all-round performance improvement, improved user experience, and help grow the JuliaRobotics community.  Although the JuliaRobotics community is still small, we believe that Julia could become a significant language in robotics.  In the mean-time, a multi-language interface is in the works too.  We are actively using Julia in algorithmic research and development work for robotic navigation.  Robotic navigation is generally done by combining data from multiple sensors such as odometers, cameras, inertial measurement units, lidars, GPS, sonar acoustics, etc.  The dream is to build factor graph based non-Gaussian state-estimation into real-time capable systems.  Julia has enabled the development of newer non-Gaussian inference techniques that would otherwise have been near intractable if attempted with older languages.  Most SLAM systems today are built in C++ with some Python integration while others are using MATLAB with an eye on later C++ implementations.  Switching to Julia has been worth it;  our ongoing efforts are to formalize the benefits of the one-language / fast / distributed / high-level-numerical-syntax of Julia with an open-source development model.  Our approach not only includes on-board computations but also distributed inference with a cloud server model.  JuliaRobotics/Caesar.jl is an umbrella framework alongside dedicated packages such as RoME.jl / IncrementalInference.jl / Arena.jl / ApproxManifoldProducts.jl / GraffSDK.jl.  The JuliaRobotics/Caesar.jl package depends on over 100 other Julia packages, creating challenges with first run compile times and debugging efforts.  Our challenge now is to continue software development, all-round performance improvement, improved user experience, and help grow the JuliaRobotics community. ",
          "url": "https://pretalx.com/juliacon2019/talk/G7LXYQ/",
          "index": 53,
          "speaker": "Sam Claassens, Dehann Fourie"
        },
        {
          "start_datetime": "2019-07-23T16:15:00",
          "end_datetime": "2019-07-23T16:45:00",
          "duration": 30,
          "location": "Room 349",
          "title": "XLA.jl: Julia on TPUs",
          "text": "The intersection of Machine Learning and High Performance Computing: Running Julia code on Google Cloud Tensor Processing Units. Machine Learning workloads continue to require greater and greater compute capability, spawning the development of multiple generations of specialized hardware designed to eke out ever greater efficiency in training and inference workloads.  This talk will explore the state of Julia on this hardware platform, showcasing some of the impressive speedups the hardware and provide, alongside some of the restrictions the hardware model imposes upon the dynamic nature of the Julia language. ",
          "url": "https://pretalx.com/juliacon2019/talk/8ANSVY/",
          "index": 54,
          "speaker": "Keno Fischer, Elliot Saba"
        },
        {
          "start_datetime": "2019-07-23T11:40:00",
          "end_datetime": "2019-07-23T11:50:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Analyzing social networks with SimpleHypergraphs.jl",
          "text": "A hypergraph is a generalization of a graph where a single edge can connect more than two vertices. Typical applications are related to social data analysis and include situations such as sending a single email to several recipients, a customer giving reviews to several restaurants or analyzing security vulnerabilities of information networks. In many situations the usage of a hypergraph rather than a classical graph allows to better capture and analyze dependencies within the network. We will start by presenting the library and its functionality. As an example a use case with analysis of Yelp reviews will be shown. The presentation will be based on Jupyter notebook and will be very illustrative for researchers planning to do social network modelling in Julia. In the second part of presentation we will show how we made use of typical Julia programming patterns to build the library. This includes overloading Array operators to provide a user an Array-like access to the hypegraphs data, using object composition as a standard inheritance mechanism for generating various representations (views) of a hypergraph and finally, making the hypegraph data structures compatible with LightGraphs.jl by providing new method implementations. This should give the participants an overview of typical patterns used when extending the package ecosystem of the Julia language. Acknowledgement: The project is financed by the Polish National Agency for Academic Exchange. ",
          "url": "https://pretalx.com/juliacon2019/talk/3FSTJF/",
          "index": 55,
          "speaker": "Bogumił Kamiński, Przemysław Szufel"
        },
        {
          "start_datetime": "2019-07-25T17:15:00",
          "end_datetime": "2019-07-25T17:25:00",
          "duration": 10,
          "location": "Elm B",
          "title": "TimerOutputs.jl - a cheap and cheerful instrumenting profiler",
          "text": "TimerOutputs.jl is a tool that lets you annotate sections in your code so that after execution, a nicely formatted table with information about how much time and allocations were spent in each section can be shown. Julia has for a long time come with a built-in profiler, which is available as the Profile standard library. This profiler is a sampling profiler which means that it collects snapshots of the stacktrace at regular intervals. After execution of the profiled code, the number of traces that were collected in each function can be displayed which gives a good estimate where the code is spending its time. While sampling profiling is a very useful and cheap way of profiling code, there are a few drawbacks: \nSince only samples of the execution is collected, exact information of e.g. the time spent in functions or the number of calls to a function is not available. \nNot being able to annotate what parts of the code you care about mean that the output from the profiler is sometimes noisy and hard to interpret for non-experts. \nAllocations can not be attributed to certain sections of the code. TimerOutputs is a Julia package that provides an instrumenting profiler which requires you to annotate your code with labeled sections. While the code is running, TimerOutputs records timing and allocation data in these sections and can then print a summary back to the user. This can sometimes make it easier to get a high level overview of the performance characteristics of the code. An example of the output from TimerOutputs is shown below. ───────────────────────────────────────────────────────────────────────────────\n                                        Time                   Allocations\n                                ──────────────────────   ───────────────────────\n        Tot / % measured:            6.89s / 97.8%           5.20GiB / 85.0%\n\n Section                ncalls     time   %tot     avg     alloc   %tot      avg\n ───────────────────────────────────────────────────────────────────────────────\n assemble                    6    3.27s  48.6%   545ms   3.65GiB  82.7%   624MiB\n   inner assemble         240k    1.92s  28.4%  7.98μs   3.14GiB  71.1%  13.7KiB\n linear solve                5    2.73s  40.5%   546ms    108MiB  2.39%  21.6MiB\n create sparse matrix        6    658ms  9.77%   110ms    662MiB  14.6%   110MiB\n export                      1   78.4ms  1.16%  78.4ms   13.1MiB  0.29%  13.1MiB\n ───────────────────────────────────────────────────────────────────────────────\n The timing and allocations for each section is presented and the call graph (e.g. that assemble calls inner assemble) is shown by indentation. This lightning talk gives a short summary of the implementation, syntax and use cases of TimerOutputs. ",
          "url": "https://pretalx.com/juliacon2019/talk/M8G7DD/",
          "index": 56,
          "speaker": "Kristoffer Carlsson"
        },
        {
          "start_datetime": "2019-07-25T11:30:00",
          "end_datetime": "2019-07-25T11:40:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Implicit Geometry with Multi-Dimensional Bisection Method",
          "text": "In the proposed talk an efficient root finding algorithm is presented through engineering applications, which are formed as implicit non-linear equation systems. Multi-Dimensional Bisection Method (MDBM.jl) is an efficient and robust root-finding package, which can be used to determine whole high-dimensional submanifolds (points, curves, surfaces…) of the roots of implicit non-linear equation systems, especially in cases, where the number of unknowns surpasses the number of equations. Engineering application will be presented from the different fields \n - determination of the workspace of a robot arm with collision avoidance \n - stability (stabilizability) chart computations \n - constrained parameter optimisation ",
          "url": "https://pretalx.com/juliacon2019/talk/7S9BDD/",
          "index": 57,
          "speaker": "Daniel Bachrathy"
        },
        {
          "start_datetime": "2019-07-25T17:25:00",
          "end_datetime": "2019-07-25T17:35:00",
          "duration": 10,
          "location": "Room 349",
          "title": "A probabilistic programming language for switching Kalman filters",
          "text": "I will present a probabilistic programming language that implements switching Kalman filters, and its applications to industrial time series processing. At R2 Inc., we monitor in real-time tens of thousands of sensors in industrial plants, looking for anomalous behaviour. Industrial processes are usually very well understood and predictable, making them ideal candidates for classical Bayesian analysis. Off-the-shelf modelling approaches like Stan offer great flexibility in formulating a model, but the Markov Chain Monte Carlo algorithms they use are slow on large datasets, which hinders model iteration. Kalman filters can provide much faster, exact posterior probabilities, by assuming that the uncertainties are Gaussian and that the hidden state evolution is linear. We have built a probabilistic programming language around the switching Kalman filter algorithm. It was implemented as a Julia macro, and supports Unitful time series with missing data. I will present its design, implementation and some of its applications. ",
          "url": "https://pretalx.com/juliacon2019/talk/BD9EBF/",
          "index": 58,
          "speaker": "Cédric St-Jean-Leblanc"
        },
        {
          "start_datetime": "2019-07-25T16:15:00",
          "end_datetime": "2019-07-25T16:45:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Building a Debugger with Cassette",
          "text": "As the saying goes:  \"You can solve that with Cassette\" . \nThis is a tuitoral on how to use Cassette for building a debugger. \nIt explains the core of MagneticReadHead.jl, and how you can build similar tools, \nto instrument julia code for your purposes. As the saying goes:  \"You can solve that with Cassette\" . \nYou can do anything with Cassette, and debugging is a thing, therefore Cassette can be used for it. \nGenerally speaking, you shouldn't solve problems with Cassette that you can solve in any other way. \nHowever if you want to build a debugger, the options include building  an entire interpreter , going deep into the lowest levels of the compiler/LLVM , \nor using  Cassette . \nThe other options are certainly good, and indeed the interpreter work has yeilded  Debugger.jl . \nBut this talk is about doing it with Cassette. MagneticReadHead v0.1.0  is usable debugger based on easy-to-use Cassette function overdubs. \nIt is under 300 lines of code, and allowed setting breakpoints and stepping between function calls. MagneticReadHead v0.2+  is featureful debugger based on Cassette IR passes. \nIt is under 800 lines of code, and alloweds setting breakpoints at arbitary locations and stepping between IR statements. The talk will first explain the Cassette function overdubs used in v0.1.0 and how you can use them to fairly painlessly instrument julia code at the function call level. \nIt will then move on the the much more complex IR passes used in current versions of MagneticReadHead. \nExplaining how you can recursively modify julia code at run time to instert the extra functionality needed for debugging. At first Julia IR may seem like a read-only language. \nIt is surprisingly easy to read, but actually modifying it... the concept brings on a special kind of head pain. \nAfter this talk you will be able to experience that special pain for yourself, \nand hopefuly push through it to do something useful. This tuitorial type presentation is for the advanced julia user. \nWhile knowledge of Cassette is not required, it is expected that attendees are broadly familar with the idea of what IR is, even if they have no idea how to write it. \nEveryone is welcome to come along for the ride. ",
          "url": "https://pretalx.com/juliacon2019/talk/Y9B87L/",
          "index": 59,
          "speaker": "Lyndon White (@oxinabox)"
        },
        {
          "start_datetime": "2019-07-24T14:30:00",
          "end_datetime": "2019-07-24T15:00:00",
          "duration": 30,
          "location": "Elm B",
          "title": "DataKnots.jl - an extensible, practical and coherent algebra of query combinators",
          "text": "DataKnots is a Julia library for querying data with an extensible, practical and coherent algebra of query combinators.  DataKnots is designed to let data analysts and other accidental programmers query and analyze complex structured data. DataKnots  implements an algebraic query interface of  Query Combinators . This algebra’s elements, or queries, represent relationships among class entities and data types. This algebra’s operations, or combinators, are applied to construct query expressions.   We seek to prove that this query algebra has significant advantages over the state of the art: DataKnots is a practical alternative to SQL with a declarative syntax; this makes it suitable for use by domain experts. DataKnots' data model handles nested and recursive structures (unlike DataFrames or SQL); this makes it suitable for working with CSV, JSON, XML, and SQL databases. DataKnots has a formal semantic model based upon monadic composition; this makes it easy to reason about the structure and interpretation of queries. DataKnots is a combinator algebra (like XPath but unlike LINQ or SQL); this makes it easier to assemble queries dynamically. DataKnots is fully extensible with Julia; this makes it possible to specialize it into various domain specific query languages. This talk will provide a conceptual introduction to DataKnots.jl with applications in medical informatics. ",
          "url": "https://pretalx.com/juliacon2019/talk/HLLDQT/",
          "index": 60,
          "speaker": "Clark C. Evans"
        },
        {
          "start_datetime": "2019-07-23T15:45:00",
          "end_datetime": "2019-07-23T16:15:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Porting a massively parallel Multi-GPU application to Julia: a 3-D nonlinear multi-physics flow solver",
          "text": "We showcase the port to Julia of a massively parallel Multi-GPU solver for spontaneous nonlinear multi-physics flow localization in 3-D. Our contribution is a real-world example of Julia solving \"the two language problem\". We showcase the port to Julia of a massively parallel Multi-GPU solver for spontaneous nonlinear multi-physics flow localization in 3-D. The original solver is itself the result of a translation from a Matlab prototype to CUDA C and MPI. Our contribution is an illustration of Julia solving \"the two language problem\": the Matlab prototype and the CUDA C + MPI production code are being replaced by a single Julia code that will serve both further prototyping and production. The solver's parallel and matrix-free design enables a short time to solution and is applicable to solve a wide variety of coupled and nonlinear systems of partial differential equations in 3-D. The employed stencil-based iterative method optimally suits both shared and distributed memory parallelization. As reference, the original Multi-GPU solver achieved a high performance and a nearly ideal parallel efficiency on up to 5120 NVIDIA Tesla P100 GPUs on the hybrid Cray XC-50 \"Piz Daint\" supercomputer at the Swiss National Supercomputing Centre, CSCS. We report the first performance and scaling results obtained with the Julia port. We present additionally our porting approach and discuss the related challenges. ",
          "url": "https://pretalx.com/juliacon2019/talk/LGHLC3/",
          "index": 61,
          "speaker": "Ludovic Räss"
        },
        {
          "start_datetime": "2019-07-24T16:35:00",
          "end_datetime": "2019-07-24T17:05:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Fitting Neural Ordinary Differential Equations with DiffeqFlux.jl",
          "text": "Neural Ordinary Differential Equations (neural ODEs) are a brand new and exciting method to model nonlinear transformations as they combine the two fields of machine learning and differential equations. In this talk we discuss DiffEqFlux.jl, a package for designing and training neural ODEs, and we introduce new methodologies to improve the efficiency and robustness of neural ODEs fitting. A  neural Ordinary Differential Equation  (ODE) is a differential equation whose evolution equation is a neural network. We can use neural ODEs to model nonlinear transformations by directly learning the governing equations from time course data. Therefore, neural ODEs present a novel method for modelling time series in an elegant manner as they allow us to use sophisticated differential equations solving procedures in the field of machine learning, an area of already high and still increasing demand. In this talk we discuss  DiffEqFlux.jl , a package for designing and training neural ODEs. We demonstrate how to fit neural ODEs against data by using the L2 loss function, and explain how Julia's automatic differentiation is used to calculate the gradients through the differential equation solvers to compute the gradients of the loss function. While this is the \"standard\" method, it involves solving an ODE at each step of the optimization which can be very time consuming. Thus, we introduce new methodologies available in DiffEqFlux.jl, to improve the efficiency and robustness of the fitting. First, we demonstrate new functionalities provided by a bridge to the  two stage collocation method  of the package  DiffEqParamEstim.jl . Second, we show how to effectively use these functions in a mixed training loop to improve the speed and robustness of the fitting. Third, we demonstrate and explain a new loss function in DiffEqFlux.jl which allows for multiple shooting, and show its performance characteristics. Together, these three features improve the performance and robustness of the fitting process of neural ODEs in Julia and, thus, allow it to scale to more practical models and data. ",
          "url": "https://pretalx.com/juliacon2019/talk/KGHF7T/",
          "index": 62,
          "speaker": "Elisabeth Roesch"
        },
        {
          "start_datetime": "2019-07-23T15:45:00",
          "end_datetime": "2019-07-23T16:15:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Solving Delay Differential Equations with Julia",
          "text": "Delay differential equations (DDEs) are used to model dynamics with inherent time delays in different scientific areas; however, solving them numerically in an efficient way is hard. This talk demonstrates how the DifferentialEquations ecosystem allows to solve even complicated DDEs with a variety of different numerical algorithms. Time delays are an inherent part of many dynamical systems in different scientific areas such as biology, physiology, chemistry, and control theory, suggesting to model these systems with delay differential equations (DDEs), i.e., differential equations including time delays. However, solving DDEs numerically in an efficient way is hard. In my talk I present  DelayDiffEq.jl , a Julia package for solving DDEs. I show how it integrates into the DifferentialEquations ecosystem and makes use of the large number of numerical algorithms in  OrdinaryDiffEq.jl  for solving ordinary differential equations. ",
          "url": "https://pretalx.com/juliacon2019/talk/H7TZTT/",
          "index": 63,
          "speaker": "David Widmann"
        },
        {
          "start_datetime": "2019-07-23T17:15:00",
          "end_datetime": "2019-07-23T17:25:00",
          "duration": 10,
          "location": "Elm B",
          "title": "HydroPowerModels.jl: A Julia/JuMP Package for Hydrothermal economic dispatch Optimization",
          "text": "HydroPowerModels.jl  is a Julia/JuMP package for Hydrothermal Multistage Steady-State Power Network Optimization solved by Stochastic Dual Dynamic Programming (SDDP). The objective of this work is to build an open source tool for hydro-thermal dispatch that is flexible enough for the electrical sector to test new ideas in an agile and high-level way, but at the same time using the state-of-the-art implementations of both the SDDP and the dispatch model formulations. For this, we will take advantage of the julia language and the packages, also open-source, which implement the power flow of the electrical dispatch and the Stochastic Dual Dynamic Programming (SDDP), called respectively  PowerModels.jl  and  SDDP.jl . The hydrothermal dispatch problem is very important for the planning and operation of the electrical system, especially for the Brazilian system. It is composed of an optimization problem in which the generation of generators, energy distribution and hydro storage management are coordinated in order to minimize cost of operation. Often, this problem is formulated with the Multi-stage Stochastic optimization framework, where decisions are taken for various periods and in the presence of uncertainties, since the generation resources are limited and often shared inter-temporally. Solving Multi-stage Stochastic optimization is a challenging numerical problem. Therefore, these are commonly solved by a methodology based on the approximation of the bellman equation of stochastic dynamic programming by a piecewise linear function, called Stochastic Dual Dynamic Programming (SDDP). This methodology is preferred because it avoids the high dimensionality of present in classical stochastic dynamic programming. The objective of this work is to build an open source tool for Hydrothermal Multistage Steady-State Power Network Optimization solved by Stochastic Dual Dynamic Programming (SDDP). Problem Specifications and Network Formulations are handled by  PowerModels.jl . Solution method is handled by  SDDP.jl . The talk will constitute of: (i) An overview of the package; (ii) A brief description of the dependent packages and their integration; (iii) Quick example of the package's usage. ",
          "url": "https://pretalx.com/juliacon2019/talk/BXYJ8D/",
          "index": 64,
          "speaker": "Andrew Rosemberg"
        },
        {
          "start_datetime": "2019-07-24T15:45:00",
          "end_datetime": "2019-07-24T17:45:00",
          "duration": 120,
          "location": "Elm B",
          "title": "Raising Diversity & Inclusion among Julia users",
          "text": "This session aims at discussing/showcasing our experience promoting diversity and inclusion in the US, Brazil, Chile and online, with the help of the Julia Computing Diversity & Inclusion Award, funded by the Sloan Foundation. Diversity of users is fundamental for the development of an open language such as Julia. Because it is a young, but very promising programming language, the promotion of working groups that foster the spread of its usage among users from different regions, backgrounds, ages, and social contexts can shed light on bugs and potential growth because of the different perspectives brought with diversity. The Julia Computing Diversity & Inclusion Award funded five projects aimed at promoting the usage of Julia Language with different approaches, in different regions of the planet. In this session, we will share our experience in our projects, talking about how we planned, executed and evaluated the outcomes, and what we learned. For more information about individual projects funded,  see here . ",
          "url": "https://pretalx.com/juliacon2019/talk/GRZZBA/",
          "index": 65,
          "speaker": "Anna Harris, Elwin van 't Wout, Kevin S Bonham"
        },
        {
          "start_datetime": "2019-07-25T16:45:00",
          "end_datetime": "2019-07-25T17:15:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Soss.jl: Probabilistic Metaprogramming in Julia",
          "text": "This talk will explore the basic ideas in Soss, a new probabilistic programming library for Julia. Soss allows a high-level representation of the kinds of models often written in PyMC3 or Stan, and offers a way to programmatically specify and apply model transformations like approximations or reparameterizations. Probabilistic programming is sometimes referred to as “modeling for hackers”, and has recently been picking up steam with a flurry of releases including Stan, PyMC3, Edward, Pyro, and Tensorflow Probability. As these and similar systems have improved in performance and usability, they have unfortunately also become more complex and difficult to contribute to. This is related to a more general phenomenon of the “two language problem”, in which performance-critical domain like scientific computing involve both a high-level language for users and a high-performance language for developers to implement algorithms. This establishes a kind of wall between the two groups, and has a harmful effect on performance, productivity, and pedagogy. In probabilistic programming, this effect is even stronger, and it’s increasingly common to see three languages: one for writing models, a second for data manipulation, model assessment, etc, and a third for implementation of inference algorithms. Solving this “three-language problem” usually means accepting either lower performance or a restricted class of available models and inference algorithms. It doesn’t have to be this way. The Julia language supports Python-level coding with C-level performance. In Julia, Julia’s own code is “first-class”: code can be pulled apart and manipulated as a data structure. This leads to an approach for high-level representation of models, with transformations and optimizations specific to a given model or inference family. This is the approach taken in Soss, a small and extensible Julia library that provides a way to represent and manipulate probabilistic models. In this talk, we’ll discuss the need and for Soss, some of its concepts at a high level, and finally some recent advancements and upcoming opportunities. ",
          "url": "https://pretalx.com/juliacon2019/talk/GBWC9F/",
          "index": 66,
          "speaker": "Chad Scherrer"
        },
        {
          "start_datetime": "2019-07-25T15:45:00",
          "end_datetime": "2019-07-25T16:15:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Turing: Probabalistic Programming in Julia",
          "text": "Turing is a probabilistic programming language written in Julia. This talk will introduce Turing and its tooling ecosystem, as well as go over some introductory tutorials. During the course of the talk, I will introduce Turing's modeling syntax, some typical workflows, and examples of how Turing integrates with notable Julia packages such as Flux.jl or DifferentialEquations.jl. Additionally, I hope to present the status on some of the Julia Summer of Code projects, which may include Variational Inference or greater Gaussian processes integration with Stheno.jl, among others. ",
          "url": "https://pretalx.com/juliacon2019/talk/MA9N8R/",
          "index": 67,
          "speaker": "Cameron Pfiffer"
        },
        {
          "start_datetime": "2019-07-23T14:30:00",
          "end_datetime": "2019-07-23T15:00:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Generating documentation: under the hood of Documenter.jl",
          "text": "Documenter compiles docstrings, code snippets, and Markdown pages into HTML or PDF documents and can automatically deploy them as websites, making it easy to create manuals for Julia packages that are immediately available to users. This talk explores what goes into making all of that happen. Documenter can take Markdown files and inline docstrings and combine them into a manual for your Julia package. In addition, it can also run code snippets, verify that the output from code examples is up to date (doctesting) and upload the manual automatically to GitHub from a Travis CI build to be published as a website. Documenter is used by many Julia packages, and for generating Julia's own manual. Behind the scenes, Documenter needs to (1) parse and represent Markdown documents, done via the Markdown standard library, (2) run code snippets embedded in the Markdown documents, (3) work with meta-information about functions and types, such as method signatures, and (4) fetch docstrings from your Julia code. Once all that is done, it compiles the result into the chosen output format -- a set of HTML pages or a PDF document. The talk explores how Documenter goes from a make.jl script to a completely rendered and deployed manual. It should give existing users a glance into how Documenter works, but also provide a thorough overview of what is possible with Documenter to prospective new users. ",
          "url": "https://pretalx.com/juliacon2019/talk/TTBU37/",
          "index": 68,
          "speaker": "Morten Piibeleht"
        },
        {
          "start_datetime": "2019-07-23T15:10:00",
          "end_datetime": "2019-07-23T15:20:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Let's Play Hanabi!",
          "text": "Games have been testbeds for Artificial Intelligence research for a long time. Here I will demonstrate how to play the fantastic  Hanabi card game  interactively in Julia REPL. Furthermore, I will introduce how to implement some state-of-the-art learning algorithms in pure Julia. Hanabi is a card game for two to five players. What makes Hanabi special is that, unlike most card games, players can only see their partners' hands, and not their own. In this talk, I will focus on the following three parts: A short introduction to Hanabi and how to implement the game in a client-server style in Julia. The challenges of Hanabi and some typical approaches. The implementation details of some state-of-the-art algorithms. I hope this talk can arouse the interest of the audiences. And get more people involved in the reinforcement learning field in Julia. ",
          "url": "https://pretalx.com/juliacon2019/talk/8T3FVZ/",
          "index": 69,
          "speaker": "Jun Tian"
        },
        {
          "start_datetime": "2019-07-24T11:00:00",
          "end_datetime": "2019-07-24T11:30:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Probabilistic Biostatistics: Adventures with Julia from Code to Clinic",
          "text": "Physician scientists conducting clinical trials are typically not statisticians or computer scientists. Perhaps, in a perfect world, they would be, or more realistically could have statisticians and computer scientists on their research team, but that is often not the case. This leads to what we refer to as the “two-field problem.”  Physician-researchers require sophisticated and powerful statistical tools to address complex inferential problems, yet these tools must be intuitive and user-friendly enough not to require advanced statistical knowledge and programming skills.  Using Julia, we illustrate the application of Bayesian probabilistic biostatistics to meta-analyses of treatment effects and clinical trials.  This combination of Julia and Bayesian methods provides a solution to the “two-field problem.” We know that Julia solves the “two-language problem”: it is both fast and efficient (performance), and easy to use (user friendliness).  Using Julia combined with the Bayesian MCMC machinery can solve what we call “the two field problem” in clinical trials, which is that clinical researchers need expertise in more than one field.   Medical research - including clinical trials - is frequently conducted by physician researchers who have limited training in inferential statistics and computer programming.  Typically, clinical research teams will have a biostatistician, though this may be an MS level individual who performs pre-specified “off the shelf” analyses, and generally is not someone well-versed in Bayesian inferential tools. The prevalence of “five percentitus,” i.e. looking only for and reporting p-values that are “statistically significant” (p<0.05), testifies to this fact. The advances in computing power and capabilities in the last several decades, along with the subsequent developments in Bayesian computational methods, are only just beginning to have an impact on this. As those conducting and funding clinical RCTs recognize the high costs of these studies (e.g., medication expense, time required, and potential exposure of patients to ineffective treatments), there has been greater enthusiasm for (1) improving statistical analytic methods for RCTs, and 2) using evidence-based methods to examine existing naturalistically-collected clinical data to inform clinical practice without the need for RCTs.  These approaches require far greater statistical and programming knowledge and sophistication from users.  Thus, there is an urgent need to provide statistical tools to clinician-researchers that are intuitive and easy to use, yet sophisticated and powerful enough “under the hood” to answer questions that simpler methods cannot. The “Bayesian machinery” of Markov chain Monte Carlo (MCMC) methods together with Julia offer a solution to this “two-field problem”. They enable exact small sample inference and hypothesis testing for complex models without requiring the restrictive assumptions necessary to obtain analytical tractability (performance), and facilitate the analysis of complex models with basic statistical concepts: frequency distributions, density plots, means, medians, modes, standard deviations, quantiles, and posterior odds (user friendliness). The talk will demonstrate application of this approach using examples from our own research that illustrate our experiences with Bayesian inferential methods for clinical research using Julia.  [the number and detail of examples will be modified to suit the length of the talk]. •   Reevaluating the evidence from previously conducted RCTs. \n•   Analysis of abandoned trials. \n•   Joint evaluation of tolerability and efficacy in RCTs. \n•   Bayesian hierarchical modeling for meta-analysis evaluating adverse events (“side effects”) in trial participants,  \n        and examining the difference between industry and federally sponsored randomized controlled trials. ",
          "url": "https://pretalx.com/juliacon2019/talk/M8UDFK/",
          "index": 70,
          "speaker": "Jeff Mills"
        },
        {
          "start_datetime": "2019-07-23T17:25:00",
          "end_datetime": "2019-07-23T17:35:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Modeling in Julia at Exascale for Power Grids",
          "text": "The ExaSGD (Optimizing Stochastic Grid Dynamics at Exascale) application is part of the Department of Energy's Exascale project (ECP). The dawn of renewable energies poses a great challenge to long-term planning with higher uncertainties, not only in the grid load, but also in the energy generation. The goal of this project is to provide policy planners and grid operators with cost effective long term planning solutions that are protected against uncertainties in the grid operation. This talk gives an overview of our implementation and where we leverage Julia's unique capabilities to  make efficient use of the upcoming exascale hardware, while giving engineers a flexible modeling language. ",
          "url": "https://pretalx.com/juliacon2019/talk/JAXM9R/",
          "index": 71,
          "speaker": "Michel Schanen"
        },
        {
          "start_datetime": "2019-07-25T11:40:00",
          "end_datetime": "2019-07-25T11:50:00",
          "duration": 10,
          "location": "Elm A",
          "title": "A case study of migrating Timelineapp.co to the Julia language",
          "text": "Timelineapp.co  is an on-line platform for financial planners. Recently its core compute engine has been migrated to the Julia language. In this talk we discuss the reasons and benefits of this decision. Timelineapp.co  is a platform that supports financial planners in analysis of different retirement income strategies. It interactively allows a user to specify the desired retirement income management plan and performs its backtesting to verify its profitability and risk profile. It shows the impact of asset allocation decisions, rebalancing, fees, and taxes and it prepares clients for market ups and downs. The legacy development process at Timelineapp was that quantitative analysts specified application logic using Matlab and next software developers translated it to Elixir code that was deployed to production. As the application complexity increased, even trying to squeeze out maximum performance from the legacy technology stack, the team faced the challenge that the response time per one financial scenario backtesting query would grow up to around 40 seconds. This was clearly not acceptable for an on-line application. Facing performance bottleneck  the team researched different alternatives, did some benchmarks, and picked Julia. After migrating the code, it was possible to cut the time to response down to 0.6 second per query. Another benefit of moving to Julia was a dramatic simplification of the development process. In the past Matlab code had to be translated to Elixir. That was quite cumbersome and many times things got lost in translation from one programming language to the other. Now both, the quantitative analysts and the developers, write Julia. This way the code has less bugs and the time from idea and experimental calculations (by the quantitative analysts team) to deployment to production (by the software development team) is much shorter and agile. ",
          "url": "https://pretalx.com/juliacon2019/talk/YPGRDD/",
          "index": 72,
          "speaker": "Bogumił Kamiński"
        },
        {
          "start_datetime": "2019-07-24T11:50:00",
          "end_datetime": "2019-07-24T12:00:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Mining Imbalanced Big Data with Julia",
          "text": "Machine learning for data Mining applications in imbalanced big data classification is very challenging task. In this talk, we have proposed a new cluster-based under-sampling approach with ensemble learning for mining real-life imbalanced big data in Julia. In this era of big data, classifying imbalanced real-life data in supervised learning is a challenging research issue. Standard data sampling methods: under-sampling, and over-sampling have several limitations for dealing with big data. Mostly, under-sampling approach removes data points from majority class instances and over-sampling approach engenders artificial minority class instances to make the data balanced. However, we may lose informative information/ instances using under-sampling approach, and under other conditions over-sampling approach causes overfitting problem. In this talk, we have presented a new cluster-based under-sampling approach by amalgamating ensemble learning (e.g. RandomForest classifier) for classification of imbalanced data that we implemented in Julia. We have collected actual illegal money transaction telecom fraud data, which is highly imbalanced with only 8,213 minority class instances amount 63,62,620 instances. The proposed method bifurcates the data into majority class and minority class instances. Then, clusters the majority class instances into several clusters and considers a set of instances from each cluster to create several sub-balanced datasets. Finally, a number of classifiers are generated using these balances datasets and apply majority voting technique for classifying unknown/ new instances. We have tested the proposed method on separate test dataset that achieved 97% accuracy. ",
          "url": "https://pretalx.com/juliacon2019/talk/HBBG8N/",
          "index": 73,
          "speaker": "Swakkhar Shatabda, Dewan Md. Farid"
        },
        {
          "start_datetime": "2019-07-25T15:45:00",
          "end_datetime": "2019-07-25T16:15:00",
          "duration": 30,
          "location": "Elm A",
          "title": "Efficient Stiff Ordinary Differential Equation Solvers for Quantitative Systems Pharmacology (QsP)",
          "text": "QsP is a sophisticated and effective way to predict the interaction between drugs and the human body, however, simulating QsP models can take a long time because of the intrinsic stiffness in transient chemical reactions. Here we take a deep look at the efficiency of various stiff ordinary differential equation solvers in the JuliaDiffEq ecosystem applied to QsP models, and utilize benchmarks to summarize how the ecosystem is progressing and what kinds of advances we can expect in the near future. The solution of the stiff ordinary differential equation (ODE) systems resulting from QsP models is a rate-limiting step in large-scale population studies. Here we review the ongoing efficiency developments within the JuliaDiffEq numerical differential equation solver ecosystem with a focus on ODEs derived from QsP models. These models have specific features that can be specialized in order to gain additional efficiency in the integration, such as their small size (normally <500 ODEs), frequent dosing events, and multi-rate behaviors. We demonstrate how new implementations of high order Rosenbrock methods with PI-adaptive time stepping, exponential propagation iterative methods (EPRIK) with adaptive Krylov expmv calculations, and implicit-explicit singly diagonally implicit Runge-Kutta methods (IMEX SDIRK) can be advantageous over classical schemes like LSODA and Sundials CVODE on these types of models and discuss the future directions. ",
          "url": "https://pretalx.com/juliacon2019/talk/J39LVP/",
          "index": 74,
          "speaker": "Yingbo Ma"
        },
        {
          "start_datetime": "2019-07-23T16:45:00",
          "end_datetime": "2019-07-23T17:15:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Scientific AI: Domain Models with Integrated Machine Learning",
          "text": "Modeling practice seems to be partitioned into scientific models defined by mechanistic differential equations and machine learning models defined by parameterizations of neural networks. While the ability for interpretable mechanistic models to extrapolate from little information is seemingly at odds with the big data \"model-free\" approach of neural networks, the next step in scientific progress is to utilize these methodologies together in order to emphasize their strengths while mitigating weaknesses. In this talk we will describe four separate ways that we are merging differential equations and deep learning through the power of the DifferentialEquations.jl and Flux.jl libraries. Data-driven hypothesis generation of model structure, automated real-time control of dynamical systems, accelerated of PDE solving, and memory-efficient deep learning workflows will all shown to be derived from this common computational structure of differential equations mixed with neural networks. The audience will leave with a new appreciation of how these two disciplines can benefit from one another, and how neural networks can be used for more than just data analysis. Dynamical models are often interesting due to the high-level qualitative behavior that they display. Differential equation descriptions of fluids accurately predict when drone flight will go unstable, and stochastic evolution models demonstrate the behavior for how patterns may suddenly emerge from biological chemical reactions. However, utilizing these models in practice requires the ability to understand, prediction, and control these outcomes. Traditional nonlinear control methods directly tie the complexity of the simulation to the control optimization process, making it difficult to apply these methods in real-time to highly detailed but computationally expensive models.  \nIn this talk we will show how to decouple the computation time of a model from the ability to predict and control its qualitative behavior through a mixture of differential equation and machine learning techniques. These new methods directly utilize the language-wide differentiable programming provided by Flux.jl to perform automatic differentiation on differential equation models described using DifferentialEquations.jl. We demonstrate an adaptive data generation technique and show that common classification methods from machine learning literature converge to >99% accuracy for determining qualitative model outcomes directly from the parameters of the dynamical model. Using a modification of methods from Generative Adversarial Networks (GANs), we demonstrate an inversion technique with the ability to predict dynamical parameters that meet user-chosen objectives. This method is demonstrated to be able to determine parameters which constrains predator-prey models to a specific chosen domain and predict chemical reaction rates that result in Turing patterns for reaction-diffusion partial differential equations. Code examples will be shown and explained to directly show Julia users how to do these new techniques. Together, these methods are scalable and real-time computational tools for predicting and controlling the relation between dynamical systems and their qualitative outcomes with many possible applications. ",
          "url": "https://pretalx.com/juliacon2019/talk/QJAUAT/",
          "index": 75,
          "speaker": "Chris Rackauckas"
        },
        {
          "start_datetime": "2019-07-23T11:00:00",
          "end_datetime": "2019-07-23T12:00:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Dynamical Modeling in Julia",
          "text": "A lot of people are building tooling for differential equation based models in Julia for various domains. DifferentialEquations.jl, DynamicalSystems.jl, PuMaS.jl, Modia.jl, QuantumOptics.jl, etc. and the list goes on. The purpose of this BoF is to gather the developers who are interested in this topic in order to learn about the priorities and gripes within the community in order to plan for the next developments. Many different aspects of dynamical modeling in Julia have seen a recent boom in popularity. A lot of package development focus has been given to the tooling for simulating dynamical models, such as the differential equation solvers of DifferentialEquations.jl and the relevant underlying pieces like IterativeSolvers.jl and NLsolve.jl. In addition, a community of domain-specific modeling tools such as DynamicalSystems.jl, Modia.jl, PuMaS.jl, QuantumOptics.jl, and more than can be listed have all built their own user bases.  The purpose of this BoF is to gather the developers of these related tooling to discuss the current state of the ecosystem and develop plans and priorities for next steps. A quick overview of the package space and its recent developments will be given to frame the conversion, with most of the time dedicated to discussion. Possible topics include (but are not limited to) understanding the domains most in need of new and more performant solvers, the utilization of parallelism (multithreading, multiprocessing, and GPu), incorporating symbolic tooling such as ModelingToolkit.jl, and the commonalities of analysis tooling (such as parameter estimation, neural network integration, uncertainty propagation). We invite developers within the community to express their feedback and help guide our next moves within the package space. ",
          "url": "https://pretalx.com/juliacon2019/talk/Q8KE7A/",
          "index": 76,
          "speaker": "Chris Rackauckas"
        },
        {
          "start_datetime": "2019-07-23T16:45:00",
          "end_datetime": "2019-07-23T16:55:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Targeting Accelerators with MLIR.jl",
          "text": "MLIR is a flexible compiler infrastructure with an open ecosystem of dialects, built for a world of increasingly heterogeneous hardware. With its support for metaprogramming and extensible JIT compiler, Julia is well-positioned as a frontend language for the MLIR stack. ",
          "url": "https://pretalx.com/juliacon2019/talk/3YBZLC/",
          "index": 77,
          "speaker": "James Bradbury"
        },
        {
          "start_datetime": "2019-07-25T14:30:00",
          "end_datetime": "2019-07-25T15:00:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Mimi.jl – Next Generation Climate Economics Modeling",
          "text": "We will present Mimi.jl, a next generation platform for Integrated Assessment Modelling widely used in climate economics research. The talk will outline technical aspects of the platform, as well as its adoption and impact both on research at universities and in the US federal climate regulation process. In 2016, the EPA commissioned a report from the National Academy of Sciences on research priorities for improving and updating the Social Cost of Carbon, a metric used by the federal government to account for the impacts of climate change within regulatory impact analyses. One central recommendation from the ensuing National Academies  report  was to create a common, modular computational platform to better serve modelling work in this area. Our team created the leading (and probably only) implementation following this call to action: the  Mimi Framework . Mimi.jl is entirely implemented in Julia. This talk will present this computational platform, discuss its application, and dive into key design considerations. The main design constraints for Mimi.jl were that we needed something:  \na) computationally fast, \nb) simple enough that a lack of significant programming experience is not a barrier for users, \nc) that enables a modular work style for distributed, loosely coordinated teams, and  \nd) that creates a transparent framework enabling easy replication of computational experiments. We will describe in some detail how we achieved this design using a macro based domain specific language for certain parts of the framework, while at the same time exposing the full power of the Julia language to users. We will also touch on our use of a custom Julia registry as the repository for different modules that different groups can work on, allowing us to use Julia’s package manager to solve the replication problem for computational experiments. We will also discuss a large number of specific design decisions that helped us make the system easy to use for novice programmers. We will conclude the talk with a discussion of adoption and impact of this platform. We will outline how different groups at a number of leading universities and think tanks have adopted the platform for their work and outline why we believe it will power the next generation of the US federal climate economics work in the regulatory space going forward. ",
          "url": "https://pretalx.com/juliacon2019/talk/ZE9AVH/",
          "index": 78,
          "speaker": "David Anthoff, Lisa Rennels, Cora Kingdon"
        },
        {
          "start_datetime": "2019-07-25T11:00:00",
          "end_datetime": "2019-07-25T11:30:00",
          "duration": 30,
          "location": "Room 349",
          "title": "The Unreasonable Effectiveness of Multiple Dispatch",
          "text": "If you're familiar with Julia and its ecosystem, you may have noticed something lovely but a bit puzzling: there seems to be an unusually large amount of code reuse between packages compared to other seemingly similar languages. This sharing of code comes in two forms: Sharing basic types among a wide variety of packages providing disparate functionality; Sharing generic algorithms that work on various implementations of common abstractions. Why does generic code in Julia \"just work\"? Why do Julia packages seem to share types with so little friction? Both kinds of reuse are supposed to be natural benefits of class-based object-oriented languages. After all, inheritance and encapsulation are two of the four pillars of OOP. Even more puzzling is that Julia has no encapsulation and doesn't allow inheriting from concrete types at all. Yet both kinds of code reuse are rampant. What is going on? In this talk, I make the case that both of kinds sharing stem directly from Julia's multiple dispatch programming paradigm. The former kind of sharing of types stems from the external nature of multiple dispatch: the source of many problems in class-based OOP is that methods have to live \"inside of\" classes. Simply by associating methods with generic functions rather than the type that they operate on, multiple dispatch avoids many of the problems that OOP has. The latter kind of sharing stems from the ability to correctly choose specialized code based on the types of all arguments of a function. There are patterns like double dispatch to try to deal with this in single dispatch languages, but they are cumbersome, brittle and opt-in, meaning that unless someone else planned for you to extend their code, you are unlikely to be able to do so. ",
          "url": "https://pretalx.com/juliacon2019/talk/BCYWZJ/",
          "index": 79,
          "speaker": "Stefan Karpinski"
        },
        {
          "start_datetime": "2019-07-25T14:30:00",
          "end_datetime": "2019-07-25T15:00:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Writing maintainable Julia code",
          "text": "How to use abstractions to write code that will be easy to follow and change while also not significantly impacting performance Have you ever updated an algorithm's code just to find that the algorithm has changed in unexpected ways? Have you ever started coding an algorithm just to think to yourself that you had already done something extremely similar for a different algorithm? These problems are often the case because code is not broken down into clear conceptual components that are independent from one another and easy to reuse. To illustrate how this can be accomplished we will walk through the implementation of three highly similar iterative eigenvalue/eigenvector algorithms. It will be shown that each of the three iterative algorithms consists of the same main conceptual components which will be extracted into a single method used by all three iterative algorithms. The result will be code that is easy to follow at a high level because breaking it into high level conceptual components will make it easier to read and follow. Changes will also be easier to make because finding the correct area of the code to change will be easier and there will be less risk of unexpected side effects because the other components should be independent. Finally some discussion will be made about the performance implications of introducing more abstractions and how if the abstractions are kept at the higher levels of the algorithms code it is highly unlikely that performance will be significantly impacted. ",
          "url": "https://pretalx.com/juliacon2019/talk/J779CB/",
          "index": 80,
          "speaker": "Scott Haney"
        },
        {
          "start_datetime": "2019-07-23T17:05:00",
          "end_datetime": "2019-07-23T17:15:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Generic Sparse Data Structures on GPUs",
          "text": "Sparse linear operators that arise from structured grids often tend to have rich structure. We present a feature rich yet simple DIAgonal format (DIA), which also supports blocked and GPU arrays, as well as Algebraic Multigrid (AMG) preconditioners. We present this rich framework of tools to solve large oil reservoir simulations. Sparse matrices arising from structured grids generally possess rich structure, which is amenable to GPU-parallelism. We implemented the DIA format, one of the most primitive sparse matrix storage formats, in Julia. BLAS routines are implemented on DIA format with GPU using  CUDAnative.jl  and  CuArrays.jl . We also present Geometric Multigrid(GMG) preconditioner, implemented on GPU using DIA format and solve large ill-conditioned systems. Julia allows users to write generic code, which allows us to exploit blocked structure that arises from higher degrees of freedom. We benchmark and verify against the SPE10 problem, a standard oil reservoir simulation benchmark. ",
          "url": "https://pretalx.com/juliacon2019/talk/BXVHJV/",
          "index": 81,
          "speaker": "Ranjan Anantharaman, Sungwoo Jeong"
        },
        {
          "start_datetime": "2019-07-24T15:45:00",
          "end_datetime": "2019-07-24T17:45:00",
          "duration": 120,
          "location": "Elm A",
          "title": "Polynomial and Moment Optimization in Julia and JuMP",
          "text": "Polynomial and moment optimization problems are infinite dimensional optimization problems that can model a wide range of problems in engineering and statistics. In this minisymposium we show how the Julia and JuMP ecosystems are particularly well suited for the effortless construction of these problems and the development of state-of-the-art solvers for them. Polynomial and moment optimization problems are infinite dimensional optimization problems that can model a wide range of problems such as shape-constrained polynomial regression, optimal control of dynamical systems, region of attraction, polynomial matrix decomposition, smooth maximum-likelihood density estimation, AC power systems, experimental design, and computation of Nash equilibria. In this minisymposium we show how the  Julia  and  JuMP  ecosystems are particularly well suited for constructing and solving these problems. In particular, we show how the JuMP extensions  SumOfSquares / PolyJuMP  allow for an effortless construction of these problems and how they provide a flexible and customizable building block for additional packages such as JuliaMoments. We also show how various features of the Julia programming language are used in the state-of-the-art solvers Hypatia.jl and Aspasia.jl. Finally, we showcase specific uses of these tools for applications in engineering and statistics. ",
          "url": "https://pretalx.com/juliacon2019/talk/QZBKAU/",
          "index": 82,
          "speaker": "Tillmann Weisser, Benoît Legat, Chris Coey, Lea Kapelevich, Juan Pablo Vielma"
        },
        {
          "start_datetime": "2019-07-24T15:00:00",
          "end_datetime": "2019-07-24T15:30:00",
          "duration": 30,
          "location": "Elm A",
          "title": "OmniSci.jl: Bringing the open-source, GPU-accelerated relational database to Julia",
          "text": "OmniSci (formerly MapD) is an open-source relational database built from the ground-up to run on GPUs, providing millisecond query speed on multi-billion row datasets. This talk presents OmniSci.jl, the database client for OmniSci written completely in Julia and a basic demonstration of using OmniSci and Julia together, with the aim of encouraging community collaboration on GPU accelerated analytics. For this talk, I will highlight the work-to-date in bringing the functionality of OmniSci to Julia, and how all of the work of others on packages for geospatial, decimal support, Thrift and Apache Arrow make OmniSci.jl  possible. Specifically, I will discuss: Why OmniSci and Julia are a great fit (performance, LLVM) Connecting to OmniSci from Julia Performing basic queries in millisecond speed Future work towards end-to-end analytics on the GPU in Julia ",
          "url": "https://pretalx.com/juliacon2019/talk/MHUAX7/",
          "index": 83,
          "speaker": "Randy Zwitch"
        },
        {
          "start_datetime": "2019-07-25T15:00:00",
          "end_datetime": "2019-07-25T15:30:00",
          "duration": 30,
          "location": "Elm B",
          "title": "The Climate Machine: A New Earth System Model in Julia",
          "text": "We are using Julia to develop the first Earth System Model that automatically learns from diverse data sources. The  Climate Modeling Alliance (CliMA)  aims to build the first Earth system model that automatically learns from both Earth observations and embedded high-resolution simulations. The goal is to build a more accurate climate model with quantified uncertainties.  High computational performance on heterogeneous architectures, including CPUs, GPUs, and distributed computing architectures is essential for the project. The model is being developed in Julia to ensure portable performance at supercomputing scales for this ambitious scientific computing project. This talk will give an overview of the project and its motivation. We will highlight how we’re pushing Julia to scale, including lessons learnt and challenges we are facing. ",
          "url": "https://pretalx.com/juliacon2019/talk/FXBCLP/",
          "index": 84,
          "speaker": "Charlie Kawczynski, Simon Byrne"
        },
        {
          "start_datetime": "2019-07-25T16:55:00",
          "end_datetime": "2019-07-25T17:05:00",
          "duration": 10,
          "location": "Elm A",
          "title": "IVIVC.jl: In vitro – in vivo correlation module as part of an integrated pharmaceutical modeling and simulation platform",
          "text": "IVIVC.jl is a state of the art package for predictive mathematical modelling which correlates in vitro property (rate of drug dissolution) and in vivo response (plasma drug concentration profile). An IVIVC is meant to serve as a surrogate for in vivo bioavailability. This relationship can guide product development and support biowaivers. IVIVC.jl pipelines input bio-data to an IVIVC model with validations and it involves mathematical modelling, optimization and data visualisation accelerated with Julia. In this talk, I will introduce IVIVC.jl, a state of the art package for pharmaceutical modelling and simulation-based in Julia. In the core, IVIVC.jl uses Optim.jl as optimization library to model the in-vitro data and then correlates the model with deconvoluted in vivo data. This package establishes three levels (A, B and C) of in vitro-in vivo correlation (IVIVC). IVIVC is the relationship between parameter derived from a pharmacokinetic property produced by a dosage form and a physicochemical property of the same dosage form. The pharmacokinetic properties include maximum plasma concentration (Cmax) or area under the plasma concentration-time curve (AUC). When an IVIVC correlation is established, it is used for development and optimization of drug formulations. \nUsing IVIVC.jl, one can accelerate drug development and can introduce a drug in the market faster. IVIVC can be used to substitute human bioequivalence studies in the initial approval process, the scale-up process, and the post-approval changes. This project is under the University of Maryland, Baltimore and the authors are me, Jogarao Gobburu and Vijay Ivaturi. ",
          "url": "https://pretalx.com/juliacon2019/talk/9BRTVV/",
          "index": 85,
          "speaker": "Shubham Maddhashiya"
        },
        {
          "start_datetime": "2019-07-25T11:30:00",
          "end_datetime": "2019-07-25T11:40:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Julia web servers deployment",
          "text": "We present our experience in deploying Julia web servers in production systems. We developed a custom buildpack that facilitates deploying web servers on Heroku. It is built so that any application requires almost no special code to be deployed. Julia web servers deployment To deploy Julia web servers easily, we developed an open-source buildpack which is available on  https://github.com/Optomatica/heroku-buildpack-julia . \nIt just requires  Project.toml  and  Manifest.toml  in the root of the repository to be pushed and it automatically download dependencies and make the server available on  Heroku . \nIt also precompiles all dependencies for speedy server boot time.  We will present our experience in making this buildpack and how we optimized it so that the web server boot time is minimized. We compare its performance with having a docker instance and it outperforms having a docker image and it requires less maintenance overhead than having a docker image. This can help many Julia users deploying web servers in no time. ",
          "url": "https://pretalx.com/juliacon2019/talk/L983HR/",
          "index": 86,
          "speaker": "Mohammed El-Beltagy, Amgad Naiem"
        },
        {
          "start_datetime": "2019-07-25T11:00:00",
          "end_datetime": "2019-07-25T12:00:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Performant parallelism with productivity and portability.",
          "text": "This BoF will be a forum to discuss the state of the state around performant parallelism for distributed memory programming in Julia. Performance, parallelism, productivity and portability are four P's of distributed memory parallelism that over the last 30 years have proved hard to satisfy simultaneously in a general solution. The goal of this BoF is discussion and exploration of approaches for providing performant distributed memory parallelism in Julia in ways that are portable and that reflect the productivity vision of Julia. The format will consist of a series of presentations and a discussion/Q&A section. It will look both within Julia and across other languages at the last 30 years of efforts in this space. The motivation for the BoF is that meeting the four P's well remains an unsolved problem. For now projects that seek all of performance, parallelism at scale, portability and productivity typically have to make compromises in one or more of these areas. The hoped for outcome is some shared momentum and sharing of ideas for developing Julian approaches that lessen (or eliminate) the need to compromise in any of the four P's in the future. This BoF is motivated in part by interesting new application development efforts that are combining high-performant scientific computing style parallelism with large scale machine learning, optimization and statistical methods. The BoF will focus on current and future directions for language and library level abstractions for large distributed parallel applications in Julia. Some projects such as  Celeste  and  CLiMA  are employing Julia for work that scales to tens of thousands or more parallel cores. The BoF will be a forum for starting conversations and brainstorming how Julia tools for distributed parallelism might evolve in coming years to support both portable, high-performance parallelism and productive interactivity in a relatively unified way. The BoF will include short presentations from current participants in large scale scientific computing parallel efforts using Julia, it will also include short presentations from relevant tool developers as well as an open discussion time for question and answer.  We anticipate covering a few interconnected themes and goals. Blending in new ideas . In the last 30 years, since the emergence of the message passing interface (MPI) parallel library standard for scientific computing, many projects have explored alternate parallelism paradigms. These alternates, which include UPC, X10, CoArray Fortran, Chapel, Hadoop, Spark, OCCA and many others, have introduced new ideas, but in scientific computing none have gained the broad traction of MPI in practice. One topic of interest for this BoF is where can the Julia language, library and meta-programming ecosystem usefully blend in some of the parallel programming ideas that have emerged in academic projects in the last 30 years. Enabling interactivity front and center in large scale, high-performance parallelism . Are there ways Julia might help bring some flavor of productive interactivity to the sorts of applications that have typically leveraged MPI for portable performance. Some debugging tools, from other languages, such as  ddt  and  totalview  may provide models for how to interact explicitly with multiple concurrent streams of computation in a large parallel application under something of a REPL feel. Julia Distributed arrays, Channels and Cluster manager abstractions provide more implicit ways for interacting with parallel computation streams. Using existing components it is already possible to create elaborate applications that mix high-performance parallel simulation and distributed machine learning, for example, in a single workflow. This sort of workflow is emerging in many fields from plasma science to economics.  However, current programming approaches can result in a somewhat complex mix of abstractions that are not always amenable to flexible and agile exploration in an interactive environment of the sort that is Julia's hallmark. Catalyzing activities to discover the right APIs . The BoF will aim to catalyze conversations and energize projects looking at the next generation of Julia ecosystem tools to support high-performance, parallel scientific computing. In this realm it is likely that many of the key abstractions/APIs are likely to be discovered somewhat organically as much as designed. The BoF seeks to be inclusive to all Julia projects that may have an interest in these areas. The organizers welcome anyone interested in presenting a slide at the BoF to  contact us . We plan to gather the BoF material into a post meeting document that will be openly available. ",
          "url": "https://pretalx.com/juliacon2019/talk/37VY3Q/",
          "index": 87,
          "speaker": "Andreas Noack, Lucas Wilcox, Alan Edelman, Chris Hill"
        },
        {
          "start_datetime": "2019-07-25T17:05:00",
          "end_datetime": "2019-07-25T17:15:00",
          "duration": 10,
          "location": "Elm A",
          "title": "GigaSOM.jl: Huge-scale, high-performance flow cytometry clustering in Julia",
          "text": "Flow cytometry clustering for several hundred million cells has long been hampered by software implementations. Julia allows us to go beyond these limits. Through the high-performance GigaSOM.jl package, we gear up for huge-scale flow cytometry analysis. Recent advances in single-cell technologies offer an unprecedented opportunity to comprehensively characterize the immune system, revealing a previously unparalleled complexity in the phenotype and function of immune cells. Mass cytometry, also known as CyTOF, was recently implemented to measure up to 40 different markers in several million single cells. A typical clinical study with hundreds of patients can therefore include billions of single cells (rows) and up to 40 markers (features). \nDifferent dimension reduction methods have been implemented in commercial and open-source software, mainly written in R. The machine learning algorithm FlowSOM [1] is based on the famous Kohonen Self Organising Feature Maps (SOM) [2] and has shown various advantages over other methods. \nHowever, all current implementations have a critical limitation on the total number of cells to be analyzed . This limitation often blocks the analysis of large-scale clinical studies with several hundred million cells.  \nHere, we present the open-source, high-level, and high-performance package GigaSOM.jl ( https://github.com/LCSB-BioCore/GigaSOM.jl ), which is HPC-ready and is written to handle very large datasets without limits. Julia is the natural language of choice when it comes to performing huge-scale cytometric analyses. With the GigaSOM.jl package, the possibilities for flow cytometry analysis  are further broadened. The quality of the software package is assured using ARTENOLIS ( https://artenolis.lcsb.uni.lu ) [3]. Biological validation of the results will be performed on downsampled datasets by comparison to conventional implementations of the FlowSOM package and manual hierarchical analysis.  References [1] Sofie Van Gassen, Britt Callebaut, Mary J. Van Helden, Bart N. Lambrecht, Piet Demeester, Tom Dhaene and Yvan Saeys. FlowSOM: Using self-organizing maps for visualization and interpretation of cytometry data. Cytometry A 2015, volume 87.7 (p. 636-645) \n[2] Kohonen T. The self-organizing map. Proc IEEE 1990;78:1464–1480 \n[3] Heirendt, Laurent; Arreckx, Sylvain; Trefois, Christophe; Yarosz, Yohan; Vyas, Maharshi; Satagopam, Venkata P.; Schneider, Reinhard; Thiele, Ines; Fleming, Ronan M. T., ARTENOLIS: Automated Reproducibility and Testing Environment for Licensed Software, arXiv:1712.05236. ",
          "url": "https://pretalx.com/juliacon2019/talk/9UWDLY/",
          "index": 88,
          "speaker": "Vasco Verissimo, Laurent Heirendt"
        },
        {
          "start_datetime": "2019-07-24T17:25:00",
          "end_datetime": "2019-07-24T17:35:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Machine Learning for Social Good",
          "text": "Using Julia and Flux.jl, we want to show how we have applied modern neural architectures like Mask RCNN and Inception to identify diseases and slums in metropolitan cities. ML has provided us with the tools to think of data as a source of insight. It isn’t a stretch to apply the same thinking towards some of the most pressing socio economic calamities we as a society are faced with. Mask RCNN is a state of the art object detection and segmentation net that was developed by FAIR and has shown tremendous leaps in terms of segmentation while being conceptually simple. We present an all-Julia Flux implementation of Mask RCNN and our methodology of setting up the segmentation task. We use satellite images of cities and try to identify regions where slums exist. Finally we share our results of our findings. Code: \nThe code is currently private before it is released openly through contributions to various existing projects like the Flux model-zoo and Metalhead.jl. ",
          "url": "https://pretalx.com/juliacon2019/talk/KJ9SGA/",
          "index": 89,
          "speaker": "Dhairya Gandhi"
        },
        {
          "start_datetime": "2019-07-25T16:45:00",
          "end_datetime": "2019-07-25T16:55:00",
          "duration": 10,
          "location": "Elm A",
          "title": "An advanced electrodialysis process model in the Julia ecosystem",
          "text": "Electrodialysis, a prominent technology in the production of drinking water from seawater is modelled using the Julia ecosystem. A framework of partial differential equations and neural networks is solved to model the fouling of this process and to optimise its design and operation. Electrodialysis is a separation technology that uses electric fields and ion-exchange membranes to separate charged components from solutions. Electrodialysis is a highly efficient technology with prominent applications in the production of drinking water from seawater and the recovery and upgrading of various bio-based resources. The majority of physical and electrochemical phenomena are well understood and can be described by mechanistic models. The complex and intricate interplay of various phenomena that occur at the surface of the ion-exchange membranes add an incredible amount of complexity and a mechanistic description is often too difficult. The Julia ecosystem provides a unique opportunity to couple differential equation solvers with machine learning techniques such as neural networks as a hybrid approach to model these kind of systems. Automatic differentation facilitates the optimisation procedure and is interesting from an engineering point of view. ",
          "url": "https://pretalx.com/juliacon2019/talk/7SX9LN/",
          "index": 90,
          "speaker": "Bram De Jaegher"
        },
        {
          "start_datetime": "2019-07-25T14:30:00",
          "end_datetime": "2019-07-25T15:00:00",
          "duration": 30,
          "location": "Elm A",
          "title": "If Runtime isn't Funtime: Controlling Compile-time Execution",
          "text": "\"This block will compile away,\" the comments say.  But will it?  In this talk we'll see some scenarios where controlling compile-time vs runtime execution is crucial for performance, and we'll discuss some ideas that might make this control easier in Julia. Julia's ability to compile away complex logic is remarkable. Especially in recent releases, Const-propagation is a thing to behold! But we've found it can be hard to reason about  why  some operations are compiled away (or why they aren't), and even harder to  control  that behavior. What's more, that behavior can change as your code evolves, or Julia is updated, and it's difficult to test. In Julia, the distinction between compile-time and runtime is deliberately muddy: compilation itself happens  during runtime ; a function may be compiled once, many times or never—it might even be compiled more times than it runs. Still, there are cases where we expect a function to be compiled once, early on, and then need it to run extremely quickly, many times, in a tight loop, where controlling the ability to move work from runtime to compile-time is critical. This talk will explore a few such motivating cases we've seen at  RelationalAI , including in pieces of the  FixedPointDecimals.jl  library. We'll examine the options currently available in Julia for controlling compile-time execution, and their pros and cons, including some lessons-learned about the pain we've experienced with  @generated . We'll study the approach modern C++ is taking to this problem, with its  constexpr  annotation. And we'll propose a few ideas for how we might add features to Julia that could increase our control over this fierce compiler. ",
          "url": "https://pretalx.com/juliacon2019/talk/QXF9AM/",
          "index": 91,
          "speaker": "Nathan Daly"
        },
        {
          "start_datetime": "2019-07-23T15:00:00",
          "end_datetime": "2019-07-23T15:10:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Literate programming with Literate.jl",
          "text": "Literate programming is described as an  explanation of the program logic in a natural language, interspersed with traditional source code .  This presentation will describe how the  Literate.jl  package can be used for literate programming, and show how to generate multiple outputs, such as jupyter notebooks, or markdown pages, based on the same source file. Literate programming was introduced by Donald Knuth in 1984 and is described as an  explanation of the program logic in a natural language, interspersed with traditional source code .  Literate.jl  is a simple Julia package that can be used for literate programming. The original purpose was to facilitate writing example programs for documenting Julia packages. Julia packages are often showcased and documented using \"example notebooks\". Notebooks are great for this purpose since they contain both input source code, descriptive markdown and rich output like plots and figures, and, from the description above, notebooks can be considered a form of literate programming. One downside with notebooks is that they are a pain to deal with in version control systems like git, since they contain lots of extra data. A small change to the notebook thus often results in a large and complicated diff, which makes it harder to review the actual changes. Another downside is that notebooks require external tools, like Jupyter and  IJulia.jl  to be used effectively. With  Literate.jl  is is possible to dynamically generate notebooks from a simple source file. The source file is a regular  .jl  file, where comments are used for describing the interspersed code snippets. This means that, for basic usage, there are no new syntax to learn in order to use  Literate.jl , basically any valid Julia source file can be used as a source file. This solves the problem with notebooks described in the previous section, since the notebook itself does not need to be checked into version control -- it is just the source text file that is needed.  Literate.jl  can also, from the  same  input source file, generate markdown files to be used with e.g.  Documenter.jl  to produce HTML pages in the package documentation. This makes it easy to maintain both a notebook and HTML version of examples, since they are based on the same source file. This presentation will briefly cover the  Literate.jl  syntax, and show examples of how  Literate.jl  can be used. ",
          "url": "https://pretalx.com/juliacon2019/talk/DAKCYM/",
          "index": 92,
          "speaker": "Fredrik Ekre"
        },
        {
          "start_datetime": "2019-07-23T11:00:00",
          "end_datetime": "2019-07-23T11:30:00",
          "duration": 30,
          "location": "Room 349",
          "title": "Pkg, Project.toml, Manifest.toml and Environments",
          "text": "One of the major features of Julia's new package manager is  package environments . This presentation will explain how environments work, what they are useful for and how to use them effectively. Julia's new package manager, Pkg, was released together with version 1.0 of the Julia language. The new package manager is a complete rewrite of the old one, and solves many of the problems observed in the old version. One major feature of the new package manager is the concept of  package environments , which can be described as independent, sandboxed, sets of packages. A package environment is represented by a  Project.toml  and  Manifest.toml  file pair. These files keep track of what packages, and what versions, are available in a given environment. Since environments are \"cheap\", just two files, they can be used liberally. It is often useful to create new environments for every new coding project, instead of installing packages on the global level. Since the package manager modifies the current project, e.g. when adding, removing or updating packages, there is no risk for these operations to mess up other environments. The fact that exact versions of packages in the environment is being recorded means that Julia has reproducibility built-in. As long as the  Project.toml  and  Manifest.toml  file pair is available it is possible to replicate exactly the same package environment. Some typical use cases include being able to replicate the same package environment on a different machine, and being able to go back in time and run some old code which might require some old versions of packages. In this presentation we will discuss how environments work, how they interact with the package manager and Julia's code loading, and how to effectively use them. Hopefully you will be more comfortable working with, and seeing the usefulness of, environments after this presentation. ",
          "url": "https://pretalx.com/juliacon2019/talk/KAMHYJ/",
          "index": 93,
          "speaker": "Fredrik Ekre"
        },
        {
          "start_datetime": "2019-07-23T17:25:00",
          "end_datetime": "2019-07-23T17:35:00",
          "duration": 10,
          "location": "Room 349",
          "title": "High-Performance Portfolio Risk Aggregation",
          "text": "We will talk about how a risk management use case got sped up ~150x using multi-core parallel computing techniques in a Docker environment. Western Asset is a fixed income asset manager.  We recently replaced the portfolio risk aggregation process with a Julia implementation, and the run-time performance has improved tremendously.  This talk will focus on system architecture, performance optimization, and deployment to a Docker swarm environment. ",
          "url": "https://pretalx.com/juliacon2019/talk/LR9FW9/",
          "index": 94,
          "speaker": "Tom Kwong"
        },
        {
          "start_datetime": "2019-07-23T16:45:00",
          "end_datetime": "2019-07-23T16:55:00",
          "duration": 10,
          "location": "Elm A",
          "title": "State of the Data: JuliaData",
          "text": "With the release of Julia 1.0, packages have raced to update and stabilize APIs. Come learn about all things current and planned for JuliaData packages, including:\n* DataFrames.jl\n* CSV.jl\n* Tables.jl\n* CategoricalArrays.jl\n* and others ",
          "url": "https://pretalx.com/juliacon2019/talk/DJY9HU/",
          "index": 95,
          "speaker": "Jacob Quinn"
        },
        {
          "start_datetime": "2019-07-23T11:40:00",
          "end_datetime": "2019-07-23T11:50:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Ultimate Datetime",
          "text": "Ultimate datetime is a datetime data type, which eliminates many of the limitations and inaccuracies of the datetime datatypes generally employed in computer languages.  Ultimate datetime enables representation of datetimes from the Big Bang through to the year 100,000,000,000 with attosecond precision, while properly handling leap seconds, the full range of time zones, and accounting for precision and uncertainty. Ultimate datetime is a high performance, comprehensive datatype that was developed in C, then integrated into Julia.  Ultimate datetime represents datetimes from the Big Bang through the year 100,000,000,000 with attosecond precision.  Specifiable precision and uncertainty have been implemented along with a rich set of comparison and arithmetic functions.  Leap seconds are handled properly, as is the pre-leap second atomic time period.  Local times support the full range of time zones provided in the IANA database, including proper accounting for historical time zones, as well as the varying transitions from the Julian to the Gregorian calendar around the world. ",
          "url": "https://pretalx.com/juliacon2019/talk/UUESUW/",
          "index": 96,
          "speaker": "Jay Dweck"
        },
        {
          "start_datetime": "2019-07-24T17:05:00",
          "end_datetime": "2019-07-24T17:15:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Randomized Sketching for Approximate Gradients : Applications to PDE Constrained Optimization and Backpropagation.",
          "text": "Randomized sketching algorithms are a powerful tool for on-the-fly compression of matrices. In this talk we show how sketching can be used for approximate gradient and hessian-times-vector computations that are storage optimal. \nThis approach gives cutting-edge low memory algorithms to address the challenge of expensive storage in optimization problems with PDE constraints.  \nWe also discuss implications for efficient adjoint computation/back-propagation. This work is motivated by the challenge of expensive storage in optimization problems with PDE constraints e.g. optimal flow control, full waveform inversion, optical tomography etc. \nThese optimization problems are characterized by PDE constraints that uniquely determine the state of a physical system for a given control. The state matrix is typically much more expensive to store than the control matrix.  The optimization algorithms effects changes in the control that move a physical system towards optimal behavior. Any first or second order algorithm requires gradient computation. As a first step we have to solve the PDE and store its solution and this is a storage bottleneck.  Recently randomized algorithms have been developed for matrix approximation and Sketching is a high-performance algorithm for on-the-fly compression of matrices. We demonstrate how sketching can be used to compute approximate gradients and hessian-times-vector quantities while avoiding the storage bottleneck caused by the PDE solution.  This cutting-edge algorithmic recipe has been applied successfully for linear parabolic boundary control and optimal fluid flow. We also explore its implications for efficient adjoint computation or back-propagation. ",
          "url": "https://pretalx.com/juliacon2019/talk/ZDRQQA/",
          "index": 97,
          "speaker": "Ramchandran Muthukumar"
        },
        {
          "start_datetime": "2019-07-25T17:25:00",
          "end_datetime": "2019-07-25T17:35:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Electrifying Transportation with Julia",
          "text": "In this talk, we will discuss implementation of various models relevant for electrochemical energy systems in order to more rapidly optimize component design and use-case specific optimization.We will show massive performance improvements gained through Julia for a variety of popularpseudo-2D  porous  electrode  models  describing  Li-ion  batteries.   In  addition,  we  will  illustrate an example of an integrated design workflow of an aircraft power dynamics model along with a battery model, implemented within Julia. Modeling electric vehicle systems and their batteries helps to hasten the adoption and development of electric vehicles by clarifying their capabilities and requirements. Much progress has been made in electrifying automobiles, but less has been made in aircraft, which contribute a significant fraction of the greenhouse gas emissions from transportation.  Aircraft have different battery requirements than automobiles and other modes of ground transportation.  Specifically, the take-off and climb stages of flight can require discharge rates far greater than ground based  systems.To  study the effects of electrifying aviation, models of aircraft and batteries need to be integrated and studied together.  It is essential to calculate the parameters of both the aircraft and the battery because these two systems are dependent on each other.We  use  Julia  to  model  both  aircraft  and  batteries.   To  model  aircraft,  a  physics  based  performance model is used to calculate the energy and power requirements of the system.  We use historical aircraft of various size and configurations to calculate energy and power requirements of different classes of aircraft. Our lab has modeled both eVTOL and conventional aircraft. Convert-ing the model from MATLAB to Julia yielded a massive speedup, enabling us to test many more configurations and classes of aircraft.We use several battery models depending on the size and battery requirements of the mode of transportation.  For modes of that are capable of being powered by Lithium-Ion batteries, we use psuedo-2D single particle models incorporating all relevant properties of batteries, including energy, discharge rates, mass, and temperature. These models involve large systems of differential equations which can be efficiently solved using the DifferentialEquations.jl package. Porting these battery models to Julia yielded massive speedups, enabling parameter sweeps and use-case specific optimization  of  battery  cell  parameters.   Larger  and  longer  range  forms  of  transportation  have battery requirements that exceed what can be provided by Lithium-Ion batteries.   For example,a fully electric commercial aircraft could require a Lithium Air battery.  We also use the speed provided by Julia to increase our modeling capabilities for these forms of transportation.  In thistalk, we will show an integrated model of a Lithium Air battery and an aircraft performance model. ",
          "url": "https://pretalx.com/juliacon2019/talk/NF9XC7/",
          "index": 98,
          "speaker": "Alec Bills"
        },
        {
          "start_datetime": "2019-07-24T17:15:00",
          "end_datetime": "2019-07-24T17:25:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Neural Network states and unsupervised learning for Open Quantum Systems",
          "text": "We recently investigated how Neural Networks can be used to approximate the density matrix encoding mixed quantum states, and how traditional numerical techniques in physics can be reinterpreted in terms of unsupervised learning. I will talk about how Julia allowed us to rapidly iterate in our research while also producing an efficient yet flexible package. The quantum state describing an Open Quantum System is encoded by a density matrix with exponentially-many elements. We recently demonstrated that such high-dimensional function can be approximated by a Neural Network. Moreover, the variational procedure by which we determine the steady-state neural density matrix is formally equivalent to an unsupervised learning problem. After a brief introduction of our main results, we will share details on how Julia allowed us develop an efficient and flexible code to explore this topic. The resulting Julia code is of interest for physicists working in the novel field of neural network representations of quantum states. ",
          "url": "https://pretalx.com/juliacon2019/talk/AVDWLV/",
          "index": 99,
          "speaker": "Filippo Vicentini"
        },
        {
          "start_datetime": "2019-07-24T11:40:00",
          "end_datetime": "2019-07-24T11:50:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Re-designing Optim",
          "text": "With Julia v1.0 released, It is time to reflect on what a Julian Julia package is, and why some popular packages such as Optim is not necessarily as Julian as they can be! Based on requests from the community and own experiences, I explain some guiding principles on a complete re-write of the packages in the JuliaNLSolvers organization. Optim, NLsolve and LsqFit are three packages in the JuliaNLSolvers organization. They have all been around from the early Julia days, and serve some basic scientific computing needs such as minimizing a function, fitting a curve and solving a system of equations. Their age means that they are widely used and well-known. However, their age also show in much of the design and abstractions that predates many of the unique and powerful features and packages in Julia. Based on my own experience as a maintainer of these packages, and learning from the discussions on mailing lists, forums, and github, I will talk about the failures of the three packages, and how a complete rewrite of the packages is the best way forward. Hopefully, my reflections and experiences can help future package writers avoid making the same mistakes over and over again. The talk won't be heavy on the mathematical details, but will explore important things to design for from the start. Users will eventually request many of the features, but they might be difficult to retrofit, so come join the quest to find the best ways of satisfying the greedy Julia users and abusers out there! ",
          "url": "https://pretalx.com/juliacon2019/talk/FXU7DC/",
          "index": 100,
          "speaker": "Patrick Kofod Mogensen"
        },
        {
          "start_datetime": "2019-07-24T16:25:00",
          "end_datetime": "2019-07-24T16:35:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Neural Ordinary Differential Equations with DiffEqFlux",
          "text": "This talk will demonstrate the models described in  Neural Ordinary Differential Equations  implemented in DiffEqFlux.jl, using DifferentialEquations.jl to solve ODEs with dynamics specified and trained with Flux.jl. This talk will demonstrate models described in  Neural Ordinary Differential Equations  implemented in DiffEqFlux.jl, using DifferentialEquations.jl to solve ODEs with dynamics specified and trained with Flux.jl. In particular it will show how to use gradient optimization with the adjoint method to train a neural network which parameterizes an ODE for supervised learning and for Continuous Normalizing Flows. These demonstrations will be contributed to the Flux model-zoo. The supervised learning demonstration will illustrate that neural ODEs can be drop-in replacements for  residual networks  on supervised tasks such as image recognition.  The Continuous Normalizing Flow demo will show how a neural ODE, with the instantaneous change of variables, can learn a continuous transformation from tractable base distribution to a distribution over data which can be sampled from and evaluate densities under. ",
          "url": "https://pretalx.com/juliacon2019/talk/HANGXH/",
          "index": 101,
          "speaker": "Jesse Bettencourt"
        },
        {
          "start_datetime": "2019-07-25T09:30:00",
          "end_datetime": "2019-07-25T10:00:00",
          "duration": 30,
          "location": "NS Room 130",
          "title": "What's Bad About Julia",
          "text": "I'll describe some of the more fundamental issues in Julia today, as I see it, and how we can potentially solve them to get a better language. As everyone knows, the problem with Julia is that it uses 1-based indexing! Well, of course that's not it, but are there any  real  problems? While there are any number of readily apparent issues involving performance, \nmissing functionality, and so on, those are being fixed every day. Subtler issues lurk beneath the surface. In this talk I will present some of the tricker, more hidden, and more fundamental problems involving the type system, object model, and core language generally --- things that keep me up at night. For example, did you know that Julia's types are not closed under intersection, but that it would be nice if they were? The good news is that these are all things I believe we can solve --- in time --- to make Julia a meaningfully better language. ",
          "url": "https://pretalx.com/juliacon2019/talk/ZFQHDS/",
          "index": 102,
          "speaker": "Jeff Bezanson"
        },
        {
          "start_datetime": "2019-07-23T11:30:00",
          "end_datetime": "2019-07-23T11:40:00",
          "duration": 10,
          "location": "Room 349",
          "title": "FilePaths: File system abstractions and why we need them",
          "text": "Have you ever found yourself writing code that special cases different local and remote  filesystems ?  \nFilePath types are a great way to encapsulate filesystem specific logic and provide a common  abstraction  for interacting with various types of paths (e.g., posix, windows, S3, FTP). We'll start by discussing filesystem libraries for other languages (e.g.,  pathlib  for Python,  Data.FilePath  for Haskell,  Paths  in Rust) and how such abstractions may uniquely benefit from multiple dispatch in Julia. \nI’ll review some examples of how we (myself and my colleagues) have used  FilePathsBase.jl  to simplify our application logic and avoid ambiguous code paths. \nFinally, we'll conclude with an open discussion around how these abstractions can be better incorporated into the larger Julia ecosystem. ",
          "url": "https://pretalx.com/juliacon2019/talk/CY3YQB/",
          "index": 103,
          "speaker": "Rory Finnegan"
        },
        {
          "start_datetime": "2019-07-25T15:45:00",
          "end_datetime": "2019-07-25T16:15:00",
          "duration": 30,
          "location": "Elm B",
          "title": "Symbolic Manipulation in Julia",
          "text": "Symbolic terms are fundamental to a variety of fields in computer science, including computer algebra, automated reasoning, and scientific modeling. In this talk, we discuss a family of Julia packages for symbolic computation, including Rewrite.jl for term rewriting and ModelingToolkit.jl for symbolic differential equations. The manipulation of symbolic terms is fundamental to a variety of fields in computer science, including computer algebra, automated reasoning, and scientific modeling. Through the lens of symbolic transformations, we concisely represent and efficiently apply complex properties and equivalences. In this talk, we discuss a family of Julia packages for symbolic computation, establishing the foundations of term rewriting and showcasing extensions and applications. After offering a formal definition of symbolic terms, we will examine various notions from the field of term rewriting and their implementations in Rewrite.jl. We will design sets of rewrite rules that simplify algebraic expressions into unique normal forms, based on domain-specific axioms. Building on this interpretation, we finally will explore symbolic differential equations in ModelingToolkit.jl, showcasing methods for incorporating context-aware symbolic variables and techniques for enforcing mathematical invariants. ",
          "url": "https://pretalx.com/juliacon2019/talk/9R9A7M/",
          "index": 104,
          "speaker": "Harrison Grodin"
        },
        {
          "start_datetime": "2019-07-23T09:30:00",
          "end_datetime": "2019-07-23T10:00:00",
          "duration": 30,
          "location": "NS Room 130",
          "title": "Debugging code with JuliaInterpreter",
          "text": "We present a Julia debugger and demonstrate a variety of interfaces for accessing it. We also describe the infrastructure that provides intriguing new capabilities to the Julia ecosystem. A Julia debugger, with support for breakpoints, trapping errors, and inspection of local variables, has been long desired in the Julia community. We describe an approach based on a new interpreter for Julia code, JuliaInterpreter.jl. JuliaInterpreter is able to evaluate Julia’s  lowered representation  statement-by-statement, and thus serves as the foundation for inspecting and manipulating intermediate results. Compared with previous tools, JuliaInterpreter offers several new features, such as improved performance, the ability to evaluate top-level code, built-in support for breakpoints, and the ability to switch flexibly between compiled and interpreted evaluation. JuliaInterpreter can be used directly as a standalone interpreter, and this makes it interesting for other purposes such as exploring tradeoffs between compile-time and run-time efficiency. To enable JuliaInterpreter’s use as a debugger, we developed three different front-ends. One is the Juno IDE, which supports graphical management of breakpoints and stepping through code in a manner integrated with its editing capabilities. In addition to Juno, there are two different console-based (REPL) interfaces. Debugger.jl offers the most powerful control over stepping, whereas Rebugger.jl emulates features of a graphical client. We will demonstrate these tools as means to access some of JuliaInterpreter’s capabilities. ",
          "url": "https://pretalx.com/juliacon2019/talk/BB9VQZ/",
          "index": 105,
          "speaker": "Kristoffer Carlsson, Sebastian Pfitzner, Tim Holy"
        },
        {
          "start_datetime": "2019-07-25T17:05:00",
          "end_datetime": "2019-07-25T17:15:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Analyzing and updating code with JuliaInterpreter and Revise",
          "text": "Revise.jl allows you to modify code in your running Julia session. Revise was recently rewritten around JuliaInterpreter.jl and a new query interface, CodeTracking.jl, resulting in many improvements and easier access to Revise’s internal data. Revise.jl serves a dynamic bridge between the text in source files and the compiled methods in your running Julia session. To faithfully bridge these two worlds, Revise needs to understand quite a bit about code. Historically, Revise analyzed expressions written in Julia’s  surface syntax ; however, recent examples revealed a number of weaknesses in this approach. To address these limitations, starting with version 2.0 Revise has leveraged JuliaInterpreter.jl to perform its analysis of code using Julia’s internal lowered-form representation. This has resulted in dramatic improvements in the number of methods that can be tracked by their signatures, and may allow new capabilities such as discovery of block-level interdependencies. At the same time, Revise’s internal data structures have been reorganized to simplify access by other packages, resulting in a lightweight standalone package CodeTracking.jl. I will describe the motivations for these changes and the solutions enabled by the new approach, and demonstrate some of the dramatic improvements this has netted for dependent packages like Rebugger.jl. ",
          "url": "https://pretalx.com/juliacon2019/talk/RH78UW/",
          "index": 106,
          "speaker": "Tim Holy"
        },
        {
          "start_datetime": "2019-07-25T11:30:00",
          "end_datetime": "2019-07-25T11:40:00",
          "duration": 10,
          "location": "Room 349",
          "title": "Julia's Killer App(s): Implementing State Machines Simply using Multiple Dispatch",
          "text": "Julia's embrace of multiple dispatch as a key organizing concept provides \ndevelopers with all the tools they need to simply implement state machine based \nsolutions to a wide range of problems. This presentation will explore a series \nof increasingly complex tasks that can all be addressed using a clever \ncombination of types and multiple dispatch. In the universe of programming languages, success for any new language hangs on \nits ability to simplify some class of problem that exceed the capabilities of \nother existing languages to generate simple solutions for. The concept of a \nstate machine is a powerful tool that programmers have used for ages to address \nall manner of challenges, but until now implementing a state machine has \ntypically required either the use of involved external libraries or the design \nof relatively opaque algorithms and data structures. Julia changes all of that \nby embracing multiple dispatch and an extensible type system that, together, \nprovide everything a programmer requires to design and develop even the most \ncomplex of state machines. This presentation will begin with a basic introduction to the concepts behind \nstate machines and their implementation and then dive into an example of how \none might use the concept of a state machine to handle the parsing of a regular \nexpression into a Julia data structure. Continuing from there, we will look at \nhow matching a regular expression to a string can, itself, be implemented using \na state machine. All the while, we will only require Julia, its type system, \nand a handful of multiply dispatched methods. Finally, we will review various ways in which state machines implemented in \nJulia can be extended and iterated upon without requiring any new libraries or \ntools beyond those used in their initial implementation. We will also consider \nhow even more complex tasks, including even an entire HTTP request/response \nhandler, can be tackled using the exact same approach. By the end, it should be \nclear that the killer feature that Julia brings to the world of programming \nlanguages is the ability to develop state machines in a way that is clear, \nconcise, performant, and infinitely flexible. ",
          "url": "https://pretalx.com/juliacon2019/talk/JVUMQJ/",
          "index": 107,
          "speaker": "Joshua Ballanco"
        },
        {
          "start_datetime": "2019-07-24T11:00:00",
          "end_datetime": "2019-07-24T12:00:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Sustainable Development and Open Source Monetization",
          "text": "As the Julia community grows and becomes core tooling to many scientists and businesses, sustainably keeping members of the community as developers of free software developers is vital to the health of the ecosystem. In this discussion we will talk about the various ways we ourselves are funding or have been funded for Julia-based open source software development, and hypothesize alternative methods such as crowdfunding. ",
          "url": "https://pretalx.com/juliacon2019/talk/EKN9AD/",
          "index": 108,
          "speaker": "Clark Evans"
        },
        {
          "start_datetime": "2019-07-23T16:55:00",
          "end_datetime": "2019-07-23T17:05:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Prototyping Visualizations for the Web with Vega and Julia",
          "text": "The internet is a powerful medium for story telling in data science, but creating compelling, interactive graphics can be difficult.  This talk will show how Vega (VegaLite.jl) and Julia can be used to prototype interactive visualizations, and then how those visualizations can be deployed to the web. Using Julia and Vega to jumpstart development of interactive visualizations helps bridge the gap between analysis done on your laptop and publishing compelling results to the web.  This talk will show how you can use the language, tools, and development environment you love with Julia and have web-ready interactive graphics ready to deploy.  We'll highlight the use of DataVoyager.jl for data exploration, how to use DataVoyager plots to quick-start your visualizations in VegaLite.jl, adding interactivity to your visualizations, and finally how this translates to the web. ",
          "url": "https://pretalx.com/juliacon2019/talk/YZPSDK/",
          "index": 109,
          "speaker": "Mary McGrath"
        },
        {
          "start_datetime": "2019-07-24T11:30:00",
          "end_datetime": "2019-07-24T11:40:00",
          "duration": 10,
          "location": "Elm B",
          "title": "Slow images, fast numbers: Using Julia in biomedical imaging and beyond",
          "text": "At MIT’s preclinical setting (Preclinical Modeling, Imaging and Testing, PMIT), the available shared biomedical imaging instrumentation, such as magnetic resonance imaging (MRI) or x-ray micro-computed tomography (microCT) scanners, produces diverse and large data sets on a daily basis. The acquisition of an image can be fast or slow depending on the acquisition protocols and whether we are interested in a 2D slice, a 3D volume or a 4D dataset over time. The time from acquisition to visualization of the image heavily depends on the size of the dataset, the image reconstruction algorithm and the computing power available. Although image acquisition and visualization are typically tied to the manufacturer of each specific platform, image quantification is more user dependent and can suffer a significant computational burden when performing non-linear mathematical operations on a pixel-by-pixel basis over millions of high-resolution images. The quantification of an image, namely the extraction of precise numerical information from the image that is representative of a biological process tied to disease and therapy, can take days to derive for users that choose high-level, easy-to-use numerical analysis software. We will present a case study of vast improvements in quantitative image processing of large preclinical MRI datasets using Julia libraries and expand on PMIT’s efforts to develop a Julia-based platform for intelligent preclinical evaluation of therapeutics from their development at bench to their visualization in a living subject. ",
          "url": "https://pretalx.com/juliacon2019/talk/3JUN8D/",
          "index": 110,
          "speaker": "Virginia Spanoudaki"
        },
        {
          "start_datetime": "2019-07-23T10:05:00",
          "end_datetime": "2019-07-23T10:15:00",
          "duration": 10,
          "location": "NS Room 130",
          "title": "Julia Survey Results",
          "text": "A presentation on the results of the 2019 Julia Survey ",
          "url": "https://pretalx.com/juliacon2019/talk/9NK3HY/",
          "index": 111,
          "speaker": "Viral B. Shah"
        },
        {
          "start_datetime": "2019-07-23T08:40:00",
          "end_datetime": "2019-07-23T09:25:00",
          "duration": 45,
          "location": "NS Room 130",
          "title": "Keynote: Professor Madeleine Udell",
          "text": "Madeleine Udell is Assistant Professor of Operations Research and Information Engineering \nand Richard and Sybil Smith Sesquicentennial Fellow at Cornell University. \nShe studies optimization and machine learning for large scale data analysis and control, \nwith applications in marketing, demographic modeling, medical informatics, \nengineering system design, and automated machine learning. \nHer research in optimization centers on detecting and exploiting novel structures \nin optimization problems, with a particular focus on convex and low rank problems. \nThese structures lead the way to automatic proofs of optimality, better complexity guarantees, and faster, \nmore memory-efficient algorithms. She has developed a number of open source libraries for \nmodeling and solving optimization problems, including  Convex.jl , \none of the top tools in the Julia language for technical computing. ",
          "url": "https://pretalx.com/juliacon2019/talk/PMLSD9/",
          "index": 112,
          "speaker": "Professor Madeleine  Udell"
        },
        {
          "start_datetime": "2019-07-25T08:40:00",
          "end_datetime": "2019-07-25T09:25:00",
          "duration": 45,
          "location": "NS Room 130",
          "title": "Keynote: Professor Heather Miller",
          "text": "Heather Miller is an Assistant Professor in the School of Computer Science at Carnegie Mellon, \nwhere she is affiliated with the Institute for Software Research. Prior to joining the faculty at CMU, \nProfessor Miller not only worked as a research scientist at  EPFL , but \nalso co-founded and served as the Executive Director for the  Scala Center , a \nnonprofit focused on software development, education, and research surrounding the open source Scala \nprogramming language. She continues to work on and around Scala, while pursuing research on various \nflavors of distributed and concurrent computation. Some of her projects underway include programming \nmodels and type systems to facilitate the design of new, functional distributed systems. ",
          "url": "https://pretalx.com/juliacon2019/talk/JUZUDM/",
          "index": 113,
          "speaker": "Professor Heather Miller"
        },
        {
          "start_datetime": "2019-07-24T08:40:00",
          "end_datetime": "2019-07-24T09:25:00",
          "duration": 45,
          "location": "NS Room 130",
          "title": "Keynote: Professor Steven G Johnson",
          "text": "Steven G. Johnson is a Professor of Applied Mathematics and Physics at MIT, \nwhere he joined the faculty in 2004 and previously received a PhD in physics (2001) \nand BS degrees in physics, mathematics, and computer science (1995). \nHe has a long history of contributions to scientific computation and software, \nincluding the  FFTW  fast Fourier transform library (for which he co-received \nthe 1999 J. H. Wilkinson Prize) and many other software packages. \nHe has been using, contributing to, and teaching with Julia since 2012. \nHe created and maintains blockbuster Julia packages that you may have heard of: PyCall  and  IJulia \n(and Julia’s  FFTW bindings , of course). Professor Johnson's professional research concerns wave-matter interactions \nand electromagnetism in media structured on the wavelength scale (“nanophotonics”), \nespecially in the infrared and optical regimes. He works on many aspects of the theory, \ndesign, and computational modeling of nanophotonic devices, both classical and quantum. \nHe is also a coauthor on over 200 papers and over 30 patents in this area, \nincluding the textbook  Photonic Crystals: Molding the Flow of Light . ",
          "url": "https://pretalx.com/juliacon2019/talk/DRP3EF/",
          "index": 114,
          "speaker": "Professor Steven G Johnson"
        },
        {
          "start_datetime": "2019-07-24T13:30:00",
          "end_datetime": "2019-07-24T14:15:00",
          "duration": 45,
          "location": "NS Room 130",
          "title": "Keynote: Arch D. Robison",
          "text": "Arch D. Robison is a Principal Systems Software Engineer at NVIDIA, where he works \non  TensorRT , NVIDIA's platform for high-performance \ndeep-learning inference. He was the lead developer for KAI C++, the original architect of Intel \nThreading Building Blocks, and one of the authors of the book  Structured Parallel Programming: \nPatterns for Efficient Computation . Arch contributed type-based alias analysis and vectorization \nsupport to Julia, including the original implementation of  SIMD in Julia 0.3 . He's used Julia to generate  x86 assembly language  for a Go \nimplementation of his video game  Frequon Invaders . He also took 2nd place in AI Zimmermann's contest \n\"Delacorte Numbers\"  using Julia exclusively . He has 21 patents and an Erdös number of 3. ",
          "url": "https://pretalx.com/juliacon2019/talk/PKLBXV/",
          "index": 115,
          "speaker": "Arch D. Robison"
        },
        {
          "start_datetime": "2019-07-25T13:30:00",
          "end_datetime": "2019-07-25T14:15:00",
          "duration": 45,
          "location": "NS Room 130",
          "title": "Keynote: Dr Steven Lee",
          "text": "Steven Lee is an Applied Mathematics Program Manager for Advanced Scientific Computing \nResearch (ASCR) within the Department of Energy (DOE), Office of Science. Most recently, Steven and an organizing \ncommittee issued a  brochure  and  workshop report \non Scientific Machine Learning: Core Technologies for Artificial Intelligence. \nHe has also been an ASCR Program Manager within the Scientific Discovery through Advanced Computing program \n( SciDAC-3  Institutes) \nfor the projects:  FASTMATH \n- Frameworks, Algorithms and Scalable Technologies for Mathematics; and QUEST \n- Quantification of Uncertainty for Extreme-Scale Computations. Before joining the DOE, Steven was a \ncomputational scientist at Lawrence Livermore National Laboratory and Oak Ridge National Laboratory. \nHe has also been a visiting Assistant Professor in the Department of Mathematics at MIT. He has a Ph.D. \nin Computer Science (UIUC) and B.S. in Applied Mathematics (Yale). ",
          "url": "https://pretalx.com/juliacon2019/talk/SSNXAP/",
          "index": 116,
          "speaker": "Dr Steven  Lee"
        },
        {
          "start_datetime": "2019-07-23T13:30:00",
          "end_datetime": "2019-07-23T14:15:00",
          "duration": 45,
          "location": "NS Room 130",
          "title": "Keynote: Dr Ted Rieger",
          "text": "Ted Rieger received his PhD in Chemical Engineering from Northwestern where he developed models of protein aggregation of Huntington. After graduate school, he joined Entelos, Inc in the Bay Area where he spent 6 years, developing and utilizing Quantitative Systems Pharmacology (QSP) models to understand drug development questions, primarily in the area of cardiometabolic diseases. In 2011, Ted transitioned to Pfizer’s Systems Biology Group in our CVMET Research Unit. He has been at Pfizer since then, and is now a Senior Principal Scientist in the QSP Group in Early Clinical Development.  He presently supports programs in the cardiometabolic space from early discovery through proof-of-concept. ",
          "url": "https://pretalx.com/juliacon2019/talk/AY9C9Z/",
          "index": 117,
          "speaker": "Dr Ted Rieger"
        },
        {
          "start_datetime": "2019-07-23T08:30:00",
          "end_datetime": "2019-07-23T08:40:00",
          "duration": 10,
          "location": "NS Room 130",
          "title": "Opening Remarks",
          "text": "Welcome to Juliacon! \nThis opening session will let you know all the details of what is going on, and will include the important information and what to do in-case of emergencies. ",
          "url": "https://pretalx.com/juliacon2019/talk/F8BBQW/",
          "index": 118,
          "speaker": "JuliaCon Committee"
        },
        {
          "start_datetime": "2019-07-24T09:30:00",
          "end_datetime": "2019-07-24T09:45:00",
          "duration": 15,
          "location": "NS Room 130",
          "title": "Sponsor Address: J P Morgan Chase & Co.",
          "text": "An address from our sponsor. ",
          "url": "https://pretalx.com/juliacon2019/talk/JHZRJS/",
          "index": 119,
          "speaker": "Jiahao Chen"
        },
        {
          "start_datetime": "2019-07-24T09:45:00",
          "end_datetime": "2019-07-24T09:50:00",
          "duration": 5,
          "location": "NS Room 130",
          "title": "Sponsor Address: Julia Computing",
          "text": "An address from one of our sponsors. ",
          "url": "https://pretalx.com/juliacon2019/talk/CYJRTK/",
          "index": 120,
          "speaker": "Stefan Karpinski"
        },
        {
          "start_datetime": "2019-07-23T10:00:00",
          "end_datetime": "2019-07-23T10:05:00",
          "duration": 5,
          "location": "NS Room 130",
          "title": "Sponsor Address: Intel",
          "text": "An address from one of our sponsors. ",
          "url": "https://pretalx.com/juliacon2019/talk/LFGLXC/",
          "index": 121,
          "speaker": "Paul Petersen"
        },
        {
          "start_datetime": "2019-07-25T10:00:00",
          "end_datetime": "2019-07-25T10:05:00",
          "duration": 5,
          "location": "NS Room 130",
          "title": "Sponsor Address: University of Maryland",
          "text": "An address from one of our sponsors. ",
          "url": "https://pretalx.com/juliacon2019/talk/PK738L/",
          "index": 122,
          "speaker": "Vijay Ivaturi"
        },
        {
          "start_datetime": "2019-07-25T14:30:00",
          "end_datetime": "2019-07-25T15:30:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Julia in Healthcare",
          "text": "This session is for gathering the various groups interested in Julia for healthcare purposes. Pharmacometrics, healthcare-focused biological research, and the translation of software to practice will be discussed. ",
          "url": "https://pretalx.com/juliacon2019/talk/7RPM7G/",
          "index": 123,
          "speaker": "Vijay Ivaturi"
        },
        {
          "start_datetime": "2019-07-23T15:45:00",
          "end_datetime": "2019-07-23T16:35:00",
          "duration": 50,
          "location": "BoF: Room 353",
          "title": "Julia and NumFocus, a discussion of how money works",
          "text": "Discussion on how Julia as a community handles money, sponsorship and grants. ",
          "url": "https://pretalx.com/juliacon2019/talk/TFFARR/",
          "index": 124,
          "speaker": "Viral B. Shah"
        },
        {
          "start_datetime": "2019-07-23T11:40:00",
          "end_datetime": "2019-07-23T11:50:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Thread Based Parallelism part 2",
          "text": "Hear about what is new in julia 1.2 and 1.3 with thread-based parallelism. \n(note: due to a race condition, Thread Based Parallelism part 2 occurs before Thread Based Parallelism part 1) ",
          "url": "https://pretalx.com/juliacon2019/talk/83YFMV/",
          "index": 125,
          "speaker": "Jeff Bezanson"
        },
        {
          "start_datetime": "2019-07-23T11:50:00",
          "end_datetime": "2019-07-23T12:00:00",
          "duration": 10,
          "location": "Elm A",
          "title": "Thread Based Parallelism part 1",
          "text": "Hear about what is new in julia 1.2 and 1.3 with thread-based parallelism. \n(note: due to a race condition, Thread Based Parallelism part 1 occurs after Thread Based Parallelism part 2) ",
          "url": "https://pretalx.com/juliacon2019/talk/3YQSSP/",
          "index": 126,
          "speaker": "Jameson Nash"
        },
        {
          "start_datetime": "2019-07-23T10:15:00",
          "end_datetime": "2019-07-23T10:20:00",
          "duration": 5,
          "location": "NS Room 130",
          "title": "Sponsor Address: Relational AI",
          "text": "A talk from one of our gracious sponsors. ",
          "url": "https://pretalx.com/juliacon2019/talk/CQM3RC/",
          "index": 127,
          "speaker": "Nathan Daly"
        },
        {
          "start_datetime": "2019-07-24T15:45:00",
          "end_datetime": "2019-07-24T16:45:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Julia In Production",
          "text": "A casual chat about the virtues and concerns relating to running julia in a production enviroment. ",
          "url": "https://pretalx.com/juliacon2019/talk/B38TDU/",
          "index": 128,
          "speaker": "Curtis Vogt"
        },
        {
          "start_datetime": "2019-07-25T15:45:00",
          "end_datetime": "2019-07-25T16:45:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Package Management BoF",
          "text": "Everything Pkg: discussion of package management, version resolution, binary artifacts, registries, manifests, configuration, etc. ",
          "url": "https://pretalx.com/juliacon2019/talk/GMRBWB/",
          "index": 129,
          "speaker": "Stefan Karpinski"
        },
        {
          "start_datetime": "2019-07-23T16:35:00",
          "end_datetime": "2019-07-23T17:35:00",
          "duration": 60,
          "location": "BoF: Room 353",
          "title": "Cassette and company -- Dynamic compiler passes",
          "text": "Chat about Cassette,  Vinyl, IRTools, and Aborist. Things that rewrite the code at compile-time, based on context. ",
          "url": "https://pretalx.com/juliacon2019/talk/APPUNN/",
          "index": 130,
          "speaker": "Jarrett Revels, Valentin Churavy"
        },
        {
          "start_datetime": "2019-07-24T16:45:00",
          "end_datetime": "2019-07-24T17:35:00",
          "duration": 50,
          "location": "BoF: Room 353",
          "title": "JuliaGPU",
          "text": "A discussion of the Julia GPU ecosystem ",
          "url": "https://pretalx.com/juliacon2019/talk/BACLJQ/",
          "index": 131,
          "speaker": "Valentin Churavy, Tim Besard"
        },
        {
          "start_datetime": "2019-07-25T16:45:00",
          "end_datetime": "2019-07-25T17:35:00",
          "duration": 50,
          "location": "BoF: Room 353",
          "title": "Julia in Astronomy",
          "text": "Casual chats about the uses of Julia in Astronomy, JuliaAstro and related packages and studies. ",
          "url": "https://pretalx.com/juliacon2019/talk/MC8TPZ/",
          "index": 132,
          "speaker": "Mosè Giordano"
        }
      ]
    },
    {
      "name": "data_0",
      "source": "source_0",
      "transform": [
        {
          "type": "formula",
          "expr": "toDate(datum[\"start_datetime\"])",
          "as": "start_datetime"
        },
        {
          "type": "formula",
          "expr": "toDate(datum[\"end_datetime\"])",
          "as": "end_datetime"
        },
        {
          "type": "formula",
          "as": "day_start_datetime",
          "expr": "datetime(2006, 0, day(datum[\"start_datetime\"])+1, 0, 0, 0, 0)"
        },
        {"type": "identifier", "as": "_vgsid_"},
        {
          "type": "formula",
          "as": "hoursminutes_end_datetime",
          "expr": "datetime(0, 0, 1, hours(datum[\"end_datetime\"]), minutes(datum[\"end_datetime\"]), 0, 0)"
        },
        {
          "type": "formula",
          "as": "hoursminutes_start_datetime",
          "expr": "datetime(0, 0, 1, hours(datum[\"start_datetime\"]), minutes(datum[\"start_datetime\"]), 0, 0)"
        },
        {
          "type": "formula",
          "as": "yearmonthdatehoursminutes_start_datetime",
          "expr": "datetime(year(datum[\"start_datetime\"]), month(datum[\"start_datetime\"]), date(datum[\"start_datetime\"]), hours(datum[\"start_datetime\"]), minutes(datum[\"start_datetime\"]), 0, 0)"
        },
        {
          "type": "filter",
          "expr": "datum[\"hoursminutes_start_datetime\"] !== null && !isNaN(datum[\"hoursminutes_start_datetime\"])"
        }
      ]
    },
    {
      "name": "column_domain",
      "source": "data_0",
      "transform": [{"type": "aggregate", "groupby": ["day_start_datetime"]}]
    }
  ],
  "signals": [
    {"name": "child_width", "value": 300},
    {"name": "child_height", "value": 150},
    {
      "name": "unit",
      "value": {},
      "on": [
        {"events": "mousemove", "update": "isTuple(group()) ? group() : unit"}
      ]
    },
    {"name": "paintbrush", "update": "vlSelectionResolve(\"paintbrush_store\")"}
  ],
  "layout": {
    "padding": 20,
    "columns": {"signal": "length(data('column_domain'))"},
    "bounds": "full",
    "align": "all"
  },
  "marks": [
    {
      "name": "row_header",
      "type": "group",
      "role": "row-header",
      "encode": {"update": {"height": {"signal": "child_height"}}},
      "axes": [{"scale": "y", "orient": "left", "grid": false, "zindex": 1}]
    },
    {
      "name": "column_header",
      "type": "group",
      "role": "column-header",
      "from": {"data": "column_domain"},
      "sort": {"field": "datum[\"day_start_datetime\"]", "order": "ascending"},
      "title": {
        "text": {"signal": "timeFormat(parent[\"day_start_datetime\"], '%A')"},
        "style": "guide-label",
        "frame": "group",
        "fontSize": 15,
        "offset": 10
      },
      "encode": {"update": {"width": {"signal": "child_width"}}}
    },
    {
      "name": "column_footer",
      "type": "group",
      "role": "column-footer",
      "from": {"data": "column_domain"},
      "sort": {"field": "datum[\"day_start_datetime\"]", "order": "ascending"},
      "encode": {"update": {"width": {"signal": "child_width"}}},
      "axes": [
        {
          "scale": "x",
          "orient": "bottom",
          "grid": false,
          "labelFlush": true,
          "labelOverlap": true,
          "tickCount": {"signal": "ceil(child_width/40)"},
          "encode": {
            "labels": {
              "update": {"text": {"signal": "timeFormat(datum.value, '%H:%M')"}}
            }
          },
          "zindex": 1
        }
      ]
    },
    {
      "name": "cell",
      "type": "group",
      "style": "cell",
      "from": {
        "facet": {
          "name": "facet",
          "data": "data_0",
          "groupby": ["day_start_datetime"]
        }
      },
      "sort": {
        "field": ["datum[\"day_start_datetime\"]"],
        "order": ["ascending"]
      },
      "encode": {
        "update": {
          "width": {"signal": "child_width"},
          "height": {"signal": "child_height"}
        }
      },
      "signals": [
        {
          "name": "facet",
          "value": {},
          "on": [
            {
              "events": [{"source": "scope", "type": "mousemove"}],
              "update": "isTuple(facet) ? facet : group(\"cell\").datum"
            }
          ]
        },
        {
          "name": "paintbrush_tuple",
          "on": [
            {
              "events": [{"source": "scope", "type": "mouseover"}],
              "update": "datum && item().mark.marktype !== 'group' ? {unit: \"child\" + '__facet_column_' + (facet[\"day_start_datetime\"]), fields: paintbrush_tuple_fields, values: [(item().isVoronoi ? datum.datum : datum)[\"_vgsid_\"]]} : null",
              "force": true
            },
            {
              "events": [{"source": "scope", "type": "dblclick"}],
              "update": "null"
            }
          ]
        },
        {
          "name": "paintbrush_tuple_fields",
          "value": [{"type": "E", "field": "_vgsid_"}]
        },
        {
          "name": "paintbrush_toggle",
          "value": false,
          "on": [
            {
              "events": [{"source": "scope", "type": "mouseover"}],
              "update": "event.shiftKey"
            },
            {
              "events": [{"source": "scope", "type": "dblclick"}],
              "update": "false"
            }
          ]
        },
        {
          "name": "paintbrush_modify",
          "update": "modify(\"paintbrush_store\", paintbrush_toggle ? null : paintbrush_tuple, paintbrush_toggle ? null : true, paintbrush_toggle ? paintbrush_tuple : null)"
        }
      ],
      "marks": [
        {
          "name": "child_marks",
          "type": "rect",
          "style": ["rect"],
          "from": {"data": "facet"},
          "encode": {
            "update": {
              "opacity": {"value": 1},
              "stroke": {"value": "white"},
              "strokeWidth": {"value": 1},
              "cursor": {"value": "pointer"},
              "fill": {"scale": "color", "field": "duration"},
              "fillOpacity": [
                {
                  "test": "(vlSelectionTest(\"paintbrush_store\", datum))",
                  "value": 1
                },
                {"value": 0.4}
              ],
              "tooltip": {
                "signal": "{\"title\": ''+datum[\"title\"], \"Speaker\": ''+datum[\"speaker\"], \"Location\": ''+datum[\"location\"], \"Date & Time\": timeFormat(datum[\"yearmonthdatehoursminutes_start_datetime\"], '%b %d, %Y %H:%M'), \"Duration (min)\": format(datum[\"duration\"], \"\")}"
              },
              "href": {"signal": "''+datum[\"url\"]"},
              "x": {"scale": "x", "field": "hoursminutes_start_datetime"},
              "x2": {"scale": "x", "field": "hoursminutes_end_datetime"},
              "y": {"scale": "y", "field": "location"},
              "height": {"scale": "y", "band": true}
            }
          }
        }
      ],
      "axes": [
        {
          "scale": "x",
          "orient": "bottom",
          "gridScale": "y",
          "grid": true,
          "tickCount": {"signal": "ceil(child_width/40)"},
          "domain": false,
          "labels": false,
          "maxExtent": 0,
          "minExtent": 0,
          "ticks": false,
          "zindex": 0
        }
      ]
    }
  ],
  "scales": [
    {
      "name": "x",
      "type": "time",
      "domain": {
        "data": "data_0",
        "fields": ["hoursminutes_start_datetime", "hoursminutes_end_datetime"]
      },
      "range": [0, {"signal": "child_width"}]
    },
    {
      "name": "y",
      "type": "band",
      "domain": {"data": "data_0", "field": "location", "sort": true},
      "range": [0, {"signal": "child_height"}],
      "paddingInner": 0.5,
      "paddingOuter": 0.25
    },
    {
      "name": "color",
      "type": "ordinal",
      "domain": {"data": "data_0", "field": "duration", "sort": true},
      "range": "category"
    }
  ],
  "config": {
    "axis": {"labelFontSize": 12, "titleFontSize": 12, "gridOpacity": 0},
    "style": {"cell": {"strokeOpacity": 0}}
  }
}
