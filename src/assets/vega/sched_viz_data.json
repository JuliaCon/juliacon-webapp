[
 {
  "start_datetime": "2020-07-30T13:00:00Z",
  "end_datetime": "2020-07-30T13:30:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "YVRWMA",
  "title": "NetworkDynamics.jl - Modeling dynamical systems on networks",
  "text": "NetworkDynamics.jl - Modeling dynamical systems on networks NetworkDynamics.jl is a tool for dynamical modeling and analysis of large, inhomogeneous, networked systems. It provides a convenient interface between LightGraphs.jl and DifferentialEquations.jl.\r\n\r\nWe introduce the basic syntax of our package and showcase applications ranging from neurodynamics to power systems. We conclude with a brief overview of advanced features such as multi-threading, support for SDEs and integration with the machine learning environment DiffEqFlux.jl. NetworkDynamics.jl is developed at Potsdam Insitut for Climate Impact Research (PIK) to facilitate modeling and analysis of large, inhomogeneous, networked dynamical systems. In such systems local dynamics as well as interactions can be described by differential and/or algebraic equations. ND.jl\r\n serves as the technical core of new efforts to develop state of the art power system models in Julia (PowerDynamics.jl).\r\n\r\nThe aim of this package is to provide the user with a convenient interface that allows them to focus on building models rather than to worry about numerical intricacies. This is achieved by combining the network package LightGraphs.jl with the fully-featured solver suite DifferentialEquations.jl. \r\n\r\nJulia turned out to be the perfect environment for our goal since it can be used like a scripting language for protoyping while matching the speed of FORTRAN and C when writing optimized code. \r\n\r\nIn this talk we introduce the basic constructors of NetworkDynamics.jl and showcase potential applications ranging from neurodynamics to power systems. We conclude with a brief overview of advanced features such as multi-threading, support for stochastic differential equations and integration with the machine learning environment DiffEqFlux.jl.",
  "url": "/talk/YVRWMA",
  "index": 1,
  "speaker": "Michael Lindner, Anton Plietzsch"
 },
 {
  "start_datetime": "2020-07-31T18:30:00Z",
  "end_datetime": "2020-07-31T19:00:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "LUSFK8",
  "title": "Simulating the Early Universe with Inflation.jl",
  "text": "Simulating the Early Universe with Inflation.jl I'll talk about my experience developing the `Inflation.jl` package in my research as a graduate student, and what I think Julia can do for computational and theoretical cosmology.\r\nThe talk should appeal to anyone interested in Julia's differential equations and parameter estimation suites, symbolic computation, package development, or the early universe. The early universe is a terribly violent place, but within the first 10<sup>-30</sup> seconds, cosmologists believe a process called inflation smoothed out the primordial universe into something that could expand and cool into our universe today.\r\n\r\nSimulating this process is a necessity for understanding the early universe, but in practice this means symbolically generating and then solving a challenging set of PDEs, and comparing their solutions to cosmological data. When the model includes unknown parameters, some parameter estimation is needed as well. I'll describe how Julia is the right tool for every step in this process.\r\n\r\n`Inflation.jl` generates the symbolic PDEs with a **symbolic tensor manipulation engine** built on `SymPy.jl` and `sympy.tensor.tensor`. Then `DifferentialEquations.jl` and related parameter estimation routines solve the PDEs, having little trouble even with high-dimensional inflation models.\r\n\r\nThe presentation will be organized into the lessons I learned while developing the package, and what I think we can all learn and apply to our own scientific computing projects, in cosmology and other fields.",
  "url": "/talk/LUSFK8",
  "index": 2,
  "speaker": "Robert Rosati"
 },
 {
  "start_datetime": "2020-07-30T17:30:00Z",
  "end_datetime": "2020-07-30T17:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "3YDDAE",
  "title": "JuliaLang Survey Results",
  "text": "JuliaLang Survey Results The results of the 2020 JuliaLang Survey ",
  "url": "/talk/3YDDAE",
  "index": 3,
  "speaker": "Viral B. Shah"
 },
 {
  "start_datetime": "2020-07-30T16:30:00Z",
  "end_datetime": "2020-07-30T16:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "BSQLL9",
  "title": "Adventures in Avoiding Allocations",
  "text": "Adventures in Avoiding Allocations Lessons learned while achieving a 100x speedup of TrajectoryOptimization.jl by eliminating allocations. Memory allocations can have a significant impact on run-time performance. My research focuses on developing state-of-the-art optimization solvers for doing real-time motion planning on nonlinear robotic systems, where run-time consistency is critical. This talk will discuss some practical considerations of writing non-allocating code in Julia, in the context of TrajectoryOptimization.jl, where we leveraged several techniques to achieve a 100x improvement in speed on many problems. This talk will include tips, tricks, and insights on how to avoid memory allocations and boost performance, as well as some discussion about the shortcomings of Julia with regards to memory management.",
  "url": "/talk/BSQLL9",
  "index": 4,
  "speaker": "Brian Jackson"
 },
 {
  "start_datetime": "2020-07-30T15:10:00Z",
  "end_datetime": "2020-07-30T15:55:00Z",
  "duration": 45,
  "location": "Track 1",
  "id": "7RL9UQ",
  "title": "Keynote: Juan Pablo Vielma",
  "text": "Keynote: Juan Pablo Vielma TBA TBA",
  "url": "/talk/7RL9UQ",
  "index": 5,
  "speaker": "Juan Pablo Vielma"
 },
 {
  "start_datetime": "2020-07-29T18:10:00Z",
  "end_datetime": "2020-07-29T18:20:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "PUHBMG",
  "title": "Applying Differentiable Programming to the Dark Channel Prior",
  "text": "Applying Differentiable Programming to the Dark Channel Prior The Dark Channel Prior was introduced by He, et al. as a method to dehaze a single image. Since its publication in 2010, other authors have sought to improve this dehazing method. Using the parameters that other authors have tuned as a guide, we parameterize the Dark Channel Prior dehazing method and utilize Zygote to apply gradient based optimization. This talk will briefly discuss the Dark Channel Prior implementation and will emphasize how it is possible to parameterize the algorithm and replace key portions with small neural networks. It will also cover gathering useful data and defining a meaningful loss function for measuring the performance of the dehaze algorithm. The hope is that others will see how programming in Julia can allow for easy application of differentiable programming in variety of scientific domains.",
  "url": "/talk/PUHBMG",
  "index": 6,
  "speaker": "tombsvj@ornl.gov"
 },
 {
  "start_datetime": "2020-07-31T19:20:00Z",
  "end_datetime": "2020-07-31T19:30:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "XBLMPG",
  "title": "The Julia Vega and Vega-Lite ecosystem",
  "text": "The Julia Vega and Vega-Lite ecosystem The Queryverse has a powerful visualization story that is based on the Vega ecosystem. This talk will demonstrate how one can use the Vega family of packages to easily create simple and advanced visualizations with Julia and how the various packages are integrated with each other. The Julia Vega ecosystem is made up of five packages and tightly integrated with the Queryverse. The packages that this talk will introduce are:\r\n- VegaLite.jl: the core grammar of interactive graphics package that makes it easy to create powerful figures with ease.\r\n- Vega.jl: if you need the power of the full Vega grammar, you can access it via this package. Creating figures with Vega.jl is more verbose, but gives you more control.\r\n- QuickVega.jl: this package provides a simple imperative API to create complicated figures without a full grammar of graphics API.\r\n- DataVoyager.jl: an interactive UI for data exploration that allows you to create Vega-Lite plots.\r\n- Lyra.jl: another interactive UI that is WYSIWYG editor for powerful Vega figures.\r\n\r\nI will also briefly on various front-ends that have native Vega and Vega-Lite support built in: ElectronDisplay.jl, the Julia VS Code extension, Jupyterlab and nteract.",
  "url": "/talk/XBLMPG",
  "index": 7,
  "speaker": "David Anthoff"
 },
 {
  "start_datetime": "2020-07-29T17:30:00Z",
  "end_datetime": "2020-07-29T17:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "SD8PSC",
  "title": "Terminal User Interfaces in Julia",
  "text": "Terminal User Interfaces in Julia Have you ever wondered how htop, vim or other terminal applications work? Do you want to add color, or formatting to the terminal output from your Julia application? Are you interested in building interactive terminal user interfaces for your users? Well, this is the talk for you! \r\n\r\nWe will discuss how terminal emulators work, features they make available and how you can leverage these features to create the best experience for you and your users in the terminal for a Julia application. Terminal User Interfaces can be developed using in-band ANSI escape and control sequences. Using the various escape and control sequences we can move the cursor to any position, erase lines or part of the screen, set formatting options such as bold, italic, foreground color, background color, change the cursor shape, etc. \r\n\r\nIn this talk I will go over best practices for dealing with the terminal from Julia, and some tips and tricks to draw text fast and efficiently to the terminal. I will also be discussing TERMIOS settings, such as cooked, raw and cbreak modes, and I will show how to read stdin and write to stdout while in these various modes.",
  "url": "/talk/SD8PSC",
  "index": 8,
  "speaker": "Dheepak Krishnamurthy"
 },
 {
  "start_datetime": "2020-07-30T12:30:00Z",
  "end_datetime": "2020-07-30T12:40:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "GX8QCX",
  "title": "Complex graphs in transportation networks with OpenStreetMapX.jl",
  "text": "Complex graphs in transportation networks with OpenStreetMapX.jl We will show how to perform modeling and large scale simulation of complex graphs using the `OpenStreetMapX.jl` package.\r\nAny transportation network can be represented as a complex directed graph where vertices are spread an Euclidean space. The library provides a bridging functionality between real world spatial data available in the OpenStreetMap project and `LightGraphs.jl` and makes it possible to run real-life-sized experiment on transportation networks along with various visualizations. A transportation system or even an entire city can be represented as a complex directed graph embedded in an Euclidean space. Such graph can model real world in 1:1 scale and be used to perform various numerical experiments. The [`OpenStreetMapX.jl`](https://github.com/pszufe/OpenStreetMapX.jl) package makes it possible to load the data from the [OpenStreetMap.org](https://www.openstreetmap.org/) project and processes such graphs with Julia. The package is using [LightGraphs.jl](https://github.com/JuliaGraphs/LightGraphs.jl) to represent the directed graph structure object along with meta related to spatial information.\r\n\r\nIn this talk the following areas will be discussed:\r\n- processing of [OpenStreetMap](https://www.openstreetmap.org/) data in Julia to obtain graph structures\r\n- visualizing graphs, maps and spatial data with [OpenStreetMapXPlot.jl](https://github.com/pszufe/OpenStreetMapXPlot.jl) (`GR`, `PyPlot` backends) as well as integration with [Leaflet](https://leafletjs.com/) via [folium](https://github.com/python-visualization/folium) and [PyCall](https://github.com/JuliaPy/PyCall.jl)\r\n- technical issues and tips for running massive scale agent based simulations  (e.g. with 1 million agents) of an entire city with real-world spatial data in 1:1 scale\r\n- various examples and scenarios of graph dynamics analysis with simulation models reflecting behavior of people and vehicles in virtual model of a city.\r\n\r\nThis project is co-financed by the Polish National Agency for Academic Exchange.",
  "url": "/talk/GX8QCX",
  "index": 9,
  "speaker": "Bogumił Kamiński, Przemysław Szufel"
 },
 {
  "start_datetime": "2020-07-30T17:00:00Z",
  "end_datetime": "2020-07-30T17:10:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "VP3W33",
  "title": "Rocket.jl: A Julia package for reactive programming",
  "text": "Rocket.jl: A Julia package for reactive programming __Rocket.jl__ is a native Julia implementation of reactive programming concepts. \r\nThe package uses the observable sequence and actor model to make it easier to work with asynchronous data streams and message-driven program architectures. The reactive programming (RP) paradigm is becoming increasingly popular. RP combines concepts from asynchronous data processing and the observer design pattern. Common applications are online data processing, interactive visualization and responsive user interfacing. The implementation of RP within a reactive framework allows developers to conveniently define relationships between data producers and consumers, and enables developers to build distributed and scalable applications more efficiently. Popular reactive frameworks in languages other than Julia include RxPy, RxJS, RxCpp and RxJava. \r\n\r\nIn areas such as machine learning, reinforcement learning and signal processing, data often arrive asynchronously and at different time scales. In this context, to reduce the developer's effort, RP offers a set of operators for composing, merging, filtering and transforming asynchronous data streams and provides a versatile API for listening for changes in these data streams. \r\n\r\nIn order to support RP in Julia, we have developed Rocket.jl, which is an efficient and flexible reactive extensions package, written in pure Julia. \r\n\r\nEfficiency is achieved by relying on Julia's type system and advanced optimisation techniques. Rocket.jl introduces additional abstractions that can largely be evaluated and in-lined at compile time, resulting in an efficient implementation of RP with almost zero overhead compared to traditional imperative programs. Comparative performance benchmarks are available on the GitHub repository.\r\n\r\nAt the same time, flexibility is maintained by making use of Julia's multiple dispatch system. A user can readily extend built-in functionality with additional operators and custom observables. The self-contained documentation of Rocket.jl provides a convenient introduction to RP, and offers a collection of examples and use cases that illustrates how users can customize the built-in functionality to their needs.\r\n\r\nWe compared Rocket.jl with two other Julia implementations of the RP, and applied the basic map and filter operators to an asynchronous data stream. In terms of computation time, Rocket.jl outperforms Signals.jl and Reactive.jl on average by a factor of 2 and 4, respectively. Memory usage is similar across these packages. \r\n\r\nWe believe that usability is a key factor when applying the RP to practical problems. Therefore we designed Rocket.jl as a RP package that enables developers to build flexible and efficient reactive systems.",
  "url": "/talk/VP3W33",
  "index": 10,
  "speaker": "Dmitry Bagaev"
 },
 {
  "start_datetime": "2020-07-31T17:30:00Z",
  "end_datetime": "2020-07-31T17:40:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "ZRC8HA",
  "title": "SmartHomy: Julia controlling your home and life!",
  "text": "SmartHomy: Julia controlling your home and life! After fighting with a Python smarthome implementation, I re-implemented it in Julia. I'll show how I set up Julia on a Raspberry Pi, control the sensors & devices with a mix of PyCall & Julia libraries, and how I unite it all under a UI written with JSServe.jl. ",
  "url": "/talk/ZRC8HA",
  "index": 11,
  "speaker": "Simon Danisch"
 },
 {
  "start_datetime": "2020-07-31T13:20:00Z",
  "end_datetime": "2020-07-31T13:30:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "HJTZNE",
  "title": "Julia Track Google Code In and Beyond",
  "text": "Julia Track Google Code In and Beyond This talk will describe work done using the NeuralNetDiffEq & Flux packages, as part of the Google Code In 2019 program, including writing a second order ODE solver. I will also talk about pursuing Julia beyond GCI, including how I used Julia to create Corona-Net, a binary and multi-class symptoms localisation system for COVID-19. Through this talk, I hope share on how GCI with Julia has accelerated my progress in ML, and how Julia can be used to help contribute to the fight against COVID-19. Some highlights for Google Code In were working with the NeuralNetDiffEq and Flux packages. In this talk, I will describe the process of writing a 2nd order ordinary differential equations solver using Neural Networks as part of GCI. Subsequently, I will cover how I used Flux to implement UNet's Fully-Convolutional Network architecture, for binary and multi-class (3 symptoms: ground glass, consolidation, pleural effusion) segmentation on the COVID-19 CT Segmentation Datasets, and discuss the Julia versus Python workflow in creating Corona-Net. Lastly, I will reflect on the impact of Google Code In Julia track on teenage ML & Open Source enthusiasts like myself, and how it ties in to my subsequent opportunities at NVIDIA. \r\n\r\n(A big thank you to Chris Rackauckas, Kirill Zubov, Avik Sengupta, Dhairya Gandhi, Avik Pal and Logan Kilpatrick for all their guidance in GCI, JuliaCon and beyond!)",
  "url": "/talk/HJTZNE",
  "index": 12,
  "speaker": "Choi Ching Lam"
 },
 {
  "start_datetime": "2020-07-30T16:40:00Z",
  "end_datetime": "2020-07-30T16:50:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "P7EQCK",
  "title": "Write a WebApp in Julia with Dashboards.jl",
  "text": "Write a WebApp in Julia with Dashboards.jl For many scientific workflows, and easy way to publish results interactively to the browser is very useful. However, most web frameworks have a steep learning curve, and involve knowledge of multiple languages and technologies. In this talk, we will show you how to create web applications in pure Julia, without any javascript or html using Dashboards.jl. [Dashboards.jl](https://github.com/waralex/Dashboards.jl) is a Julia interface to the Dash framework developed by the Plotly team. This talk is aimed at demonstrating how easy it is to write a high quality webapp in Julia, without having to write JavaScript, and still have it be really intuitive, almost as if one is writing HTML. \r\nOften in large projects, one of the key goals is to deliver a final solution to a large user base. In this talk, we will explore a simple way to deploy your solution behind a web server.\r\nWe will write a webapp that includes user input, automated HTTP request routing, and displaying analytical results with Plotly graphs.",
  "url": "/talk/P7EQCK",
  "index": 13,
  "speaker": "Dhairya Gandhi"
 },
 {
  "start_datetime": "2020-07-30T12:50:00Z",
  "end_datetime": "2020-07-30T13:00:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "J9Q8UR",
  "title": "AMDGPU Computing in Julia",
  "text": "AMDGPU Computing in Julia I will describe the current state of Julia's AMDGPU stack and how it compares\r\nto Julia's CUDA stack, interesting advantages of AMD's ROCm platform that\r\nwe can leverage from Julia, as well as my own perspective on the future of\r\nJulia's GPGPU ecosystem. NVIDIA's CUDA (Compute Unified Device Architecture) has been the dominant\r\ntoolkit for general-purpose GPU (GPGPU) computing for many years, and has\r\nexcellent support in Julia. However, AMD's ROCm (Radeon Open Compute) platform\r\nis rising in popularity, and many Julia users wish to use their AMD GPUs in\r\nJulia in the same ways that CUDA users can today. I will provide an overview\r\nof how to do exactly that, and what pitfalls users need to be aware of.\r\n\r\nBeyond past basic functionality, the open source nature of the AMDGPU kernel\r\nmodule makes support for advanced features like hostcall and unified memory\r\neasy to use, and enables opportunities to unify computations on CPUs and GPUs\r\nwithout much difficulty. I will present some short demos of how these useful\r\nfeatures can be used in practice\r\n\r\nGoing forward, a number of innovations in Julia's GPGPU ecosystem are\r\npossible. Merging compiler codebases, providing better abstractions for\r\ngeneric kernel programming, integration with distributed computing libraries,\r\nand automated GPU-ification of scientific and machine learning codes are all\r\non the table for the future. I will briefly explore what exciting\r\npossibilities users and developers have to look forward to, and what work\r\nstill needs to be done.",
  "url": "/talk/J9Q8UR",
  "index": 14,
  "speaker": "Julian P Samaroo"
 },
 {
  "start_datetime": "2020-07-31T13:10:00Z",
  "end_datetime": "2020-07-31T13:20:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "PTL7YB",
  "title": "BITE, a Bayesian glacier thickness estimation model",
  "text": "BITE, a Bayesian glacier thickness estimation model BITE is a new glacier thickness estimation model based on a mass-conserving forward model and a Bayesian inversion scheme. The model is fitted to available data using a Markov chain Monte Carlo (MCMC) method. The model is applied to more than 30,000 glaciers representing about 1/6 of the total. Thanks to  Julia's speed it was possible to calculate the 1e8 glacier thickness maps necessary for the MCMC procedure. Accurate estimations of glacier ice thickness and volume are indispensable for ice flow modelling, hydrological forecasts and sea-level rise projections. I present a new ice thickness estimation model [1,2] based on a mass-conserving forward model and a Bayesian inversion scheme (BITE.jl code on github [3]).  The model assimilates observations of ice thickness and speed using a Bayesian scheme implemented with a Markov chain Monte Carlo method, which calculates estimates of ice thickness and their error. The model is validated using 733 glaciers from four regions of the world with ice thickness measurements, and it is demonstrated that the model can be used for large-scale studies by fitting it to over 30,000 glaciers from around the globe. I will detail how Julia's speed as well as its productivity was indispensable in making the project succeed.\r\n\r\n[1] https://doi.org/10.1017/jog.2019.93,\r\n[2] https://juliacomputing.com/case-studies/bayesian.html,\r\n[3] https://github.com/mauro3/BITEmodel.jl",
  "url": "/talk/PTL7YB",
  "index": 15,
  "speaker": "Mauro Werder"
 },
 {
  "start_datetime": "2020-07-30T12:30:00Z",
  "end_datetime": "2020-07-30T12:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "LHBLF3",
  "title": "State Space Modeling for Macroeconomics with StateSpaceEcon",
  "text": "State Space Modeling for Macroeconomics with StateSpaceEcon We will show how StateSpaceEcon can be used for state space modeling in macroeconomics in Julia. This package can solve discrete-time systems of linear and non-linear equations that contain expectations of future values of the variables. The shocks to the system can be anticipated or unanticipated. This package can also find the steady state of the system and diagnose which variables are left undetermined. In addition, we will cover the Julia package TSeries to work with discrete time series. We will give an overview of what the Julia package StateSpaceEcon can do and how it works internally.\r\n\r\nMacroeconomics typically deals with discrete-time systems of non-linear equations that include expectations of future values of the variables. One way to solve for these expectations is the “rational expectations” hypothesis which posits that expectations should be consistent with the whole system.\r\n\r\nThe package StateSpaceEcon solves these kinds of systems using a stacked-time algorithm. This algorithm builds one large system of equations over all time periods and solves it using a root-finding algorithm such as Newton-Raphson. This approach works very well for large discrete-time systems of non-linear equations simulated with anticipated shocks. When shocks are anticipated, the expectation about the future values of the variables and their realisations are equal.\r\n\r\nBesides, the StateSpaceEcon package offer functionalities that facilitate working with state space systems in the context of macroeconomic policy analysis.\r\n1. The package dependency TSeries supports time series at low frequencies (e.g. integer, monthly, quarterly and yearly). Vectorized operations, indexing and assignments greatly facilitate data manipulations.\r\n2. A plan object allows to perfectly control which variables and shocks are endogenous (i.e. determined by the system) or exogenous (imposed on the system externally), which might change from one time period to the next.\r\n3. On top of anticipated shocks, the package can handle unanticipated shocks. In this case, the expectations and their realizations will differ.\r\n4. The rational expectations solver computes the Jacobian of the system using automatic differentiation. It uses sparse matrices throughout in order to handle the very large, but very sparse, Jacobian resulting from the stacked-time algorithm.\r\n5. The steady state of the system can be computed and analysed using QR decomposition to report states that are left undetermined. Functionalities allow for adding steady state equations and assumptions, in order to close the steady state system.\r\n6. Finally, the package StateSpaceEcon can linearize the system around the steady state or any other solution and use the linearized system for simulations.",
  "url": "/talk/LHBLF3",
  "index": 16,
  "speaker": "Nicholas Labelle St-Pierre, Boyan Bejanov, Atai Akunov"
 },
 {
  "start_datetime": "2020-07-30T16:10:00Z",
  "end_datetime": "2020-07-30T16:20:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "Y7ERM9",
  "title": "Introducing the @ccall macro",
  "text": "Introducing the @ccall macro In Julia 1.5, a new interface for calling dynamic libraries will be introduced: the `@ccall` macro. The talk goes over the new syntax, API and development process. As I was learning Julia, I was delighted with the ease and speed with which the language could access C libraries, but I found the specific syntax of `ccall` a bit cumbersome. I created a simple macro to provide what I felt was a more \"Julian\" syntax `ccall`. What I came up turned out to be very similar to a syntax that Julia's core developers had discussed previously, so I began the process of getting my macro into the language. [PR #32748](https://github.com/JuliaLang/julia/pull/32748)\r\n\r\nThis short talk will cover the new syntax presented by `@ccall`, what new features it has that the original `ccall` doesn't, and also provide some reflections on making my first contribution to the language and the helpful guidance provided by the Julia team.",
  "url": "/talk/Y7ERM9",
  "index": 17,
  "speaker": "Aaron Christianson"
 },
 {
  "start_datetime": "2020-07-29T18:30:00Z",
  "end_datetime": "2020-07-29T19:00:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "RYFMY9",
  "title": "SciML: Automatic Discovery of droplet fragmentation Physics",
  "text": "SciML: Automatic Discovery of droplet fragmentation Physics We consider a classical droplet fragmentation problem in fluid mechanics, and augment the system modeling with neural architectures using DiffEqFlux.jl. This augmentation speeds up experimental inquiries by training physically-interpretable neural architectures to recover the physical equations for the spatial and temporal variation of dynamic quantities. Together we showcase how Julia's unique differentiable programming ecosystem can be the basis for next-generation physical science. In this study, we consider a canonical fragmentation problem in fluid mechanics: splash of a drop on a liquid layer. Although this phenomena occurs in the twinkling of an eye (20 - 30 ms), it is an exquisitely regulated phenomena. The splash is typically accompanied by the formation of a thin cylindrical liquid sheet rising upwards, which resembles a crown. The crown sheet dynamics is typically characterized by a coupled set of mass and momentum balance equations. The thickness of the sheet is of the order of microns. In addition, the crown sheet thickness is found to have a spatial and temporal dependence, making it a dynamically changing quantity and difficult to probe experimentally. The sheet thickness has only recently been experimentally measured and theoretically validated in prior studies.\r\n\r\nIn the present work, we use a neural architecture to approximate the sheet thickness profile and use it in combination with the crown mass and momentum balance equations. We show that the thickness profile predicted by the trained neural architecture matches well with the experimentally measured thickness profile. In addition, the trained neural network is also able to recover the spatial and temporal dependence of the thickness profile, which matches well with the theoretically derived dependencies. \r\n\r\nThis augmentation of scientific modeling with neural networks is thus shown to play a major role in speeding experimentally driven inquiries, especially when studying dynamically varying quantities which are difficult to measure; such as the sheet thickness in this system. In addition, such augmentation paves way to make neural architectures more interpretable even when working with small datasets.",
  "url": "/talk/RYFMY9",
  "index": 18,
  "speaker": "Raj Dandekar"
 },
 {
  "start_datetime": "2020-07-29T12:50:00Z",
  "end_datetime": "2020-07-29T13:00:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "CE7FZA",
  "title": "AugmentedGaussianProcesses.jl, a full Gaussian Process toolkit",
  "text": "AugmentedGaussianProcesses.jl, a full Gaussian Process toolkit Gaussian Processes (GP) are an essential model of Bayesian non-parametrics. While multiple GP packages already exist in Julia such as Stheno.jl or GaussianProcesses.jl, `AugmentedGaussianProcesses.jl` has a larger scope of applications and is constantly updated with state-of-the-art methods. One of its specificity is to work with augmented variables to simplify inference. In this talk I will briefly explain this concept and show the potential of the package. Started as a very specific research project, [`AugmentedGaussianProcesses.jl`](https://github.com/theogf/AugmentedGaussianProcesses.jl) (AGP) is now a package with a much broader range of tools.\r\nA large class of different of problems are implemented such as Student-T likelihood, heterogeneous multi-output GP, heteroscedastic regression. Are also implemented various type of inference like variational inference, Gibbs sampling, Hamilton Monte-Carlo or even variational streaming!\r\nIn this sense AGP aims at being a competitor with general GP toolbox such as [`GPFlow`](https://github.com/GPflow/GPflow) or [`GPytorch`](https://gpytorch.ai/) with better or same training and prediction performance.\r\nHowever one of the additional strength of AGP is to convert problems which start as being intractable into easy ones via latent variable augmentations with a method based on my academic work. It is done so far case by case but current work will aim at being able to treat any problem.\r\nIn this talk I will showcase all the potential of AGP, and compare its performance with other Julia and Python solutions.",
  "url": "/talk/CE7FZA",
  "index": 19,
  "speaker": "Théo Galy-Fajou"
 },
 {
  "start_datetime": "2020-07-31T15:10:00Z",
  "end_datetime": "2020-07-31T15:20:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "PLFURQ",
  "title": "Pkg.update() or What's going on in Pkg-land?",
  "text": "Pkg.update() or What's going on in Pkg-land? Julia 1.0 was released two years ago and with that a brand new, rewritten from scratch, package manager called `Pkg`. This talk summarizes some of the improvements and features that have been added to `Pkg` since Julia 1.0 was released and also gives an overview of some of the plans for the future. The new package manager, `Pkg`, that comes with Julia 1.0 had many improvements over the previous one. However, just because Julia 1.0 was released, did not mean that the work on Pkg stopped. The biggest feature that has landed is the [Artifact system](https://julialang.org/blog/2019/11/artifacts/) which got added in 1.3. There are however also some other, smaller features that might have gone under the radar, for example:\r\n\r\n- New resolver strategy to reduce the number of resolver errors when adding packages but also reduce the number of unnecessary updates to packages when adding a package.\r\n- Built-in support for managing registries.\r\n- Argument passing to the test process\r\n- Support for instantiating a manifest without a corresponding project file.\r\n\r\nIn addition, there are some exciting features that are in development some of which are listed below:\r\n\r\n- Offline mode (aka airplane mode) allows one to develop packages in a convenient manner even while being offline.\r\n- Community driven hosting of packages and artifacts allows for package authors to see e.g. download stats for their packages.\r\n- Multiple packages in one repo.\r\n\r\nThis talk will summarize the new features of `Pkg` since 1.0 and also give an overview of plans and work in progress for future `Pkg` releases.",
  "url": "/talk/PLFURQ",
  "index": 20,
  "speaker": "Kristoffer Carlsson"
 },
 {
  "start_datetime": "2020-07-30T12:40:00Z",
  "end_datetime": "2020-07-30T12:50:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "ALMRKK",
  "title": "Parallel Implementation of Monte Carlo-Markov Chain Algorithm",
  "text": "Parallel Implementation of Monte Carlo-Markov Chain Algorithm This work presents a parallel implementation  of Monte Carlo-Markov Chain method for solving systems of linear algebraic equations using Julia and GPU accelerator. Julia 1.1.0 + CUDAnative.jl  provide several advantages regarding development and performance which help to delve  into  convergence and precision analysis. During the last 5 years we have been working on the iterative methods for solving  systems of linear algebraic equations. Recently our work has focused on estimates inverse matrix of the system and an efficient condicioner in order to obtain a  good approximate solution. We use for this task **Markov Chain-Monte Carlo** (MCMC) method as a theoretical basis. Iterative process, convergence, random sampling and  calculation of weights and estimators represent an exhaustive computational effort for the MCMC method as the size of the system of linear equations to be solved increases. In order to tackle this problem paralllel implementation using Julia 1.1.0 + CUDAnative is proposed.\r\nJulia programming language has captured our attention since it has consolidated, as an excellent development environment for scientific computation. Our contribution to the Julia conference 2020  is to show parallel implementation of the MCMC method highlighting  the advantages of CUDAnative.jl as a wrapper of GPU accelerators.  Convergence and scaling results are discused at the end of  the talk.",
  "url": "/talk/ALMRKK",
  "index": 21,
  "speaker": "Oscar A. Esquivel-Flores, Óscar Alvarado"
 },
 {
  "start_datetime": "2020-07-29T12:40:00Z",
  "end_datetime": "2020-07-29T12:50:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "KCP9NT",
  "title": "Reproducible environments with Singularity",
  "text": "Reproducible environments with Singularity Today’s science requires ever-increasing amounts of computation, so ideally, we should be able to easily shift our simulations to any nonpersonal machine and guarantee that we can exactly reproduce the result later.  \r\nTo do so, I would like to talk about a containerization software aimed at high performance computing called Singularity, the small package that I wrote for it, and the adventure of combining JIT with read-only containers. As the use of computing in science grows, more scientists are running ever larger computations. However, while the importance and use of a lab notebook is taught in many science degrees, the corresponding best practices for computer use often are not. From personal experience, I can tell that this leads to a growing number of random scripts and result files that after a week can’t be matched anymore. Alternatively, the code is sent to a server, and after requiring some small tweaks, the local and the remote version look different. A google search shows that this is not an uncommon problem, and there is an increasing number of blogs and papers addressing various aspects.  \r\n\r\nIn general, there are three aspect to a numerical result: the parameters, the code, and the environment. Specifically in Julia, the first two can be addressed by the combination of DrWatson.jl and Git, which makes it very easy to store the parameters used and the git hash of the commit with the code. This also includes the Manifest file, meaning that one can recreate the exact package environment, which is a major feature of Julia. However, this does not cover the binaries used by many packages. Examples include an NLopt algorithm throwing a segfault only on a specific version of Ubuntu, or a binary that only on Mac clashes with MKL.  \r\n\r\nOn the surface, containerization is the solution to these problems, but in practice the group doing the science and the group understanding containers seem mostly disjunct. After being in the first group until a few months ago, I now would like to present my approach and the small package [1] I wrote to facilitate it. It uses the scientific container software Singularity, which is less popular but more specialized than the widely known Docker (like Julia compared to Python). Differing from Docker, Singularity containers support various HPC hardware and software, do not require root to run, and integrate well into resource managers like SLURM. \r\n\r\nIn this talk, I would like to introduce my workflow based on DrWatson.jl and my own measures to create very minimal containers that enable results that are fully reproducible on any machine with the Singularity runtime. This will include general aspects about Singularity and specific one related to incorporating Julia.  \r\n\r\n[1] https://github.com/Crown421/Singularity.jl",
  "url": "/talk/KCP9NT",
  "index": 22,
  "speaker": "Steffen Ridderbusch"
 },
 {
  "start_datetime": "2020-07-30T18:30:00Z",
  "end_datetime": "2020-07-30T19:00:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "DVSD7Q",
  "title": "Solving partial differential equations in Julia with Gridap.jl",
  "text": "Solving partial differential equations in Julia with Gridap.jl We present `Gridap`, a novel finite element framework written in Julia. In the talk, we will show the software design behind the library and its application to solve a collection of well-known partial differential equations including linear, non-linear, single-field and multi-physics problems. To this end, we will consider different discretization techniques provided by the package such as continuous and discontinuous Galerkin methods with Lagrangian and Raviart-Thomas elements. The design of `Gridap` is quite unique for a finite element software package since it is not a simple translation of an existing C/C++ or FORTRAN code. In contrast, the library makes use of lazy-data structures that represent objects (e.g., elemental matrices and vectors) on the entire computational domain. This allows us the library developers to hide assembly loops and other core computations from the user-code leading to a very compact, user-friendly, syntax.  `Gridap` is designed both for research and teaching purposes.  It is a registered Julia package distributed under a MIT license and it is available at Github (https://github.com/gridap/Gridap.jl) .",
  "url": "/talk/DVSD7Q",
  "index": 23,
  "speaker": "Francesc Verdugo"
 },
 {
  "start_datetime": "2020-07-31T13:20:00Z",
  "end_datetime": "2020-07-31T13:30:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "JPGZK3",
  "title": "Climate models in 16bit: Arithmetic and algorithmic challenges",
  "text": "Climate models in 16bit: Arithmetic and algorithmic challenges Powered by Julia’s type-flexibility, various posit and float arithmetics are tested in ShallowWaters.jl and Oceananigans.jl for perspectives to accelerate climate models on modern computing architecture in 16bit, using either deterministic or stochastic rounding. Algorithmic bottlenecks with low precision are identified and information theory is used to find the best number format for a given algorithm, which led to the development of Sonums.jl – a number format that learns from data. The need for high precision calculations with 64bit floating-point numbers for weather and climate models has been questioned. Lower precision numbers can accelerate simulations and are increasingly supported by modern computing architecture. Posit numbers, a recently proposed alternative to floating-point numbers, claim to have smaller arithmetic rounding errors in many applications. As a standardized posit processor does not exist yet, we emulate posit arithmetic with SoftPosit.jl on a conventional processor. Julia’s type-flexibility easily allows to test benefits of posits compared to floats at 16bit in the Lorenz system, with ShallowWaters.jl and in Oceananigans.jl. We show that forecasts based on posits are clearly more accurate than floats. Mixing 16bit arithmetic with 32bit for critical computations strongly reduces errors and is promising for present-day float-based hardware. Reduced precision communication of boundary values with 16 or 8bit encoded as floats or posits introduces negligible errors, presenting a perspective for reduced data communication within a computer cluster.  Stochastic rounding modes, that are exact in expectation, are found to improve simulations at 16bit and mimic uncertainties. Algorithmic bottlenecks with low precision are identified using Sherlogs.jl to facilitate the transition towards 16bit arithmetic. We analyse algorithms form an information theory perspective to find the best number format for a given application. This approach led the the development of Sonums.jl, a number format that is optimal once trained on data to minimize the rounding error. Although difficult to implement in hardware, we provide perspectives for Sonums in data compression. The results promote the potential of 16bit formats for at least parts of complex weather and climate models, where rounding errors would be entirely masked by intitial condition, model or discretization error.\r\n\r\nCo-authored by\r\n- Ali Ramadhan, MIT, Cambridge, USA\r\n- Peter Dueben, ECMWF, Reading, UK\r\n- Tim Palmer, University of Oxford, UK",
  "url": "/talk/JPGZK3",
  "index": 24,
  "speaker": "Milan Kloewer"
 },
 {
  "start_datetime": "2020-07-30T16:10:00Z",
  "end_datetime": "2020-07-30T16:40:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "XGHSWW",
  "title": "Julia and C++: a technical overview of CxxWrap.jl",
  "text": "Julia and C++: a technical overview of CxxWrap.jl [CxxWrap.jl](https://github.com/JuliaInterop/CxxWrap.jl) simplifies the creation of Julia packages that rely on C++ libraries for part of their functionality. Unlike [Cxx.jl](https://github.com/JuliaInterop/Cxx.jl), the focus is on writing the wrapper code in C++, compiling it into a small shared library, inspired by the approach of Boost.Python for Python. Since the previous presentation in 2016, the package has evolved quite a bit, so after a brief recap of the basic functionality the talk will focus on some of the new design choices and their implementation, which will hopefully clarify some aspects that are not easy to convey in documentation.\r\n\r\nWe will start with a short introduction, showing the basic principle of using `ccall` on a C++ function pointer to make calling any kind of C++ function possible. From there, we will explain the mapping of argument and return types, especially focusing on the recent changes for integer number types. Since CxxWrap v0.9 there is also a much more rigorous treatment of pointers, references and values, which all have a distinct type now. We will explain some of the design choices behind these new types, as well as the new `@cxxdereference` macro that simplifies writing Julia functions acting on CxxWrap-generated types.\r\n\r\nWe end the presentation with a discussion of the new C++ standard library functionality and show how to extend this for as yet unsupported container types.",
  "url": "/talk/XGHSWW",
  "index": 25,
  "speaker": "Bart Janssens"
 },
 {
  "start_datetime": "2020-07-30T18:40:00Z",
  "end_datetime": "2020-07-30T18:50:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "EVJNMH",
  "title": "Julia for Knowledge Mining in Industry 4.0",
  "text": "Julia for Knowledge Mining in Industry 4.0 Industry 4.0, simply I4.0 or I4, refers to the “Fourth Industrial Revolution” that's the new digital industrial technology for transforming industries into smart/intelligent industries (iIndustry) by connecting machines with intelligent robots and Industrial Internet of Things (IIoT) devices. In this talk, we have addressed and proposed several issues for knowledge mining from Industrial Big Data (iBigData) in Industry 4.0 using Julia programming language. Industry 4.0 engenders and analysis data across the machines in iIndustry to produce high-quality products at low costs, and changes traditional production relationships among suppliers, producers, and customers. Industry 4.0 amalgamates nine technologies to transform industrial production, which includes: (1) Big Data Analytics, (2) Autonomous Robots/ Robotics, (3) Simulation, (4) Horizontal & Vertical System Integration, (5) Industrial Internet of Things (IIoT), (6) Cybersecurity, (7) Cloud Computing, (8) Additive Manufacturing (such as 3-D printing), and (9) Augmented Reality. I4.0 uses Decision Support Systems (DSS) incorporating with knowledge mining techniques to know what actions need to take in future that help manufacturers to optimise their operations quickly. The fourth revolution ameliorates the industries with intelligent computing fuelled by data with Machine Learning (ML) and Data Mining (DM) technologies. In this talk, we have addressed several issues for knowledge mining process in Industry 4.0 using Julia programming language. Knowledge mining is the process of extracting hidden information/patters from Industrial Big Data (iBigData) to lucid market trends, customer preferences and other information that’s useful to businesses. Industrial Big Data is extremely large that we can't store all the data into a single computer/machine; so, we need more scalable and robust learning approach to deal with iBigData. We have collected the data set with 1067371 instances named “Online Retail II” from UCI Machine Learning Repository (https://archive.ics.uci.edu/) and implemented RainForest and BOAT (Bootstrapped Optimistic Algorithm for Tree construction) learning algorithms using Julia. RainForest and BOAT are basically decision tree (DT) based supervised learning algorithms for classifying Big Data. We have presented a new decision tree merging approach that addresses the repetition and replication problems in tree pruning. Industrial Big Data is multivariate, high-dimensional, noisy, and also the characteristics of data can be changed over the time (e.g. concept drifting in data streaming environment). In this talk, we also discussed the how we can handle the noisy and streaming data; find the most informative training instances, so that we can build a learning model with minimum number of instances. For selecting informative training instances, we have used simple partition-based clustering approach and implemented clustering algorithm in Julia.",
  "url": "/talk/EVJNMH",
  "index": 26,
  "speaker": "Dewan Md. Farid, Swakkhar Shatabda, Aicha Sekhari, Yacine Ouzrout"
 },
 {
  "start_datetime": "2020-07-30T13:30:00Z",
  "end_datetime": "2020-07-30T14:00:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "9A8DCP",
  "title": "GeometricFlux.jl: Geometric Deep Learning on Flux",
  "text": "GeometricFlux.jl: Geometric Deep Learning on Flux GeometricFlux, a Julia package for geometric deep learning on graph.  GeometricFlux relies on Flux/Zygote framework, integrates with JuliaGraph ecosystem and supports CUDA. Geometric deep learning plays a role in modeling non-Euclidean data with graph structure. I introduce GeometricFlux, a Julia package for geometric deep learning on graph. GeometricFlux relies on Zygote as automatic differentiation engine, accepts graph data structure provided by JuliaGraph. GeometricFlux layers are compatible with Flux layers and supported by CuArrays. It will be a competitive platform against other framework.",
  "url": "/talk/9A8DCP",
  "index": 27,
  "speaker": "Yueh-Hua Tu"
 },
 {
  "start_datetime": "2020-07-30T16:30:00Z",
  "end_datetime": "2020-07-30T16:40:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "GFE3DB",
  "title": "JSServe: Websites & Dashboards in Julia",
  "text": "JSServe: Websites & Dashboards in Julia This talk presents JSServe.jl, a high performance framework to easily combines interactive plots, markdown, widgets and plain HTML/Javascript in Jupyter / Atom / Nextjournal and on websites. ",
  "url": "/talk/GFE3DB",
  "index": 28,
  "speaker": "Simon Danisch"
 },
 {
  "start_datetime": "2020-07-29T18:45:00Z",
  "end_datetime": "2020-07-29T19:30:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "R7EPKS",
  "title": "Probabilistic Programming in Julia",
  "text": "Probabilistic Programming in Julia Julia's PPL community is strong and growing. The various groups already have a strong professional relationship, but a BoF would help to formalize this somewhat, as well as being a good introduction for newcomers to the community Possible topics (just a starting point really):\r\n- Standardizing output data structures for samplers\r\n- Making distributions extensible, and AD- and GPU-friendly\r\n- Interop across PPLs\r\n- Connecting with non-PPL libraries (e.g. Flux)\r\n- What existing (Python, etc) capabilities is Julia PPL missing?\r\n- What's next for Julia PPL?\r\n- What's next for PPL in general?",
  "url": "/talk/R7EPKS",
  "index": 29,
  "speaker": "Chad Scherrer"
 },
 {
  "start_datetime": "2020-07-31T13:30:00Z",
  "end_datetime": "2020-07-31T14:00:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "UUECGJ",
  "title": "Intertwined Economic and Energy Analysis using Julia",
  "text": "Intertwined Economic and Energy Analysis using Julia Energy and the economy are deeply intertwined yet the models typically employed for energy analysis treat the energy sector in isolation while lacking the capability to robustly represent the U.S. economy.  This talk introduces the SLiDE.jl package, which leverages U.S. economic data to assess economic implications of energy infrastructure planning to answer these and other questions. The Scalable Linked Dynamic Equilibrium (SLiDE) model is an implementation of a computable general equilibrium (CGE) model. CGE models are commonly used for detailed regional economic analysis of inputs, outputs, prices and quantities of various economic sectors to inform policy decisions. This talk will focus on the development of the data management approach with a focus on usability.\r\n\r\nWe will delve into the inner workings of the SLiDE module to explore the benefits and challenges of using Julia for data science applications. Techniques used to standardize the publicly available blueNOTE dataset include autogenerated and populated structs and powerful multiple dispatch and methods. Discussion will include the design-thinking approach taken to create a user-friendly interface to scale the model in space, time, and sector and encourage further adoption of Julia in policy analysis.",
  "url": "/talk/UUECGJ",
  "index": 30,
  "speaker": "Caroline Hughes"
 },
 {
  "start_datetime": "2020-07-29T16:10:00Z",
  "end_datetime": "2020-07-29T16:20:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "XW9PNR",
  "title": "Using Julia and group theory  to describe Molecular Vibrations",
  "text": "Using Julia and group theory  to describe Molecular Vibrations Julia is used along applied group theory  to solve  the problem of describing and classifying molecular vibrations, a  highly demanding computational  problem. The solution of this problem  using applied group theory requires, high numerical capabilities, a fast and an extensive use of matrix operations and the possibility  to efficiently handle different kinds of  data structures.  It is shown that Julia is one of the best options  for  implementing fast, reliable and accurate solutions. We present an overview of the program for the description and classification of molecular vibrations we have been developing using Julia, along with a systematic and highly effective method derived  from applied group theory.  This overview emphasizes the computational challenges that this real-time description  presents and  the  solutions offered by Julia.\r\n \r\n The description of molecular vibrations in real-time  implies a series of complex and  highly demanding  computational tasks that we have implemented in Julia :\r\n\r\n1) Given the coordinates of the atoms as input, we determine the point symmetry group of the molecule.  Extensive use of matrices and fast calculation of  eigenvectors and eigenvalues is a must.\r\n\r\n2) Once the point group is determined, we identify the symmetry operations using their matrix representations. Once again, we have relied on Julia's capabilities of matrix diagonalization, this time in the case of  asymmetric matrices with complex eigenvalues and eigenvectors. \r\n\r\n3) Finally we determine and classify the normal modes of vibration using a matrix representation of invariant subspaces that allow a complete classification of the vibrational modes. \r\n\r\nOnly we have to add that, knowledge of  the  molecular vibrational modes is a must in many scientific and technological applications. Its  importance is out of discussion.\r\n\r\nAlthough many programs have been developed, mainly in Fortran, most of them are highly sophisticated and depends upon expensive hardware resources.\r\n\r\nJulia offers the invaluable opportunity to develop a simple, reliable and low-cost resources program with high standard of quality that requires no more than a simple laptop.",
  "url": "/talk/XW9PNR",
  "index": 31,
  "speaker": "León Alday, Roberto Bernal-Jaquez"
 },
 {
  "start_datetime": "2020-07-30T16:50:00Z",
  "end_datetime": "2020-07-30T17:00:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "8SZSBE",
  "title": "Interactive data dashboards with Julia and Stipple",
  "text": "Interactive data dashboards with Julia and Stipple The presentation will demonstrate how to build and publish interactive web based data dashboard using Stipple, the Reactive UI library for Genie. The participants will learn the fundamentals of developing and deploying Stipple apps, allowing them to apply the skills to easily and efficiently create their own interactive Julia data dashboards. We will start by taking a quick look at the technology behind Stipple and its Reactive UI components, to provide a high level understanding of the various layers and the interactions between them. \r\n\r\nThe bulk of the talk will demonstrate how to build a fully functional interactive data dashboard using the German Credit dataset - and how to publish it, with one click, on one of the major hosting platforms. All in just 10 minutes!",
  "url": "/talk/8SZSBE",
  "index": 32,
  "speaker": "Adrian Salceanu"
 },
 {
  "start_datetime": "2020-07-30T16:20:00Z",
  "end_datetime": "2020-07-30T16:30:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "3LUQVT",
  "title": "Design documents are great, and here’s why you should consider w",
  "text": "Design documents are great, and here’s why you should consider w Whether you have an existing package, are planning a re-write or creating a new package, design documents can help explain the problem you are trying to solve. In this talk, we will walk through AWSCore as a use-case, discuss what design documents are, their benefits, and showcase how they help users understand packages they haven't seen before. A design document is a written description of a software product, that a software designer writes to give a development team overall guidance to the architecture of the project. They include everything from the general architecture, internal/external dependencies, and in/out of scope tasks, among other things.\r\n\r\nWhen an individual or team starts contributing to a new package, it can be overwhelming at first. Finding out which components do what, how they interact with each other, and why certain design decisions were made. A design document can help clarify these general questions and get a new contributor started in understanding the package. Design documents are also helpful in producing an overview of the current architecture, showcasing alternative solutions, and explaining why certain design decisions were made.\r\n\r\nIn this talk, we will discuss what a design document is, why you should consider creating one and what components go into it. By the end, you will know how to create a design document that will capture a snapshot of your package (or future package), outline guiding principles and summarize design decisions that will help lead to improvements in future revisions.",
  "url": "/talk/3LUQVT",
  "index": 33,
  "speaker": "Matt Brzezinski"
 },
 {
  "start_datetime": "2020-07-31T18:00:00Z",
  "end_datetime": "2020-07-31T19:30:00Z",
  "duration": 90,
  "location": "Track 1",
  "id": "MCFFUY",
  "title": "Minisymposium on Partial Differential Equations",
  "text": "Minisymposium on Partial Differential Equations Chairs: \r\nJürgen Fuhrmann (Weierstrass Institute Berlin), \r\nPetr Krysl (UCSD)\r\n\r\nThe talks at the minisymposium present several packages devoted to the solution of partial differential equations based on various approaches to space discretization including finite element, finite volume, boundary element and spectral methods.\r\nIn a accompanying BoF session, developments of the PDE simulation infrastructure shall be discussed. Julia with its near optimal scalar performance, built-in multithreading, multiprocessing, and packages for GPU computing in combination with its generic programming facilities provides a new opportunities to implement high- performing and easy to uses packages for PDE solution.\r\n\r\nOn the other hand, it is likely that the full potential of Julia with respect to this problem class has not been reached yet. The ecosystem of packages and the language itself have barely matured.\r\n\r\nWe propose a minisymposium whose contributors present their Julia packages connected with the solution of partial differential equations and systems thereof. The talks shall  appeal to a broader public.\r\n\r\nThe minisymposium shall be accompanied by a BoF session discussing of possible developments of features and packages for PDE simulations which would help Julia to become one of the primary choices for researchers, scientists and engineers interested in PDE simulations.",
  "url": "/talk/MCFFUY",
  "index": 34,
  "speaker": "Jürgen Fuhrmann"
 },
 {
  "start_datetime": "2020-07-31T13:30:00Z",
  "end_datetime": "2020-07-31T13:40:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "9GDBEW",
  "title": "Julia in Education for Generation Z",
  "text": "Julia in Education for Generation Z The students who belong to Generation Z or post-millennials have access to gadgets such as smartphones even before they go to school. This makes them technology savvy and at the same time, they get bored easily in a traditional classroom setting. It becomes necessary to use modern tools and techniques in the classroom to engage students in activities. In this BOF, I will demonstrate how we can use smartphone and visual programming tools to engage Generation Z students in the classroom. The students who belong to Generation Z or post-millennials have access to gadgets such as smartphones even before they go to school. This makes them technology savvy and at the same time, they get bored easily in a traditional classroom setting. It becomes necessary to use modern tools and techniques in the classroom to engage students in activities. Also, governments are promoting “Bring Your Own Device (BYOD)” concept in education which can be a boon to those who cannot afford a computer or laptop. In this BOF, I will demonstrate how Julia can be installed on a smartphone and execute Julia programs on the smartphone. Next, I will also introduce visual programming tools like flowgorithm which is a flowchart interpreter to generate Julia code (The Julia code generator for flowgorithm is available at https://github.com/gcdeshpande/Julia-Code-Generator).  Then I will demonstrate how we can import Python packages in Julia for creative programming. Then the session will be open for the audience where they can share their thoughts on the topic.",
  "url": "/talk/9GDBEW",
  "index": 35,
  "speaker": "Gajendra Deshpande"
 },
 {
  "start_datetime": "2020-07-29T12:30:00Z",
  "end_datetime": "2020-07-29T12:40:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "8VUMUA",
  "title": "Parallelization, Random Numbers and Reproducibility",
  "text": "Parallelization, Random Numbers and Reproducibility We will show how the different types of parallelization in Julia interact with random number generators and shared state. Using the parametric bootstrap in MixedModels, we will show to how use threads effectively with a shared random number generator to give the same result as the serial version. Random-number generators present a special problem for both thread- and process-based parallelism, especially when guaranteeing a reproducible, unbiased stream that is independent of the number of concurrent workers. In other words, we require the ability to parallelize a replicated, stochastic operation in such a way that we will get the same result as the serial computation with the same RNG and seed. For thread-based parallelism, this can easily be achieved via a shared RNG with appropriate locking.  We demonstrate this with the implementation of the parametric bootstrap in MixedModels. The parametric bootstrap is embarrassingly parallel computation, yet depends on a stochastic element and thus random-number generation.  In particular, we examine how the granularity of locking impacts the 'striping' of random numbers across threads and thus reproducibility. We finish by contrasting our approach to the use of 'fast-forwarding' and copying the RNG and discussing issues with generalizing these approaches to process-based parallelism.",
  "url": "/talk/8VUMUA",
  "index": 36,
  "speaker": "Phillip Alday"
 },
 {
  "start_datetime": "2020-07-31T18:30:00Z",
  "end_datetime": "2020-07-31T19:00:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "Z8WWNV",
  "title": "Natural Language Processing in Julia",
  "text": "Natural Language Processing in Julia The JuliaText ecosystem provides various packages for working with human languages. In this talk, we show the usage of these JuliaText packages with Flux.jl for Natural Language Processing (NLP) with a focus on deep learning-based approaches. Natural Language Processing (NLP) enables the computers to analyse, understand and read human languages. In the past decade, tremendous growth has been witnessed in NLP owing to milestones like word embeddings, neural networks for NLP, attention and pre-trained language modelling. JuliaText packages, together with Flux, makes Deep Learning for NLP easy in Julia.\r\n\r\n## Packages\r\n\r\nThe following packages of JuliaText mainly will be discussed:\r\n- `TextAnalysis.jl` is a package for text analysis and APIs for language processing pipelines like pre-processing, stemming, Named Entity Recognition, Part Of Speech Tagging along with CRFs and ULMFiT.\r\n- `WordTokenizers.jl` provides various high-speed tokenizers and APIs for writing custom tokenizers for natural languages.\r\n- `CorpusLoaders.jl` contains a variety of (lazy) loaders for NLP corpora.\r\n- `Embeddings.jl` for working with Word Embeddings.\r\n\r\n## Talk\r\n\r\nThe attendees will gain working knowledge about how to apply the package for NLP in Julia.\r\nThe talk will encompass the following:\r\n- Tokenizers (Sentence splitters and word tokenizers) in WordTokenizers.jl\r\n- Preprocessing using TextAnalysis.jl: Stemming, text normalizing, spelling correction and stopword removal.\r\n- Word Embeddings (mapping words to vectors of numbers) using Embeddings.jl\r\n- Recurrent Neural Networks and Language models.\r\n\r\nAs a demonstration, we will also be using the packages to build an NLP pipeline for a neural network model to address the task of Sentiment Analysis over noisy data. We will then proceed to demonstrate using language models like ULMFiT for this task. As a bonus, the trained model will be run for the sentiment classification of messages from Julia Slack.",
  "url": "/talk/Z8WWNV",
  "index": 37,
  "speaker": "Ayush Kaushal"
 },
 {
  "start_datetime": "2020-07-29T16:20:00Z",
  "end_datetime": "2020-07-29T16:30:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "AWYKZL",
  "title": "Bayesian Agent-Based Monte Carlo Option Pricing with Julia",
  "text": "Bayesian Agent-Based Monte Carlo Option Pricing with Julia We will demonstrate the efficacy of pricing and hedging financial options\r\nvia a new method called Bayesian Agent-Based Monte Carlo (BABMC). This\r\nmethod nests the cananonical Black-Scholes-Merton approach to option\r\npricing and hedging, but can readily deal with transactions costs,\r\nindivisibilities, discrete rebalancing and uncertain volatilities. We will give an overview of the new package `Bruno.jl` for financial\r\noption analytics. This package approaches option pricing and hedging\r\nfrom the perspective of the derivatives market-maker who is modeled\r\nas a Bayesian agent. The problem of hedging is viewed as an optimal\r\nstatistical decision under the agent's posterior predictive\r\ndistribution.\r\n\r\nCrucially, option pricing and hedging are performed under the\r\nreal-world pricing distribution and do not rely upon assumptions\r\nof risk neutrality. While we do not rely upon risk-neutral\r\nassumptions, conditions of risk-neutrality are obtained in the limit\r\nin the absence of market frictions. The arbitrage trading strategy\r\nof the market-maker is modeled directly. This avoids the assumption\r\nof ideal markets in the form of standard \"No-arbitrage\" conditions.\r\n\r\nOne important benefit of this approach is that we need only use\r\nhistorically observed underlying asset prices. Additionally, we\r\ncan easily accommodate market frictions such as transaction costs,\r\nindivisibilities, discrete rebalancing effects and uncertainties\r\nin volatility. These every-day market realities have proven extremely\r\nchallenging to include in the standard equilibrium modeling paradigm.\r\n\r\nWe will demonstrate the approach using historical data for the Standard\r\n& Poor's 500 index.",
  "url": "/talk/AWYKZL",
  "index": 38,
  "speaker": "Tyler Brough"
 },
 {
  "start_datetime": "2020-07-31T12:30:00Z",
  "end_datetime": "2020-07-31T13:00:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "NPWSWB",
  "title": "A Computational Textbook for Teaching Data Science with Julia",
  "text": "A Computational Textbook for Teaching Data Science with Julia Data science and machine learning courses are in high demand with growing enrollments. We discuss our experience teaching a computational DS&ML course with 250+ students that is designed to scale and accommodate hundreds more. We highlight the use of experiential learning, just-in-time presentation of key concepts, and near real-time feedback on students’ understanding. We will demo a computational textbook that makes teaching a scalable DS&ML course enjoyably easy. Over the past two years at the University of Michigan, we have successfully taught computational data science and machine learning using Julia to over a thousand graduate students, spanning over 80 disciplines. We've scaled to support 275 enrolled students (Fall 2019) and expect to scale to over 500 in the very near future. The course is taught in a hybrid lecture-lab style which presents students with the opportunity to experience hands-on, interactive, inquiry-based learning. Student feedback has been overwhelmingly positive. We will present a hands-on demo, featuring selected content from the course, and invite the audience to experience it for themselves.\r\n\r\nWe will present our vision for an interactive computational textbook platform designed to stimulate deeper conversations between students and the material that they are attempting to master. The primary technique used to facilitate this deeper engagement is the punctuation of instructional content (such as motivation, math fundamentals, theorems, proofs, etc.) with short, self-contained exercises that are designed to allow the student to constantly check their understanding. Exercises include conceptual questions to check comprehension of the underlying content, auto-graded programming assignments to practice the ability to put ideas into practice as code, and free-response prompts to allow the student to make their own observations and draw the appropriate conclusions.\r\n\r\nThe effect of this constant \"self-checking\" is two-fold. First, students are forced to more rigorously develop foundational knowledge before moving on to more advanced topics. This sets students up for success when the more advanced content is presented and avoids the dreaded \"content paralysis\" phenomenon where students are overwhelmed by the sheer scope of content on first glance (this usually manifests itself as a student blindly running code in “run-all mode\" in an attempt to produce the desired results instead of actually understanding what they are doing). Second, this framework allows an author to more carefully design content to encourage a guided learning experience. The author can design a narrative, complete with exposition (what is this algorithm?), conflict (when does it fail?), and resolution (how can we fix it?). Our demo will allow you to experience how much more immersive “living” computational textbooks written in this way can be.",
  "url": "/talk/NPWSWB",
  "index": 39,
  "speaker": "Travis DePrato, Raj Rao"
 },
 {
  "start_datetime": "2020-07-30T17:10:00Z",
  "end_datetime": "2020-07-30T17:20:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "KKUCBL",
  "title": "Beyond Overdubbing: Building a Generic IR Tracker",
  "text": "Beyond Overdubbing: Building a Generic IR Tracker A case of IR-based metaprogramming, going beyond just nonstandard function execution. This talk introduces the design and development goals of [IRTracker](https://github.com/TuringLang/IRTracker.jl), a library for dynamic and recursive tracking of Julia’s intermediate representation (IR) during the execution of any Julia function.  I will describe the relative merits of [Cassette](https://github.com/jrevels/Cassette.jl) and [IRTools](https://github.com/MikeInnes/IRTools.jl) for implementing such a project, and discuss some insights about the current metaprogramming infrastructure.  Then, I’ll provide an overview of the resulting package, which is designed with the application to probabilistic programming in mind (specifically, its use within [Turing](https://github.com/TuringLang/Turing.jl) for automatic computation of Gibbs conditionals).\r\n\r\nThe code transformation mechanism is currently specialized to insert the necessary tracking statements, but it can be easily abstracted out.  This could serve as the basis for the implementation of IR transformations for other abstract interpretation mechanisms, especially such which need access not only to function calls, but also to branches performed during execution.",
  "url": "/talk/KKUCBL",
  "index": 40,
  "speaker": "Philipp Gabler"
 },
 {
  "start_datetime": "2020-07-31T14:20:00Z",
  "end_datetime": "2020-07-31T15:05:00Z",
  "duration": 45,
  "location": "Track 1",
  "id": "LG3GQP",
  "title": "Keynote: Linda Petzold",
  "text": "Keynote: Linda Petzold TBA TBA",
  "url": "/talk/LG3GQP",
  "index": 41,
  "speaker": "Linda Petzold"
 },
 {
  "start_datetime": "2020-07-31T13:20:00Z",
  "end_datetime": "2020-07-31T13:30:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "ETWX8X",
  "title": "HydroPowerModels.jl: Impacts of Network Simplifications",
  "text": "HydroPowerModels.jl: Impacts of Network Simplifications Planning the operation of Power Systems is an important task to guarantee low operational costs and reliability. In practice, model simplifications are used given problem complexity. The objective of this work is to propose a framework, comprised of a methodology and the [HydroPowerModels.jl](https://github.com/andrewrosemberg/HydroPowerModels.jl) Julia package for testing the operative and economic impact of modeling simplifications over the network power-flow in hydrothermal power systems. One of the most efficient algorithms for solving hydrothermal operation planning problems, which are large-scale multi-stage stochastic models, is the so-called stochastic dual dynamic programming (SDDP) algorithm. Operation planning of power systems aims to assess the value of the scarce resources (e.g. water) to feed short-term dispatch models used in the actual implementation of the decisions. When the planning model significantly deviates from the reality of the implemented operation, decision policies are said to be time-inconsistent. Recent literature has explored different sources of inconsistency such as time-inconsistent dynamic risk measures, inaccurate representation of the information process and simplifications in the network planning model. This work addresses the time-inconsistency due to simplifications in the network representation in the planning model extending the existing literature.\r\n\r\nThe objective of this work is to propose a framework, comprised of a methodology and an open-source computational package, for testing the operative and economic impact of modeling simplifications over the network power-flow in hydrothermal power systems. \r\n\r\nIn this presentation, we will discuss how the [HydroPowerModels.jl](https://github.com/andrewrosemberg/HydroPowerModels.jl) package models hydrothermal operation planning problems and how we have to use it to study the impacts of time-inconsistency in the operation of hydrothermal power systems.",
  "url": "/talk/ETWX8X",
  "index": 42,
  "speaker": "Andrew Rosemberg"
 },
 {
  "start_datetime": "2020-07-29T13:50:00Z",
  "end_datetime": "2020-07-29T14:00:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "ACJRET",
  "title": "Generating automatically labelled ML datasets with Lattice.jl",
  "text": "Generating automatically labelled ML datasets with Lattice.jl Machine learning research relies heavily on curated data sets for experimentation, measuring performance, and communicating results.  Labeling data is a labor most researchers would rather avoid, so the same standard data sets are constantly reused.  Lattice.jl is our attempt to provide a much wider variety of machine learning datasets with little or no human effort. Machine learning datasets are samples taken from a domain and an underlying data generating distribution.  For example, the MNIST dataset is a sample from the set of all 28x28 grayscale images (the domain) that are created by humans writing the digits 0-9 (the data generating distribution).  The examples in datasets are used to train models to perform machine learning tasks; for MNIST, the task is usually “what digit is this?” but the task could also be “is this digit odd?” or “was this digit written by a left-handed person?”  Creating the label for each example--evaluating the task applied to that example--usually requires some sort of human effort.\r\n\r\nLattice.jl provides a framework for describing and abstracting domains, data generating distributions, and machine learning tasks for those problems where it is possible for a computer program to automatically generate examples.  To explain the usefulness of such a framework, consider generating examples from an image domain. Since Lattice first generates a simple internal representation of the example and then uses the representation to draw the image, it is also possible to automatically create perfect labels for a wide variety of different tasks applied to each image.  The labels and generating distributions can be manipulated to simulate many different kinds of labeling error and bias, and these problems can be introduced to completely different datasets in a systematic way.\r\n\r\nThis talk will provide a brief overview of the motivation and use cases for Lattice, and then show how the library relies on Julia’s type system to automatically pair abstract machine learning tasks with all of the domains where the tasks make sense.  (For example, the abstract task “is X contained by Y?” can be instantiated and applied to images with at least two polygons, or images with bitmaps of a bird and a cage, but not to images of a single digit.  In Lattice, pairs of domains and tasks don't need to be manually specified.)  We’ll also show how multiple dispatch in Julia makes the implementation of Lattice--and the addition of new domains and tasks--remarkably simple.  Finally, we'll share a few examples of using Lattice datasets with Flux.jl to study representation learning and hyperparameter optimization.",
  "url": "/talk/ACJRET",
  "index": 43,
  "speaker": "Don March"
 },
 {
  "start_datetime": "2020-07-29T15:20:00Z",
  "end_datetime": "2020-07-29T15:50:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "DWCJUK",
  "title": "Juno 1.0",
  "text": "Juno 1.0 In this talk we will introduce [Juno](https://junolab.org/) 1.0 and give an overview of new features and workflows as well as key development choices we made during the last months. This new version of Juno is more robust and easy to install than ever before and combines powerful static analysis features with the dynamic approach that's been at Juno's core for so long. [Juno](https://junolab.org/) is an IDE for Julia which enables an unique, powerful and very interactive development style. It is also the oldest still maintained IDE for Julia and, as such, has undergone drastic changes during the last few years. \r\n\r\nDue to limitations around the current package infrastructure, there also have been some longstanding and fundamental problems, mostly around installation, updating, activation time, and interference with user's own package environment.\r\n\r\nIn this presentation we are going to present Juno 1.0. We will give examples of both basic workflows and more arcane features as well as explain how we tackled the problems outlined above; as such, the talk will be split in two parts: A showcase of Juno's current state, and a discussion of internals and planned improvements.",
  "url": "/talk/DWCJUK",
  "index": 44,
  "speaker": "Shuhei Kadowaki, Sebastian Pfitzner"
 },
 {
  "start_datetime": "2020-07-30T16:10:00Z",
  "end_datetime": "2020-07-30T16:20:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "Q88P8U",
  "title": "Integrate Julia and Javascript using Node.js extensions",
  "text": "Integrate Julia and Javascript using Node.js extensions Julia is a great language for implementing algorithms, and Node.js is a popular platform for writing web services using Javascript. In this talk we will see how to run Julia code in a Node.js application, by using Node.js native extensions. This approach is particularly efficient from a performance point of view, and makes it easy to integrate Julia in existing Javascript environments. Julia is a great language for implementing algorithms, and Node.js is a popular platform for writing web services using Javascript. In this talk we will see how to run Julia code in a Node.js application, by using Node.js native extensions.\r\n\r\nThis approach has been used to serve a statistical inference algorithm, written in Julia, through an HTTP API, written in Javascript.\r\n\r\nThe Julia code is simplified since it does not have to handle HTTP requests, and it avoids data serialization costs by directly sharing memory between the runtimes. Furthemore, this makes the integration into an existing Node.js environment easy, since it does not require the installation of Julia on the server.\r\n\r\nWe will show how to use `PackageCompiler.jl` to produce a shared library, and the `node-addon-api` and `node-gyp` packages to build and distribute the extension.\r\n\r\nWe will also discuss the challenges and limitations of this approach, such as garbage collection, exceptions handling, and multithreading.",
  "url": "/talk/Q88P8U",
  "index": 45,
  "speaker": "Maxime Mouchet"
 },
 {
  "start_datetime": "2020-07-29T18:00:00Z",
  "end_datetime": "2020-07-29T18:10:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "PARPJU",
  "title": "Convolutional Conditional Neural Processes in Flux",
  "text": "Convolutional Conditional Neural Processes in Flux The Convolutional Conditional Neural Process (ConvCNP) is a new member of the neural process family that models translation equivariance, an important inductive bias for many learning problems. We present ConvCNPs.jl, a simple implementation of the ConvCNP with Flux.jl, and demonstrate that it can be used to predict a sawtooth wave, an otherwise challenging task due to the wave's discontinuous nature. Conditional Neural Processes [1] are a rich class of models that directly parametrise their predictive distribution by passing the observed data, also called the context set, through a neural network that outputs the predictive means and variances at any desired location.\r\n\r\nA recent new member of this family, called the Convolutional Conditional Neural Process (ConvCNP) [2], proposes to account for _translation equivariance_ in the data:\r\nif the context set is shifted, then the predictions are shifted accordingly.\r\nTranslation equivariance is an important inductive bias for many learning problems, such as time series, spatial data, and images.\r\n\r\nIn this talk, we give a brief introduction to meta-learning and the neural process family. We define and discuss the importance of translation equivariance and show how the ConvCNP can be simply implemented with Flux.jl [3]. We finally demonstrate the benefits of translation equivariance by predicting a sawtooth wave with the ConvCNP, an otherwise challenging task due to the wave's discontinuous nature.\r\n\r\n[1] https://arxiv.org/abs/1807.01613\r\n\r\n[2] https://openreview.net/forum?id=Skey4eBYPS\r\n\r\n[3] https://github.com/wesselb/ConvCNPs.jl",
  "url": "/talk/PARPJU",
  "index": 46,
  "speaker": "Wessel Bruinsma"
 },
 {
  "start_datetime": "2020-07-29T12:40:00Z",
  "end_datetime": "2020-07-29T12:50:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "DSXCMZ",
  "title": "Fast Gaussian processes for time series",
  "text": "Fast Gaussian processes for time series TemporalGPs.jl provides a single-function API to make inference in Gaussian processes (GPs) from Stheno.jl dramatically more efficient in the time-series setting. It makes it feasible to perform (almost) exact inference with 10s of millions of data points quickly on a laptop, and plays nicely with StaticArrays.jl and Zygote.jl. Gaussian processes (GPs) are flexible probabilistic models for real-valued functions, and are standard tool for nonlinear regression. Their default implementation involves a costly Cholesky decompostion, yielding cubic computational costs in N (dataset size).\r\n\r\nThere is an increasingly-broad literature on a collection of techniques that cast certain classes of GPs for time-series (almost-exactly) as linear stochastic differential equations. This exposes a Markov structure that can be exploited to make the complexity of inference scale linearly in N.\r\n\r\nTemporalGPs.jl implements the above techniques, and provides a function that takes a Stheno.jl GP and constructs an (almost) equivalent linear SDE, which in turn exposes the same API as a Stheno.jl GP (modulo some restrictions).\r\n\r\nThe only other publicly available implementation of these techniques is available in the famous GPML Matlab package. Moreover, at the time of writing there isn't a publicly available implementation on these techniques that can be used in conjunction with reverse-mode algorithmic differentiation (to the best of the author's knowledge).\r\n\r\nIn this talk I'll present the user-facing API, show some basic benchmarking / empirical results, briefly discuss some technical challenges, and conclude with the package's future direct.",
  "url": "/talk/DSXCMZ",
  "index": 47,
  "speaker": "Will Tebbutt"
 },
 {
  "start_datetime": "2020-07-29T16:40:00Z",
  "end_datetime": "2020-07-29T17:10:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "RXAN8F",
  "title": "What's new in Pkg: artifacts, binaries & the Pkg protocol",
  "text": "What's new in Pkg: artifacts, binaries & the Pkg protocol There have been some major developments in Julia package manager in the past year. A system has been added in 1.3 for content-addressed binary artifacts, including data and platform-dependent binaries. In conjunction, the BinaryBuilder system has been updated to produce these artifacts, allowing package to depend on non-Julia libraries without any client-side build step. Pkg 1.4 introduced a new protocol for clients to get packages and artifacts from \"Pkg servers\" without needing git or GitHub. This talk will go over the high-level design of the artifact system, how BinaryBuilder lets you easily build binaries for dozens of platforms and get them in the hands of Julia users with unprecedented ease. The bottom line: no client-side build step means no client-side build failures. The new Pkg protocol makes it faster and easier to use the package manager behind a firewall or in countries that don't happen to be close to GitHub's servers. No more libgit2/proxy woes. In Julia 1.5 the Pkg protocol will be the default way that Julia clients get packages and artifacts, making it easier for Julia users everywhere to get packages.",
  "url": "/talk/RXAN8F",
  "index": 48,
  "speaker": "Elliot Saba, Stefan Karpinski"
 },
 {
  "start_datetime": "2020-07-31T13:00:00Z",
  "end_datetime": "2020-07-31T13:10:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "S9BVBR",
  "title": "Migrating to JuMP: Leaving Behind Domain Specific Languages",
  "text": "Migrating to JuMP: Leaving Behind Domain Specific Languages To increase transparency and partnership opportunities, the Department of Energy funded an [open source release](https://github.com/NREL/reopt_api) of NREL developed [REopt](https://reopt.nrel.gov/). The optimization model that powers REopt was originally written in a domain specific, proprietary modeling language called Mosel. This transition required some python-familiar engineers to learn Julia and the JuMP package. This talk will detail our experience and what we learned along the way. The REopt™ techno-economic decision support platform is used by the National Renewable Energy Laboratory (NREL) researchers to optimize energy systems for buildings, campuses, communities, microgrids, and more. REopt recommends the optimal mix of renewable energy, conventional generation, and energy storage technologies to meet cost savings, resilience, and energy performance goals.",
  "url": "/talk/S9BVBR",
  "index": 49,
  "speaker": "Josiah Pohl"
 },
 {
  "start_datetime": "2020-07-31T19:10:00Z",
  "end_datetime": "2020-07-31T19:20:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "V9NX3C",
  "title": "Creating an XML parser from scratch",
  "text": "Creating an XML parser from scratch By utilizing channels and coroutines in Julia we can create a simple lexer and parser quickly in Julia. In this example we will be building an XML parser from scratch.  Focus is on simplicity rather than performance. Many Julia XML packages wrap complex C++ parsers. This create annoying dependencies and are hard to debug. However Julia is a very nice language to hand code lexers and parsers from scratch. Here we will show how surprisingly easy it is to create a parser for XML and Apple's PList format. We will utilize channels and coroutines to simplify our design.",
  "url": "/talk/V9NX3C",
  "index": 50,
  "speaker": "Erik Engheim"
 },
 {
  "start_datetime": "2020-07-29T13:00:00Z",
  "end_datetime": "2020-07-29T13:30:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "FW7W9D",
  "title": "Jusdl.jl - Julia Based System Description Language",
  "text": "Jusdl.jl - Julia Based System Description Language The talk will introduce [Jusdl.jl](https://github.com/zekeriyasari/Jusdl.jl), which is a Julia based system description language and simulation tool that focuses on effective system simulations together with online and offline data analysis. Jusdl provides users with the ability to simulate systems consisting of components represented by different types of equations and the flexibility of enriching analysis capabilities with user-defined plugins. Numerical simulations can be expressed as solving the mathematical equations--derived from the modeling--and/or processing the data obtained from those equations. Based on the properties of the system at hand and the level of abstraction in the modeling, the mathematical equations may be ordinary, stochastic, delay differential or difference equations. Although different simulation environments have been developed for numerical simulations of systems, they are able to simulate mostly the models represented by ordinary differential or differential-algebraic equations. This is restrictive when considering the diversity of mathematical models that can be encountered. In Jusdl.jl, it is possible to simulate discrete-time and continuous-time, static or dynamical systems. In particular, it is possible to simulate dynamical systems modeled by different types of differential equations such as ODE(Ordinary Differential Equation), Random Ordinary Differential Equation(RODE), SDE(Stochastic Differential Equation), DDE(Delay Differential Equation) and DAE(Differential-Algebraic Equation), and discrete difference equations. During the simulation, the data flowing through the links of the model can be processed online and specialized analyzes can be performed. These analyses can also be enriched with plugins that can be defined using the standard Julia library or various Julia packages. The simulation is performed by evolving model components individually and in parallel in sampling time intervals. The individual evolution of the components allows the simulation of the models including the components that are represented by different kinds of mathematical equations.\r\n\r\nKey features of Jusdl.jl includes\r\n* Simulation of a large class of systems: \r\n    * Static systems (whose input, output relation is represented by a functional relation)\r\n    * Dynamical systems (whose input, state and output relation is represented by difference or differential equations)\r\n        * Dynamical systems modelled by continuous time differential equations: ODE, DAE, RODE, SDE, DDE\r\n        * Dynamics systems modelled by discrete time difference equations.\r\n* Simulation of models consisting of components that are represented by different type mathematical equations\r\n* Individual construction of components, no need to construct a unique equation representing the whole model\r\n* Online data analysis through plugins \r\n* Flexibility to enrich the data analysis scope through user-defined plugins",
  "url": "/talk/FW7W9D",
  "index": 51,
  "speaker": "Zekeriya SARI"
 },
 {
  "start_datetime": "2020-07-29T18:00:00Z",
  "end_datetime": "2020-07-29T18:30:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "JQLXBK",
  "title": "Loop Analysis in Julia",
  "text": "Loop Analysis in Julia This talk will focus on the library LoopVectorization, providing an overview of how the library represents loops, and how this representation is used alongside cost modeling to pick an efficient vectorization strategy, and how it can be used for defining loops for an autodiff reverse pass. I will give a brief introduction to loop vectorization in Julia, discussing practical issues such as the benefit of contiguous loads and stores and how they relate to data layout decisions such as arrays of structs versus struct of arrays.\r\n\r\nThe emphasis of the low level discussion will be the extreme level of parallelism within a single modern CPU core (a single AVX512 core can have up to 128 concurrent double precision floating point operations: 8 Float64 per vector * 2 operations / fma * 2 instructions executed / cycle * 4 cycles latency), emphasizing the need for parallel programming paradigms like SPMD.\r\n\r\nLoopVecorization.jl can be thought of as treating loops like a familiar DSL for specifying dependencies between operations (such as arithmetic and loads or stores) and loops, without regard to any order aside from that inherent in the dependency chains.\r\nThe library has infrastructure for modeling the cost of evaluating a loop nest using different orders of the constituent loops, and different unrolling and blocking factors of the loops.\r\nThe advantage is demonstrated in allowing writing high performance code that is generic with respect to the data layout of the underlying arrays, with the order of evaluated loops and data access pattern shifting in response to transposed arrays without any change in the user's code.\r\n\r\nNext, the advantage of the simple representation of loops as dependencies between operations and loops for automatic differentiation is demonstrated.",
  "url": "/talk/JQLXBK",
  "index": 52,
  "speaker": "Chris Elrod"
 },
 {
  "start_datetime": "2020-07-29T18:30:00Z",
  "end_datetime": "2020-07-29T18:40:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "GSXV8H",
  "title": "Accelerating Tensor Computations in Julia on the GPU",
  "text": "Accelerating Tensor Computations in Julia on the GPU GPU programming is very powerful but sometimes rather opaque to new users. In this talk, I'll show how I took a CPU based code for performing tensor (multi-linear algebra) computations, moved it over to the GPU, and then used some of Julia and NVIDIA's tools to accelerate the code even further. Then I'll talk about other classes of problems that might benefit from this approach. ",
  "url": "/talk/GSXV8H",
  "index": 53,
  "speaker": "Katharine Hyatt"
 },
 {
  "start_datetime": "2020-07-31T18:00:00Z",
  "end_datetime": "2020-07-31T18:45:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "L9LV3N",
  "title": "Transitioning Code From Closed To Open",
  "text": "Transitioning Code From Closed To Open Within private companies/institutions, it can be difficult to implement effective internal practices that enable internal code to smoothly transition into high quality, open-source contributions. In this BoF, we'll swap techniques for maximizing open-source impact in the Julia ecosystem while minimizing refactor time/effort and code churn. Julia's package ecosystem makes it fairly easy for private organizations to redistribute code back to the Julia community, and we've found there are numerous benefits to routinely open-sourcing internally developed packages:\r\n\r\n- great for recruiting both community collaborators and future FTEs\r\n- encourages well-scoped, composable APIs and discourages overcoupling of orthogonal functionality\r\n- encourages structuring/maintaining the project in a manner that keeps the contribution/collaboration barrier low\r\n- positively contributes to the health/growth of the Julia ecosystem that we all rely on; a more robust/featureful ecosystem attracts more great community members and improves productivity for existing community members.\r\n\r\nHowever, it can be difficult to implement effective internal practices that enable internal code to smoothly transition into high quality, open-source contributions. In this BoF, we'll swap techniques for maximizing open-source impact in the Julia ecosystem while minimizing refactor time/effort and code churn. Discussion points include:\r\n\r\n- developing Julia packages with upfront \"intent to open-source\"\r\n- the benefits/challenges of piecemeal upstreaming to existing packages\r\n- identifying/mitigating common pain points w.r.t. internal code churn\r\n- managing internal dependency graphs when nodes are open-sourced\r\n- the interplay between private CI/CD and open CI/CD for Julia packages\r\n- git history/metadata preservation\r\n- the role of GitHub in the Julia community, and open-sourcing non-GitHub-hosted projects\r\n- software licensing",
  "url": "/talk/L9LV3N",
  "index": 54,
  "speaker": "Jarrett Revels"
 },
 {
  "start_datetime": "2020-07-29T15:10:00Z",
  "end_datetime": "2020-07-29T15:20:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "UTGXSH",
  "title": "Diversity and Inclusion Efforts in the Julia Community",
  "text": "Diversity and Inclusion Efforts in the Julia Community It takes the entire community to promote diversity and inclusion. This talk will focus on the current plans underway to promote diversity and inclusion in the Julia Community as well as give an updated look at the state of diversity and inclusion in our community. ",
  "url": "/talk/UTGXSH",
  "index": 55,
  "speaker": "Logan Kilpatrick"
 },
 {
  "start_datetime": "2020-07-29T16:10:00Z",
  "end_datetime": "2020-07-29T16:20:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "MCQHT3",
  "title": "Estimation of Macroeconomic Models",
  "text": "Estimation of Macroeconomic Models Macroeconomic models require efficient estimation methods when used in policy analysis. Recent additions to DSGE.jl expand its toolkit with state-of-the-art routines for constructing and analyzing Dynamic Stochastic General Equilibrium (DSGE) models. Additions include DSGE-Vector Autoregressions (DSGEVAR), Hamiltonian Monte Carlo (HMC), and potentially a “double-parallel” Bayesian algorithm. I will present on new features of DSGE.jl. Tentatively, they will be DSGEVARs and HMC.\r\n\r\nDynamic Stochastic General Equilibrium (DSGE) models are workhorse tools at central banks. DSGEVAR methods allow economists to assess misspecification of DSGEs by comparing them to atheoretic vector autoregressions (VAR). The idea is to use DSGEs as priors for VARs in a Bayesian framework. These priors can be implemented by creating pseudo-data from a DSGE. The weight on the prior is determined by a hyperparameter. Larger values of the hyperparameter imply stronger belief that the DSGE explains the data. By finding the hyperparameter which maximizes the marginal data density of a DSGEVAR, we can evaluate misspecification relative to VARs. We build a simple user interface for DSGEVARs on top of DSGE.jl’s modeling approach, allowing users to easily estimate DSGEVARs and apply them in economic analysis.\r\n\r\nHamiltonian Monte Carlo (HMC) improves sampling efficiency during estimation of DSGEs because DSGEs have large sets of parameters. MCMC methods face a trade-off between exploring the parameter space and sampling from high-probability regions. This trade-off worsens in high dimensions. By using information from the gradient of the likelihood, HMC handles this trade-off better than other algorithms like Metropolis-Hastings. Applying HMC to DSGEs is difficult, however, because DSGEs have complex likelihood functions. Autodifferentiation is not immediately possible since calls to LAPACK are made during the likelihood calculation. We use the implicit function theorem to avoid calling LAPACK, which allows us to apply ForwardDiff.jl’s autodifferentiation for fast, accurate, and user-friendly gradient computation. We then write wrappers for the likelihood function and gradient to make it compatible with DynamicHMC.jl’s interface.\r\n \r\nDepending on research progress, I may also discuss tools to estimate nonlinear models. Unless Monte Carlo methods like particle filters are applied, it is difficult to compute the likelihoods of nonlinear models. Parallelization is required to effectively use these methods, but for most computing environments, this restriction forces users to use sequential Bayesian estimation algorithms, which are slow. In Julia, however, we can run nested parallel for loops. We combine SMC.jl’s Sequential Monte Carlo estimation algorithm with StateSpaceRoutines.jl’s Tempered Particle Filter to perform a “double-parallel” estimation of nonlinear economic models.",
  "url": "/talk/MCQHT3",
  "index": 56,
  "speaker": "William Chen"
 },
 {
  "start_datetime": "2020-07-31T19:00:00Z",
  "end_datetime": "2020-07-31T19:10:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "M8JLAF",
  "title": "Iterable Parser Combinators for fast parsing in pure Julia",
  "text": "Iterable Parser Combinators for fast parsing in pure Julia I will introduce the CombinedParsers package for writing complex recursive parsers efficiently in a composable functional style.\r\n\r\nThe package API will be demonstrated by example of an CombinedParser for regular expressions which generates compiled regular expression parsers in pure julia.\r\n\r\nFar more expressive than regular expressions, parser combinators allow for arbitrary transformations and higher-order parsers depending on the parsing state (exemplified with a very short html parser). Parsing data from strings recurrently is at the beginning of scientific computing and thus regular expressions are a familiar part of standard tooling. \r\nCombinedParsers constructors will be presented side-by-side with the equivalent regex syntax.\r\nThe regex parser provided with the package can be used as a pure julia plug-in replacement for the current julia Regex type.\r\n\r\nBenchmarks and compliance with PCRE syntax will be reported based on the extensive unit tests of the PCRE library.\r\nLeveraging julia compiler optimizations for multiple dispatch and parametric types,\r\nCombinedParsers performance can for many patterns compete with the PCRE C library that currently is used by julia base Regex.\r\n\r\nArbitrary transformations can be defined as part of the grammar definition, with convenient syntax for extracting data as named tuples.\r\nFor optimized performance, parsing and transformation are decoupled, and parsing memoization can be used optionally.\r\n\r\nParser combinators straightforwardly generalize from strings to parsing any iterator type.\r\nLogging and human-readable error messages help debugging complex parsers.\r\n\r\nCombinedParsers supports the iterate interface to lazily generate all valid parsings, and the TextParse interface to include CombinedParsers e.g. in CSV.jl.\r\nPreliminary packages for parsing wikitext and orgmode markup with ParserIterators are available.\r\n\r\nOther parsing packages (Automa.jl, ParserCombinator.jl) will be acknowledged. Current limitations and considerations for further optimization will be discussed.",
  "url": "/talk/M8JLAF",
  "index": 57,
  "speaker": "Gregor Kappler"
 },
 {
  "start_datetime": "2020-07-31T16:40:00Z",
  "end_datetime": "2020-07-31T17:10:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "KZK93G",
  "title": "Display, show and print -- how Julia's display system works",
  "text": "Display, show and print -- how Julia's display system works After executing Julia code you are presented with the result. If you are working in the Julia REPL you are usually seeing just a basic text representation. However, in other environments, such as in a Jupyter notebook, you sometimes see a more rich representation of the output. This talk will present how Julia's display system works when presenting output to the user, which methods are called when, and how to implement \"pretty printing\" for custom types. When Julia finishes a computation and obtains a value the user is presented with the result. In the Julia REPL the result is usually represented as plain text. In other environments, such as in a Jupyter notebook, you sometimes see more rich representations, for example some values display as HTML, and others as images.\r\n\r\nThe main functions responsible for output in Julia are `display` and `show`. Usually `display` is the first method to be called when an object is presented to the user. The `display` function is implemented by displays such as the Julia REPL, the IDE or the notebook interface. Next, `display` requests output from `show` with a specific so-called MIME-type. Which MIME-types that are requested depends on what output the display is able to present back to the user. For example, the REPL mostly works with the `text/plain` MIME-type, and the notebook display supports multiple additional MIME-types, for example `image/png` for image output, `text/html` for HTML output, and so on. Given this rough overview the display system might seem rather simple, but there are many hidden complexities.\r\n\r\nIn order to take advantage of the rich display system and implement \"pretty printing\" for a custom type it is generally enough to implement methods of `show` with specific MIME-types. All types get a default text representation, but this can easily be overridden by implementing `show` with the `text/plain` MIME type. If the type can be represented in richer formats it is simple to add additional methods. For example, in order to support image output in a notebook it is enough to implement `show` with the `image/png` MIME type.\r\n\r\nThis talk will present how Julia's display system works and go through the process of taking an output object and generating output to present the user with. The talk will also examplify this process by discussing how to customize the output for your own types.",
  "url": "/talk/KZK93G",
  "index": 58,
  "speaker": "Fredrik Ekre"
 },
 {
  "start_datetime": "2020-07-30T19:30:00Z",
  "end_datetime": "2020-07-30T20:00:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "AQMLUC",
  "title": "Enterprise data management with low-rank topic models",
  "text": "Enterprise data management with low-rank topic models How can enterprises create a catalogue of what data they have, given only a few labels and access to physical data layouts and other metadata? I show how to extend `GeneralizedLowRankModels.jl` to generate topic models that can be used for semisupervised learning tasks like extrapolating from known labels, evaluating possible errors in existing labels, and predicting missing metadata. To adopt modern practices for reproducible data science, enterprises need to first know what kinds of data they have. In some industries like financial services, being able to reproduce critical risk calculations is even a regulatory requirement. A necessary first step is for enterprises to build comprehensive data catalogue, before building other infrastructure such as data lakes. Building such a catalogue can be challenging for enterprises with multiple legacy systems, incomplete documentation, and inherited technical debt. The expert knowledge needed to provide and verify subject labels further escalates the cost of building a data catalogue.\r\n\r\nIn this talk, I demonstrate how topic modeling can be used to help build a comprehensive data catalogue from incomplete subject labels and access to metadata such as low-level record types and database table names. By treating such metadata as a sequence of tokens, similar to natural text, I show how to construct semisupervised topic models that allow extrapolation from existing labels. First, I show how a gauge transformation of a standard topic modeling technique, latent semantic indexing (LSI), yields a labelled topic model that is explictly separable. Next, I show how to use generalized low-rank models (GLRMs), as implemented in `GeneralizedLowRankModels.jl`, to explicitly construct a labelled topic model that is a sparse, interpretable, and separable generalization of principal components analysis. I show how to implement a new regularizer in Julia, including an implementation of its corresponding proximal gradient operator. Furthermore, I show how to modify the code of `GeneralizedLowRankModels.jl` to take advantage of the new multithreading model in Julia 1.3 for near-perfect parallel speedup. Additionally, numerical tricks such as low-precision iterative linear algebra, randomized subsampling, and warm starts help to make efficient the training of a GLRM via proximal gradient descent.\r\n\r\nAs an illustration of the technique, I will show how this new topic model performs on predicting subject tags on over 25,000 datasets from Kaggle.com. The GLRM-based topic model can be used for several different semisupervised learning tasks, like extrapolating from known labels, evaluating possible errors in existing labels, and predicting missing metadata.",
  "url": "/talk/AQMLUC",
  "index": 59,
  "speaker": "Jiahao Chen"
 },
 {
  "start_datetime": "2020-07-30T14:20:00Z",
  "end_datetime": "2020-07-30T15:05:00Z",
  "duration": 45,
  "location": "Track 1",
  "id": "MASLPF",
  "title": "The State of Julia",
  "text": "The State of Julia We take stock of the Julia and its ecosystem. The releases since 1.0 have been less major and non-breaking—which has been a relief—but nevertheless, a significant number of major new functionality has been added. We'll highlight some of the biggest developments in the language (can anyone say \"multithreading\"?), infrastructure (BB, Pkg3, Artifacts), and ecosystem (the Dataverse, DiffEqs, differentiable programming) and beyond.  And finally, we look ahead to Julia 2.0. In addition to taking stock of the language and ecosystem, we'll review the annual developer survey. That accounts for some portion of the 45 minutes, although it would also be separable if that's easier for scheduling.",
  "url": "/talk/MASLPF",
  "index": 60,
  "speaker": "Stefan Karpinski, Jeff Bezanson"
 },
 {
  "start_datetime": "2020-07-30T19:00:00Z",
  "end_datetime": "2020-07-30T19:30:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "KFRKCB",
  "title": "Inventing Curriculum with Julia and Pointer-Generator Network",
  "text": "Inventing Curriculum with Julia and Pointer-Generator Network In this talk, attendees will learn about natural language processing techniques (TextAnalysis.jl) using Julia and how it can be combined with machine learning(MLJ.jl) to generate new knowledge from the existing knowledge.  We will talk about how we designed curriculum using natural language processing, unsupervised machine learning and pointer-generator network. The curriculum in general and undergraduate curriculum, in particular, is one of the most important pillars of an education system. The undergraduate curriculum has two main objectives i.e. employability and higher education. The greatest challenge in designing an undergraduate curriculum is achieving a balance between employability skills and laying the foundation for higher education. Generally, the curriculum is the combination of core technical subjects, professional electives, humanities, and skill-oriented subjects. We used natural language processing and machine learning packages in Julia to build a curriculum design system.\r\nThe steps to build a curriculum design system are described below:\r\n1.\tThe dataset was built from the job profiles from different job listing websites like indeed.com, linkedin.com, and monster.com. Also from the syllabus of competitive exams and qualifying exams for higher education.\r\n2.\tOn the dataset, we applied natural language processing techniques to identify the subjects and subject content. For natural language processing, we used TextAnalysis.jl package in Julia.\r\n3.\tTo generate syllabus content for a particular subject, a pointer-generator network was used. The pointer generator network is a text summarization technique that combines extractive and abstractive summarization techniques. The extractive summarization technique extracts keywords from the dataset, whereas the abstractive summarization technique generates new text from the existing text. The pointer-generator network was implemented using the MLJ.jl machine learning package in Julia. \r\n4.\tThe generated curriculum was then compared with the existing curriculum to get insights like, how much percent of the curriculum is industry oriented, how much percent of the curriculum is aimed at higher education, and job-oriented skills. \r\n5.\tThe above steps can be repeated with modified parameters to get better insights and curriculum. This also gives us an idea of how we can have an evolving curriculum that can help us bridge the gap between industry and academia.\r\n\r\nIn this talk, attendees will learn about natural language processing techniques using Julia and how it can be combined with machine learning to generate new knowledge from the existing knowledge.",
  "url": "/talk/KFRKCB",
  "index": 61,
  "speaker": "Gajendra Deshpande"
 },
 {
  "start_datetime": "2020-07-31T18:45:00Z",
  "end_datetime": "2020-07-31T19:30:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "3AGJ3V",
  "title": "Julia in Production",
  "text": "Julia in Production An informal conversation about problems and solutions related to running Julia in a production environment. Running Julia in production can take many different forms. Those who have already deployed Julia to production will share their experiences and discuss challenges they have had or still have. For those who have not yet run Julia in production this is a good opportunity to get feedback on deployment strategies.\r\n\r\nThis birds-of-a-feather also provides us with the chance to discover common patterns with running Julia in production and hopefully will generate ideas for new tools that can we can all share.",
  "url": "/talk/3AGJ3V",
  "index": 62,
  "speaker": "Curtis Vogt"
 },
 {
  "start_datetime": "2020-07-30T18:30:00Z",
  "end_datetime": "2020-07-30T18:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "8EPG3L",
  "title": "The Queryverse",
  "text": "The Queryverse This talk will give a quick introduction to the Queryverse. I will also give an update on new features since the last Juliacon. This talk will briefly introduce users to the Queryverse, what the scope of it is and how one can use it. I will also briefly talk about new features that have been added since last year.",
  "url": "/talk/8EPG3L",
  "index": 63,
  "speaker": "David Anthoff"
 },
 {
  "start_datetime": "2020-07-30T13:30:00Z",
  "end_datetime": "2020-07-30T14:00:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "YCGSVY",
  "title": "How not to write CPU code -- KernelAbstractions.jl",
  "text": "How not to write CPU code -- KernelAbstractions.jl KernelAbstractions.jl is a library to write portable kernels for CPU and GPU computing.\r\nIt presents a unified programming model ala OpenCL in Julia so that users can write a\r\nsingle kernel that targets multiple accelerators an multi-threaded CPUs. Writing performance portable code that targets multiple hardware platforms is challenging.\r\nKernelAbstractions.jl allows users to abstract away some of the hardware differences and \r\nwrite one unified code that targets multiple hardware platforms. Despite being able to target\r\nmulti-threaded CPUs it's design choices are biased towards GPUs and can sometimes be sub-optimal\r\nfor CPU execution. In this talk I will introduce KernelAbstractions.jl, and explain it's design choices.",
  "url": "/talk/YCGSVY",
  "index": 64,
  "speaker": "Valentin Churavy"
 },
 {
  "start_datetime": "2020-07-29T16:10:00Z",
  "end_datetime": "2020-07-29T17:40:00Z",
  "duration": 90,
  "location": "Track 3",
  "id": "9BNNMD",
  "title": "Poster Session 1",
  "text": "Poster Session 1 This is the first poster session. - [\"Calling a parallel simulation code from Julia\" by Marc Fuentes](https://pretalx.com/juliacon2020/talk/D3RLQ7)\r\n - [\"Fast global optimization on the GPU\" by David P. Sanders](https://pretalx.com/juliacon2020/talk/8K8P7R)\r\n - [\"Simple Layers for Species Distributions Modelling in Julia\" by Gabriel Dansereau](https://pretalx.com/juliacon2020/talk/7LEVXF)\r\n - [\"TrackMatcher – A tool for finding intersections in trajectories\" by Peter Bräuer](https://pretalx.com/juliacon2020/talk/3CEUF7)\r\n - [\"Automatic gradient and scale for high dimensional optimization\" by Tim Holy](https://pretalx.com/juliacon2020/talk/LSYN8F)\r\n - [\"Supercharging your data science workflows using GitHub Actions\" by Chidubem Iddianozie](https://pretalx.com/juliacon2020/talk/RDMYLS)\r\n - [\"Visual Biology with Makie\" by Daniel Kool](https://pretalx.com/juliacon2020/talk/CXAYML)\r\n - [\"Why we need reversible computing?\" by JinGuo Liu](https://pretalx.com/juliacon2020/talk/V9DQSA)\r\n - [\"What can imply behind a special weather profile\" by Shiqi XIAO](https://pretalx.com/juliacon2020/talk/RBTYQR)\r\n - [\"Taylor-Mode for Higher Order Automatic Differentiation\" by Jesse Bettencourt](https://pretalx.com/juliacon2020/talk/QDD7G7)\r\n - [\"Fantastic beasts and how to show them\" by Joris Kraak](https://pretalx.com/juliacon2020/talk/M8KTBL)\r\n - [\"Deferred Acceptance with Allocation Rules\" by Minyoung Rho](https://pretalx.com/juliacon2020/talk/SNDBVR)\r\n - [\"Large-scale environmental flow simulations with Julia\" by Martijn Russcher (Deltares, Delft, the Netherlands) and Frank Platzek (Deltares, Delft, the Netherlands)](https://pretalx.com/juliacon2020/talk/TKZNMG)\r\n - [\"Squaring the circle: polyhedral approximation of convex sets\" by Maxim Demenkov](https://pretalx.com/juliacon2020/talk/VP7LXS)\r\n - [\"CombinatorFormatting.jl: Polymorphic, composable text formatting\" by Kusti Skytén](https://pretalx.com/juliacon2020/talk/K77ZJK)\r\n - [\"Vehicle's crew survivability using Julia\" by Irene Ndindabahizi](https://pretalx.com/juliacon2020/talk/3LZQXH)\r\n - [\"Julia for Good Old-Fashioned (Symbolic) Artificial Intelligence\" by Johann-Tobias Schäg](https://pretalx.com/juliacon2020/talk/TACZJT)\r\n - [\"Julia, From a Programming Language Theory Perspective\" by Harrison Grodin](https://pretalx.com/juliacon2020/talk/CHJ9ZK)\r\n - [\"BinaryTraits - traits made easy\" by Tom Kwong](https://pretalx.com/juliacon2020/talk/GZK8ML)\r\n - [\"Extending Distributions with Expectations.jl\" by Arnav Sood](https://pretalx.com/juliacon2020/talk/N9CXCT)\r\n - [\"Machine Learning in Graphs\" by Ollin D. Langle-Chimal](https://pretalx.com/juliacon2020/talk/RGT8RF)\r\n - [\"Parallel face recognition algorithms using Julia + CUDAnative.jl\" by Oscar A. Esquivel-Flores and Óscar Alvarado](https://pretalx.com/juliacon2020/talk/HPR79A)",
  "url": "/talk/9BNNMD",
  "index": 65,
  "speaker": "JuliaCon Committee"
 },
 {
  "start_datetime": "2020-07-30T18:45:00Z",
  "end_datetime": "2020-07-30T19:30:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "YPT9CQ",
  "title": "NumFOCUS and Julia project finances",
  "text": "NumFOCUS and Julia project finances The Julia project is fiscally sponsored at NumFOCUS. In this session, we will discuss the projects income and expenditures, including the finances for JuliaCon. Income for the Julia project comes primarily from JuliaCon sponsorships, and some individual contributions. Expenditures is primarily the organisation of JuliaCon, as well as smaller events and hackathon.",
  "url": "/talk/YPT9CQ",
  "index": 66,
  "speaker": "Avik Sengupta"
 },
 {
  "start_datetime": "2020-07-30T19:00:00Z",
  "end_datetime": "2020-07-30T19:30:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "HJZXMX",
  "title": "Inference of Bifurcations with Differentiable Continuation",
  "text": "Inference of Bifurcations with Differentiable Continuation In this talk I will demonstrate a gradient-based semi-supervised approach for matching target codimension one bifurcations with parameterised differential equation models. This work has been applied in synthetic biology settings, where experiments generate qualitative observations: locations of fixed points, limit cycles and bistability. Future outlooks include a view towards designing patterns and limit cycles in partial differential equations. This project extends functionality of parameter continuation library PseudoArcLengthContinuation.jl to work with automatic differentiation library Zygote.jl. This talk would be interesting to anyone who infers parameters of differential equation models, users of DifferentialEquations.jl, Flux.jl and FluxDiffEq.jl",
  "url": "/talk/HJZXMX",
  "index": 67,
  "speaker": "Gregory Szep"
 },
 {
  "start_datetime": "2020-07-29T13:30:00Z",
  "end_datetime": "2020-07-29T13:40:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "GVFYUF",
  "title": "Project Binder and the Julia Community: How can we help each oth",
  "text": "Project Binder and the Julia Community: How can we help each oth Project Binder (https://mybinder.org, https://jupyter.org/binder) offers an easy place to share reproducible computing environments, including Julia. In this lightning talk, Sarah Gibson will present the results of the mybinder.org User Survey, in particular those of interest to or suggested by the Julia community. She will introduce herself as a point of contact for further discussion on how the Julia and Binder communities can work more closely, and how you can become involved in Project Binde The Binder Project is a collection of tools that rewards best practices in reproducible data science and provides an easy method of sharing computing environments with anyone via a single clickable link. The free and public Binder service, hosted at https://mybinder.org, serves around 100,000 launches per week from over 10,000 individual git repositories in a variety of programming languages, including Julia.\r\n\r\nBinder is a community-driven project, taking the lead from community-developed standards of reproducibility and input from its users via the mybinder.org user survey. The user survey was last conducted at the beginning of 2020 and a summary of the results will be presented during the lightning talk.\r\n\r\nThere are so many fantastic ideas and features the Binder project team (https://jupyterhub-team-compass.readthedocs.io/en/latest/team.html#binder-team) would like to develop but - like many open source projects - we face time restrictions, a low bus factor (https://en.wikipedia.org/wiki/Bus_factor), and often lack domain expertise when developing language-specific features.\r\n\r\nSarah Gibson would like to introduce the Binder Project to the Julia community as an opportunity to shape a tool that would be most useful to them and provide guidance on how to get started with contributing to or joining the project.\r\n\r\nThis lightning talk will (hopefully!) be accompanied by a Birds of a Feather session and/or a drop-in table where Sarah will be available for more in-depth discussions about Binder.",
  "url": "/talk/GVFYUF",
  "index": 68,
  "speaker": "Sarah Gibson"
 },
 {
  "start_datetime": "2020-07-29T13:00:00Z",
  "end_datetime": "2020-07-29T13:10:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "AA8CQU",
  "title": "Modeling non-Gaussian time series with ScoreDrivenModels.jl",
  "text": "Modeling non-Gaussian time series with ScoreDrivenModels.jl Time series models with time-varying parameters have become increasingly popular over the years due to their advantages in capturing the dynamics of series of interest. In this context, score-driven models represent a recently developed and powerful framework for modeling time series considering non-Gaussian predictive distributions. In this talk, we present ScoreDrivenModels.jl, a Julia package for modeling, forecasting, and simulating data using score-driven models. In this talk, we will first provide a brief overview of score-driven models, also known as generalized autoregressive models, based on the paper “Generalized Autoregressive Score Models With Applications” by D. Creal et al. This class of models represents a powerful and flexible tool for dealing with time-series data under non-Gaussian distributions and different autoregressive structures.\r\nAfter a high-level introduction to the theory, we will present the ScoreDrivenModels.jl package, going through all steps that a user would possibly need to do: model specification, estimation, forecasting, and simulation. We will show how the package is built on top of Distributions.jl, thus allowing easy integration of any distribution, including more obscure ones, for example, a non-zero mean Student’s t which employs the `LocationScale` abstraction. The package also has a manual for integrating new distributions with small effort.\r\nFinally, we will motivate the use of this class of models by providing examples of applications in different fields, e.g., simulating scenarios for renewable generation and analyzing financial time-series data, while showcasing the use of the package.\r\nFor more information on score-driven models, we refer the interested reader to http://www.gasmodel.com.",
  "url": "/talk/AA8CQU",
  "index": 69,
  "speaker": "Guilherme Bodin"
 },
 {
  "start_datetime": "2020-07-31T15:20:00Z",
  "end_datetime": "2020-07-31T15:50:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "RMGYYX",
  "title": "Lessons learned on trait-based descriptions of graphs",
  "text": "Lessons learned on trait-based descriptions of graphs LightGraphs has been structured around a graph interface, which is used by algorithms without assuming anything on the underlying data structure. Few months ago, we realized it was implicitly assumed in some places that the graph vertices are contiguous integers starting from one. Making this assumption explicit for each graph type allows users to describe more properties of their types, and to indicate in the signature of algorithms whether this assumption is necessary. The talk will cover the definition of interfaces for a Julia ecosystem and advantage of a trait-based approach, these two topics being of interest not only for graphs, but for other packages defining a common interface to reason on.",
  "url": "/talk/RMGYYX",
  "index": 70,
  "speaker": "Mathieu Besançon"
 },
 {
  "start_datetime": "2020-07-29T17:20:00Z",
  "end_datetime": "2020-07-29T17:30:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "YDSABY",
  "title": "Multi-Physics 3-D Inversion on GPU Supercomputers with Julia",
  "text": "Multi-Physics 3-D Inversion on GPU Supercomputers with Julia We present an **iterative and massively scalable** 3-D multi-GPU inversion workflow using Julia for **coupled multi-physics processes** in Earth Sciences. We introduce an **adjoint framework** for the two-phase flow equations, assess the unknown porosity field reconstruction in 3-D and discuss the performance evaluation. The adjoint-based multi-physics inversion framework we present enables the development of efficient and massively scalable 3-D multi-GPU solvers with **application to optimisation problems**.\r\n\r\nWe use an **iterative matrix-free pseudo-transient approach** and the finite difference method to solve the forward and the adjoint coupled two-phase flow equations. We achieve efficient calculations of the pointwise gradients of the flow solution with respect to the porosity. We then use the gradients in a gradient descent method to reconstruct the pointwise porosity in 3-D.\r\n\r\nWe assess the performance of the 3-D memory-bounded solvers using a **simple effective memory throughput metric**. We finally discuss how the **overlap of computations with MPI communications** permits us to achieve a close to optimal parallel efficiency. We rely on the `ParallelStencil` and `ImplicitGobalGrid` packages for high-performance stencil-based calculations and optimal distributed memory parallelisation.\r\n\r\n**Co-authors** - Georg Reuber, Samuel Omlin",
  "url": "/talk/YDSABY",
  "index": 71,
  "speaker": "Ludovic Räss, Georg, Samuel Omlin"
 },
 {
  "start_datetime": "2020-07-31T19:10:00Z",
  "end_datetime": "2020-07-31T19:20:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "BMNWLJ",
  "title": "Interactive data visualizations with StatsMakie",
  "text": "Interactive data visualizations with StatsMakie The Makie library supports interactive visualizations in 2D or 3D, both native and web-based. StatsMakie adds support for statistical visualizations in two ways. It implements visualizations for common analyses (frequency table, kernel density, linear and non-linear regressions...), and it offers a set of custom types that allow to express how the data should be grouped, styled, and analyzed. This unified syntax layer simplifies the creation of StatsMakie-based UIs for data analysis. In this talk, I will first give a brief overview of the existing approaches for data visualizations in Julia. In particular, I will discuss the divide between the Grammar of Graphics approach (GoG), and the \"recipe\" approach.\r\n\r\nIn GoG (available in Julia thanks to for example Gadfly.jl or VegaLite.jl), a tabular dataset is used to inform how a plot should look like. Different columns correspond to different plot attributes, according to different scales. On top of that, columns can be transformed using \"statistics\", which in turn will inform what plot function to use (e.g. bar plot or scatter plot).\r\n\r\nIn the recipe framework, implemented in the Plots.jl and Makie.jl packages, custom types are recursively transformed into simpler types, until a suitable visualization is found.\r\n\r\nI will show how StatsMakie.jl attempts to bridge the gap between the two approaches, as it implements a version of Grammar of Graphics on top of the recipe framework. In particular, a combination of custom types (Group, Style, and Analysis) can be used to express how data should be grouped, styled, and analyzed (see [examples](http://makie.juliaplots.org/stable/statsmakie.html)).  Using multiple dispatch, I will show how to define interesting combination of these basic types using the `+` and `*` operators, as done in the experimental package [AlgebraOfGraphics](https://github.com/piever/AlgebraOfGraphics.jl).\r\n\r\nThe interface is declarative. The \"translation\" from data columns to plot attributes relies on a default theme, which can be customized, thus changing the \"look\" of all visualization consistently.\r\n\r\nAs the library is implemented in pure Julia, users are not limited to pre-built analyses but can implement their own, and they will automatically be integrated in the framework. This GoG-inspired framework, can then be combined with Makie's plot functions, as well as with the plot functions provided in StatsMakie (such as boxplot or violin plot).\r\n\r\nAn added benefit of the GoG approach is that many different plot commands can be expressed with a uniform syntax. This greatly simplifies the creation of interactive user interfaces for data analysis, where the user can select (from e.g. dropdown menus) what columns of a dataset to use, what analysis to run, and how to group and style the data. If the time allows it, I will show how to design a simple web-based app to create visualizations of a tabular dataset interactively.",
  "url": "/talk/BMNWLJ",
  "index": 72,
  "speaker": "Pietro Vertechi"
 },
 {
  "start_datetime": "2020-07-31T13:50:00Z",
  "end_datetime": "2020-07-31T14:00:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "FHEGUA",
  "title": "The ups and downs of convincing to switch to Julia in a company",
  "text": "The ups and downs of convincing to switch to Julia in a company We will talk about the hurdles of trying to convince people at ASML to switch from a very entrenched MATLAB culture to Julia at times when people are just starting to switch to python. ASML is company in the Netherlands which is the world leader on photo-lithographic system which are crucial for semi-conductor manufacture. For many years its engineers have been using MATLAB to develop hardware and algorithms that are usually rewritten in C/C++ on the main photo-lithography systems. This is the well known *two-language problem* and for mission critical systems this has been accepted for long time.\r\n\r\nFor several years ASML has been expanding its market to Analytics and Software for process optimization for which the two-language problem seems to be a little less forgiving than for hardware because time to market is a larger driving force. \r\n\r\nFor this Julia seems to be a natural candidate to solve the problem. However as this talk will show it is hard to convince \"normal\" engineers to switch from their trusted tried and truth tools. Moreover, it's even harder to convince them to switch to a relatively unknown/unfamiliar language than a more mainstream like python ... even when it's not the right tool for the job. Which makes things even more difficult is that managers also have a say on this and most think that this is just a fad.\r\n\r\nThis presentation will give an overview of common reactions, comments and attitudes, and hopefully a guide on how to work around them.",
  "url": "/talk/FHEGUA",
  "index": 73,
  "speaker": "Jorge Alberto Vieyra Salas"
 },
 {
  "start_datetime": "2020-07-31T17:10:00Z",
  "end_datetime": "2020-07-31T17:40:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "KCFCMQ",
  "title": "Manifolds in Julia – Manifolds.jl & ManifoldsBase.jl",
  "text": "Manifolds in Julia – Manifolds.jl & ManifoldsBase.jl From optimization to statistical modeling, many problems involve working with manifolds, smooth sets of points with nonlinear constraints.\r\n`Manifolds.jl` provides various tools to work on these problems along with a library of manifolds.\r\n`ManifoldsBase.jl` gives it a light-weight, extensible interface.\r\nWe will show how to use these tools to construct new manifolds and implement algorithms on these manifolds. In many scientific and engineering scenarios, measured data or model variables lie in smooth, nonlinear spaces like the sphere or the group of 3D rotations.\r\nSuch spaces often have a manifold structure, that is, they locally can be approximately linearized (_i.e._ they are locally diffeomorphic to a Hilbert space).\r\nEquipping such manifolds with a (pseudo-)Riemannian metric tensor, which defines a ruler on the manifold, enables local computation of distances and angles.\r\nThese features enable construction of efficient algorithms that respect the nonlinear structure, for example for optimization, interpolation, and statistical modeling.\r\n\r\nIn this talk, we demonstrate various tools that [Manifolds.jl](https://julianlsolvers.github.io/Manifolds.jl/latest/) provides for working with manifolds.\r\nWith these tools, you can for example explicitly locally linearize points using inverse retractions and orthonormal bases.\r\nYou can also compute intrinsic statistics, such as the Riemannian mean and variance, of data on manifolds.\r\nWe also extend [Distributions.jl](https://juliastats.org/Distributions.jl/stable/) to support distributions on arbitrary manifolds, which can be used to generate random points on a manifold or for statistical modeling.\r\n\r\n[Manifolds.jl](https://julianlsolvers.github.io/Manifolds.jl/latest/) implements a library of manifolds and provides combinators to construct new manifolds from these.\r\nExamples are the product manifold of two manifolds, the power manifold, the tangent bundle, and Lie groups.\r\nUsing a trait-based system, any manifold may be augmented with additional geometric structure, including various metrics, without sacrificing efficiency.\r\n\r\nWe also present the light-weight interface package [ManifoldsBase.jl](https://julianlsolvers.github.io/Manifolds.jl/latest/interface.html), which enables users to easily extend [Manifolds.jl](https://julianlsolvers.github.io/Manifolds.jl/latest/) with new algorithms and additional manifolds thanks to multiple dispatch.\r\nThe interface can also be used to develop new, stand-alone projects.\r\nIt is minimally restrictive and makes it possible to write algorithms that are independent from any concrete implementations of the manifolds.\r\nOne package that uses this interface is [Manopt.jl](http://manoptjl.org), which provides optimization algorithms on Riemannian manifolds, with a focus on high-dimensional and non-smooth optimization.",
  "url": "/talk/KCFCMQ",
  "index": 74,
  "speaker": "Ronny Bergmann"
 },
 {
  "start_datetime": "2020-07-31T17:10:00Z",
  "end_datetime": "2020-07-31T17:20:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "RVZNV3",
  "title": "NamedDims.jl: Work with array dimensions by name at no cost",
  "text": "NamedDims.jl: Work with array dimensions by name at no cost This talk will show how you can work with dimensions by name, to make scientific programming both safer and more readable, with no performance cost. We will give an overview [NamedDims.jl](https://github.com/invenia/NamedDims.jl), which allows you to name array dimensions and use intuitive syntax when working with arrays.  For example, letting you fetch the first timestamp with `data[time=1]`, or sum data over time with `sum(data, dims=:time)`.\r\n\r\nWe will focus on showing example where NamedDims helps solve practical problems that appear often in scientific programming.\r\n\r\nFor example, NamedDims.jl makes array operation safer by requiring dimensions to be compatible, so you don’t accidentally e.g. add `time` values to `places` values, and gives an informative error message if you try to.\r\n\r\nAnd by being a zero-cost abstraction, package developers can use NamedDims to make their code safer internally, without requiring users adopt NamedDims. For example,  taking any `AbstractArray` as input and giving the dimensions names internally with no performance hit. \r\n\r\nAnd if users do pass in `NamedDimsArray`, package developers can choose to use that information. For example this opens up the possibility of knowing which dimensions of the data stores “observations”, and allows dealing with data in any orientation.\r\n\r\nNamedDims.jl composes well with other packages, so you can use can pass `NamedDimsArray`s to your favourite machine learning package, have it train on a GPU using your favourite autodiff package, and expect everything to work the same as a plain, unnamed array. And if you pass `NamedDimsArray`s through FFTs you may even get cute `∿`s added to the names of the result!",
  "url": "/talk/RVZNV3",
  "index": 75,
  "speaker": "Nick Robinson"
 },
 {
  "start_datetime": "2020-07-29T12:50:00Z",
  "end_datetime": "2020-07-29T13:00:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "L3FYJW",
  "title": "DrWatson - The perfect sidekick to your scientific inquiries",
  "text": "DrWatson - The perfect sidekick to your scientific inquiries Science is hard! Not only because scientific work requires utmost scrutiny and focus, but also because managing a scientific project is hard and messy. [DrWatson](https://juliadynamics.github.io/DrWatson.jl/stable/) is a scientific project assistant software made for Julia that makes scientific work less nightmarish. DrWatson is the first-of-its-kind scientific project assistant software. It was born out of the frustration about the hardships of managing scientific projects, and constantly re-creating the same functionalities. DrWatson offers several ways to help you manage your project: consistent & universal project structure & navigation, naming schemes, saving tools and simulation management. This talk will introduce and motivate DrWatson and showcase its features in real scientific projects.",
  "url": "/talk/L3FYJW",
  "index": 76,
  "speaker": "George Datseris"
 },
 {
  "start_datetime": "2020-07-31T12:50:00Z",
  "end_datetime": "2020-07-31T13:00:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "GPFUZR",
  "title": "Analyzing species interaction networks in Julia",
  "text": "Analyzing species interaction networks in Julia In this talk, we will present three novel and complementary Julia packages that can handle data on species interactions. These packages can be used to import, simulate, analyze, and visualize all sorts of ecological networks, greatly simplifying the study of this emerging subfield of biology. Network ecology is the novel approach to studying biodiversity. In that respect, this presentation provides an overview of three brand-new packages (`Mangal`, `EcologicalNetworks`, and `EcologicalNetworksPlots`) written by Timothée Poisot and collaborators, which were created in response to the increasing need to handle species interaction data in Julia. Built around state-of-the-art practices in network ecology, they largely facilitate the analysis and visualization of almost all types of species interaction networks. In these, two species are linked together if they can interact.\r\n\r\nThe `Mangal` package is a wrapper around the Mangal database, which is among the world's most exhaustive open source database of ecological interactions. The Mangal database contains 172 well-documented datasets for a total of 1300 ecological networks worldwide. It encompasses various types of ecological networks, including predation (food webs), pollination and parasitism networks.\r\n\r\nIn addition, the `EcologicalNetworksPlots` package implements the visualization of ecological networks, whereas `EcologicalNetworks` provides functions for the analysis of their emergent structure. The structure of species interaction networks is a rich source of information, as it is associated with the stability, dynamics, and functions of biological communities. The `EcologicalNetworks` package is the only one designed to conduct such a specialized analysis in Julia. It is also a suitable tool for the simulation of networks under different sets of assumptions and ecological models. These two packages use a well-documented type system for networks in order to capture the various types of data typically handled by network ecologists. This makes them easily extensible and somewhat fast.\r\n\r\nTogether, these three packages provide an extremely valuable methodological framework for the analysis of ecological networks in Julia. Our presentation offers an overview of their key features and depicts some of their concrete applications in this complex and emerging subfield of biology. It is aimed at ecologists among the Julia community, but also more broadly at network scientists and other attendees fascinated by networks and graphs.",
  "url": "/talk/GPFUZR",
  "index": 77,
  "speaker": "Francis Banville"
 },
 {
  "start_datetime": "2020-07-29T13:10:00Z",
  "end_datetime": "2020-07-29T13:40:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "AD7TQW",
  "title": "AutoMLPipeline: A ToolBox for Building ML Pipelines",
  "text": "AutoMLPipeline: A ToolBox for Building ML Pipelines AutoMLPipeline (AMLP) is a package that makes it trivial to create\r\ncomplex ML pipeline structures using simple\r\nexpressions. AMLP leverages on the built-in\r\nmacro programming features of Julia\r\nto symbolically process, manipulate\r\npipeline expressions, and\r\nmakes it easy to discover optimal structures\r\nfor machine learning prediction and classification. The typical workflow in machine learning\r\nclassification or prediction requires\r\nsome or combination of the following\r\npreprocessing steps together with modeling:\r\n- feature extraction (e.g. ica, pca, svd)\r\n- feature transformation (e.g. normalization, scaling, ohe)\r\n- feature selection (anova, correlation)\r\n- modeling (rf, adaboost, xgboost, lm, svm, mlp)\r\n\r\nEach step has several choices of functions\r\nto use together with their corresponding\r\nparameters. Optimizing the performance of the\r\nentire pipeline is a combinatorial search\r\nof the proper order and combination of preprocessing\r\nsteps, optimization of their corresponding\r\nparameters, together with searching for\r\nthe optimal model and its hyper-parameters.\r\n\r\nBecause of close dependencies among various\r\nsteps, we can consider the entire process\r\nto be a pipeline optimization problem (POP).\r\nPOP requires simultaneous optimization of pipeline\r\nstructure and parameter adaptation of its elements.\r\nAs a consequence, having an elegant way to\r\nexpress pipeline structure helps in the analysis\r\nand implementation of the optimization routines.\r\n\r\n### Package Features\r\n- Pipeline API that allows high-level description of processing workflow\r\n- Common API wrappers for ML libs including Scikitlearn, DecisionTree, etc\r\n- Symbolic pipeline parsing for easy expression\r\n  of complexed pipeline structures\r\n- Easily extensible architecture by overloading just two main interfaces: fit! and transform!\r\n- Meta-ensembles that allow composition of\r\n    ensembles of ensembles (recursively if needed)\r\n    for robust prediction routines\r\n- Categorical and numerical feature selectors for\r\n    specialized preprocessing routines based on types\r\n\r\nTo illustrate, a typical machine learning workflow that extracts\r\nnumerical features (numf) for ICA (independent component analysis) and\r\nPCA (principal component analysis) transformations, respectively,\r\nconcatentated with the hot-bit encoding (ohe) of categorical\r\nfeatures (catf) of a given data for RF modeling can be expressed\r\nin AMLP as:\r\n```julia\r\njulia> model = @pipeline (catf |> ohe) + (numf |> pca) + (numf |> ica) |> rf\r\njulia> fit!(model,Xtrain,Ytrain)\r\njulia> prediction = transform!(model,Xtest)\r\njulia> score(:accuracy,prediction,Ytest)\r\n```",
  "url": "/talk/AD7TQW",
  "index": 78,
  "speaker": "Dr. Paulito Palmes, PhD"
 },
 {
  "start_datetime": "2020-07-30T12:40:00Z",
  "end_datetime": "2020-07-30T12:50:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "M89V9M",
  "title": "Boids: Dancing with Friends and Enemies",
  "text": "Boids: Dancing with Friends and Enemies Boid (\"bird\" pronounced in New York dialect) is an artificial life program\r\nsimulating flocking behaviour.  In this fun, short talk I will describe one\r\nboids simulation, a Dance with Friends and Enemies, and demonstrate a Makie\r\nvisualization that allows manipulating the swarm behaviour in realtime. A Dance with Friends and Enemies is a Boids artificer life program introduced on\r\nthe [Mathematica Forums](https://community.wolfram.com/groups/-/m/t/122095). In\r\nthis simulation each \"dancer\" has a randomly chosen friend and enemy.\r\n\r\nAt each beat of the dance, the dancers \r\n1. Take a step to the center of the dancefloor\r\n2. Take a step to their friend\r\n3. Take a step away from their enemy.\r\n\r\nAlso, at random intervals a dancer will choose new friends and enemies.\r\n\r\nThe sizes of each of these steps, as well as the frequency of partner switches,\r\nare parameters which affect the emergent, flocking behaviour.\r\n\r\nIn this talk I will quickly describe a Julia implementation of this simulation,\r\nwhich is performant with large numbers of dancers.\r\n\r\nFurther, I will demonstrate the emergent flocking behaviour with a visualization\r\nin Makie.jl. This will highlight some of Makie's features. In particular, the\r\nsimulation will have sliders allowing us to modify the parameters and see the\r\naffect on flock behaviour plotted efficiently in realtime.",
  "url": "/talk/M89V9M",
  "index": 79,
  "speaker": "Jesse Bettencourt"
 },
 {
  "start_datetime": "2020-07-30T13:00:00Z",
  "end_datetime": "2020-07-30T13:30:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "8RM33X",
  "title": "JuliaMusic: doing cool science and becoming a better drummer",
  "text": "JuliaMusic: doing cool science and becoming a better drummer JuliaMusic is a collection of packages for analyzing music data. As the lead-dev I use these packages in my day-to-day scientific work about the properties of music. However I also use them to create exercises that help me become a better drummer. JuliaMusic contains intuitive and powerful packages for analyzing music data, made for scientific work on the mathematical properties of music. Thus, they contain advanced functionality that does not exist in counterparts in e.g. Python. The flexibility of JuliaMusic allows me to straightforwardly ask and answer questions about the mathematical structure of music. But through some clever use of combinatorics, I can also use them to produce exercises for my drums practice sessions.",
  "url": "/talk/8RM33X",
  "index": 80,
  "speaker": "George Datseris"
 },
 {
  "start_datetime": "2020-07-30T13:00:00Z",
  "end_datetime": "2020-07-30T13:30:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "HVXXZD",
  "title": "Optimization Algorithms in Julia for GPUs",
  "text": "Optimization Algorithms in Julia for GPUs The ExaSGD (Optimizing Stochastic Grid Dynamics at Exascale) application is part of the Department of Energy's Exascale project (ECP). We show our challenges of finding optimization algorithms for GPUs and present our prototyping framework that written end-to-end in Julia. The ExaSGD (Optimizing Stochastic Grid Dynamics at Exascale) application is part of the Department of Energy's Exascale project (ECP). We use Julia and JuMP for large-scale optimization on the current generation of supercomputers. However, the recent switch from CPU to GPU in the upcoming generation of supercomputers poses great challenges for classic optimization algorithms. Sparse algebra and linear solvers are known to have poor performance on GPUs. Our project looks into novel optimization algorithms that are applied to the alternate current optimal power flow (ACOPF) problem. Current solvers supported by JuMP largely rely on sparse linear solvers. Our goal is to find algorithms that rely on denser algebra that scales over the large number of cores that a GPU provides. We present a complete software stack from modeling to the linear solver that is written completely in Julia and provide an end-to-end overview of the challenges met both at the modeling level as well as at the algebra level. We use automatic differentiation to generate the derivative code for the GPUs and show performance results for the power flow problem (PF) that look promising to be extended to OPF.",
  "url": "/talk/HVXXZD",
  "index": 81,
  "speaker": "Michel Schanen"
 },
 {
  "start_datetime": "2020-07-30T17:10:00Z",
  "end_datetime": "2020-07-30T17:20:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "LRKHWM",
  "title": "Continuables.jl: Python yield in Julia in blazingly fast",
  "text": "Continuables.jl: Python yield in Julia in blazingly fast When coming from Python (or C#) you may be like me and love using generators `yield` a lot. Of course I wanted to have this in Julia, too, and wanted it to be blazingly fast. Unfortunately, the recommended approach using Julia Channels is everything else but super fast. That motivated me to build a solution which in many cases can compile down to perfect machine code: [Continuables.jl](https://github.com/schlichtanders/Continuables.jl). I want to present you the simple idea behind [Continuables.jl](https://github.com/schlichtanders/Continuables.jl), to interprete `yield` as withhold computation. [Continuables.jl](https://github.com/schlichtanders/Continuables.jl) lets you define a generator with `@cont` and use `cont()` as the new ``yield``. \"cont\" stands for continue, which hints at the implementation: A continuable simply expects a function which it can use as the ``cont()`` placeholder. \r\nWith this basic idea (plus some details) you get many of the standard iterable functionalities and the code compiles perfectly.",
  "url": "/talk/LRKHWM",
  "index": 82,
  "speaker": "Stephan Sahm"
 },
 {
  "start_datetime": "2020-07-30T18:50:00Z",
  "end_datetime": "2020-07-30T19:00:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "XQ9YQK",
  "title": "Efficient RANSAC in efficient Julia",
  "text": "Efficient RANSAC in efficient Julia RANSAC.jl offers the Efficient RANSAC algorithm, a widely spread method to recognize simple primitives in point clouds of scanned objects. This talk will show that the package can not only be a basis for existing reconstruction processes, but a tool for further research as well. We introduce the RANSAC.jl package that implements the Efficient RANSAC algorithm. It is a widely used tool in the field of digital shape reconstruction to recognize simple geometric primitives (plane, sphere, cylinder, torus, cone) in point clouds. This algorithm can not only be used alone, but also as part of complex reconstruction processes.\r\n\r\nSo far, mostly C++ implementations have been published, and to the best of my knowledge, this is the first one in Julia. The main goal of the implementation is establishing a flexible tool, while maintaining the same level of performance as existing solutions. This way, not only existing functionality is replicated, but also a new research tool is introduced.",
  "url": "/talk/XQ9YQK",
  "index": 83,
  "speaker": "Tamás Cserteg"
 },
 {
  "start_datetime": "2020-07-29T16:50:00Z",
  "end_datetime": "2020-07-29T17:20:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "XEELRW",
  "title": "Solving Neuroinformatics' Three Language Problem With Julia",
  "text": "Solving Neuroinformatics' Three Language Problem With Julia The field of neuroinformatics requires collaboration from highly skilled experts from many diverse fields.\r\nWe will briefly introduce the problem space and show how JuliaNeuroscience addresses this. Neuroscience relies on the development of highly technical mathematical and computational techniques. These techniques are subsequently used and empirically validated and interpreted with the assistance of neuroscientists. This dynamic results in an additional step to the classic two-language problem, communication between fields that often have a very different knowledge base. Often this communication gap is managed by a common coding language. However, the increasing demand for incorporating multiple modalities and larger sample sizes into data analyses is incompatible with most languages used by neuroscientists (e.g., Matlab, R, Python). Consequently, neuroscientists are often using outdated techniques and those developing newer techniques struggle to reach broader adoption for empirically testing and improving their work. We will show how Julia can help solve the three-language problem through a common programmatic language and the interaction between generic code bases across different fields by introducing the [NeuroCore]( https://github.com/JuliaNeuroscience/NeuroCore.jl) package and related resources.\r\n\r\nWe will begin by providing a high-level overview of how NeuroCore provides a generic API and access to flexible types. We will provide examples illustrating how this design can be easily extended and incorporated by others.  We will then provide brief examples of current and planned uses of NeuroCore, including plotting, graph theory, file format access, and data wrangling. Finally, we will show how this design will facilitate natural integration into other components of the Julia ecosystem.",
  "url": "/talk/XEELRW",
  "index": 84,
  "speaker": "Zachary P Christensen"
 },
 {
  "start_datetime": "2020-07-29T14:20:00Z",
  "end_datetime": "2020-07-29T15:05:00Z",
  "duration": 45,
  "location": "Track 1",
  "id": "UCQCSN",
  "title": "Keynote: Karen Willcox",
  "text": "Keynote: Karen Willcox TBA TBA",
  "url": "/talk/UCQCSN",
  "index": 85,
  "speaker": "Karen Willcox"
 },
 {
  "start_datetime": "2020-07-31T16:55:00Z",
  "end_datetime": "2020-07-31T17:40:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "YYKQCW",
  "title": "What's Next For Dynamical Modeling In Julia?",
  "text": "What's Next For Dynamical Modeling In Julia? Dynamical modeling is arguably one of the biggest strengths of the Julia programming language. With DifferentialEquations.jl, DynamicalSystems.jl, RigidBodyDynamics.jl, ModelingToolkit.jl, DiffEqBiological.jl, Pumas.jl, etc. (the list keeps going), there are many state-of-the-art award winning projects. However, ,what's missing? What's next? Let's discuss and figure out some next steps. There are many directions that we can explore. What should we as a community be prioritizing? I think it would be good to hear from users what they think is \"complete\", and what gaps commonly show up. There's many topics this discussion can go towards:\r\n\r\n1) Improved modeling tools and DSLs (ModelingToolkit)\r\n2) Automated PDE solving\r\n3) Targeting alternative hardware (exporting models for embedded systems)\r\n4) New domains: integro-differential equations, fractional differential equations\r\n5) Geometric methods and DAEs\r\n6) Parallelism (MPI, GPUs, alternative acceleration hardware)\r\n7) Connections: mixing ApproxFun.jl and FEM packages with DifferentialEquations.jl, etc.\r\n8) Continuing to improve benchmarking\r\n9) Accessibility, tutorials, blog posts, etc.\r\n10) Whatever else comes to mind!",
  "url": "/talk/YYKQCW",
  "index": 86,
  "speaker": "Chris Rackauckas"
 },
 {
  "start_datetime": "2020-07-29T17:10:00Z",
  "end_datetime": "2020-07-29T17:20:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "KTDY7J",
  "title": "Probabilistic Optimization with the Koopman Operator",
  "text": "Probabilistic Optimization with the Koopman Operator The probabilistic optimization of dynamical systems is often framed to minimize the expectation of a given loss function. For non-linear systems, the evaluation of such a loss function and its gradient can be expensive. In this work the Koopman Operator and its computational advantages are presented using the AD-compatible [DiffEqUncertainty.jl](https://github.com/JuliaDiffEq/DiffEqUncertainty.jl). The probabilistic optimization of dynamical systems is often framed to minimize the expectation of a given loss function. For non-linear systems, the evaluation of such a loss function and its gradient can be expensive. Often times practitioners rely on implicit methods, such a Monte Carlo simulation, for this calculation due to ease of implementation and understanding. Alternatively, explicit methods such as the Frobenious-Perron Operator can be leveraged to directly evolve probability densities through non-linear systems. Furthermore, the adjoint to the Frobenious-Perron Operator, the Koopman Operator, can be leveraged to the same ends. In this work we will demonstrate how the adjoint property of the Koopman Operator provides significant computational advantages over alternative methods for calculating expectations. We also demonstrate how this Koopman-based approach is AD-compatible. Building on Julia's differential equation ecosystem, this Koopman-based approach is available in [DiffEqUncertainty.jl](https://github.com/JuliaDiffEq/DiffEqUncertainty.jl)",
  "url": "/talk/KTDY7J",
  "index": 87,
  "speaker": "Adam R. Gerlach"
 },
 {
  "start_datetime": "2020-07-29T18:40:00Z",
  "end_datetime": "2020-07-29T18:50:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "3JSMMG",
  "title": "Concatenation and Kronecker products of abstract linear maps",
  "text": "Concatenation and Kronecker products of abstract linear maps In this talk, I present `LinearMaps.jl`, a well-established Julia package for handling linear maps whose action on vectors is given by the classic matrix-vector product or by the application of a function to a vector. I will focus on two recently added features, namely (diagonal) block concatenation and (higher-order) Kronecker products and sums of such abstract linear maps. Linear maps (or operators) are ubiquitous in the mathematical sciences, modeling and scientific computing. In many problems, linear maps are not necessarily given by some matrix representation, but as programs that transform vectors in a linear fashion. Such linear programs can be used, for instance, in iterative linear algebra methods synonymously to usual matrices by wrapping them with the `LinearMaps.jl` package. With this package, more complicated linear maps can be constructed lazily from simple linear function maps or wrapped matrices via scaling, addition, multiplication, transposition and taking the adjoint. Recently, two further classes of such operator algebraic operations have been added to the aforementioned traditional set of operations in `LinearMaps.jl`: horizontal, vertical and diagonal (block) concatenation  and Kronecker products, sums, and powers. These operations feature prominently in applications like structured optimization and image reconstruction. Their implementation in `LinearMaps.jl` facilitates top performance even in the classic matrix context due to their laziness and type-stable usage of specialized multiplication methods.",
  "url": "/talk/3JSMMG",
  "index": 88,
  "speaker": "Daniel Karrasch"
 },
 {
  "start_datetime": "2020-07-31T19:20:00Z",
  "end_datetime": "2020-07-31T19:30:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "PTZDCJ",
  "title": "How similar do two strings look? Visual distances in Julia",
  "text": "How similar do two strings look? Visual distances in Julia We will describe a Julia package VisualStringDistances.jl which provides notions of distance between two strings based on how close they look when printed, and how to use this in the General Registry as an automated check to help prevent malicious lookalike registrations. The Julia package VisualStringDistances.jl provides several notions of distance between two strings based on how they are rendered by GNU Unifont; e.g., capital-eye (“I”) and lowercase-ell (“l”) are close together, while “a” and e.g. “X” are far apart, even though they are both one character apart. By comparing strings visually, this package provides a means for quantifying how easily two strings might be confused when read by a human.\r\n\r\nThis measure of distance is calculated by the means of “unbalanced optimal transport” via the package UnbalancedOptimalTransport.jl which will also be discussed. Loosely speaking, this measures the cost of moving “mass” (i.e. black pixels in the printed representation of a string) from one place to another in order to transform the printed representation of one string into another, allowing the destruction or creation of mass (with some cost). This will be illustrated visually in the talk to provide an understanding of this interesting technique that has been applied to a variety of fields (image registration, economics, traffic flows, etc).\r\n\r\nThe motivating application of VisualStringDistances.jl is for establishing automated checks for Julia’s General registry of packages in order to flag new packages for manual review. A malicious agent might try to register a package with a name that looks very similar to the name of some popular package, and then suggest users use it in online postings or tutorials. A user who copy-pastes the name or code that adds the package might not realize the name is different from that of the popular package. To aid in preventing this scenario, an automated check can be added to the General registry in order to prevent automated merging of new packages whose names look similar to those of existing packages.\r\n\r\nA related task is that of measuring “typo-similarity” to prevent automerging of packages who names are likely to be entered by mistake when typing the name of another package. This will be discussed as well, time permitting.",
  "url": "/talk/PTZDCJ",
  "index": 89,
  "speaker": "Eric P. Hanson"
 },
 {
  "start_datetime": "2020-07-29T12:30:00Z",
  "end_datetime": "2020-07-29T12:40:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "YY9QEJ",
  "title": "KernelFunctions.jl, machine learning kernels for Julia",
  "text": "KernelFunctions.jl, machine learning kernels for Julia Kernel functions are used in an incredible number of applications ranging from SVM to Gaussian processes as well as Stein variational methods. \r\nWith [`KernelFunctions.jl`](https://github.com/theogf/KernelFunctions.jl) we propose a modular and easily customizable kernel framework. The emphasis made in this package is to work smoothly with automatic differentiation while being able to construct arbitrarily complex kernels both in terms of input transformation and kernel structure. Realising that every package requiring kernels was having his own implementation and that `MLKernels.jl`, the last standard, had a lot of imcompabilities, William Tebbutt and I decided to work on a common project usable by all. \r\n`KernelFunctions` allows to process arbitrary transformations on the input data allowing for example to use a neural net or to construct kernel sums and product to create complex kernel structures. A series of standard kernels are available and more and more are added but creating a custom kernel is extremely straight-forward.\r\nThe package needs only a few dependencies and is very light-weight.\r\n\r\nI will give a brief introduction to the kernel methods followed by a few concrete examples such as deep kernel learning or automatic kernel selection.",
  "url": "/talk/YY9QEJ",
  "index": 90,
  "speaker": "Théo Galy-Fajou"
 },
 {
  "start_datetime": "2020-07-31T13:00:00Z",
  "end_datetime": "2020-07-31T13:10:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "VPUS7J",
  "title": "Introducing the Hispanic community to Julia",
  "text": "Introducing the Hispanic community to Julia This talk gives the origin and development of the Spanish translation of the open-source book “Think Julia”, titled “Introducción a la Programación en Julia”. This book focuses on teaching to program with Julia as the first programming language and is one of the first books in Spanish about Julia. The goal of this translation is to facilitate the use of Julia in the Hispanic community; the English level of most Latin American countries is medium or low according to the English Proficiency Index. For Julia, the diversity of users is fundamental for its development and growth. Users from different backgrounds, regions, ages, and social contexts can contribute with different perspectives, and promote its usage in their context. This talk presents our experience translating into Spanish the open-source book “Think Julia”, titled “Introducción a la Programación en Julia”. The goal of this translation is to facilitate the use of Julia in the Hispanic community. We will share how we planned and executed the translation, what we learned in the process, and why you might want to do something similar.\r\n\r\nThe talk will review the choice to translate an introductory text rather than the Julia manual, including its utility to students in secondary education (high-school). A brief history of ThinkJulia will be shared, including its license and the use of Julia to verify inline code excerpts. We will review the utility of PDF and online versions (see https://introajulia.org/). \"Intro a Julia\" will be presented as a valuable tool for Spanish coders without English proficiency.",
  "url": "/talk/VPUS7J",
  "index": 91,
  "speaker": "Pamela Alejandra Bustamante Faúndez"
 },
 {
  "start_datetime": "2020-07-29T18:50:00Z",
  "end_datetime": "2020-07-29T19:00:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "NMGTD9",
  "title": "SIMD in Julia - Automatic and explicit",
  "text": "SIMD in Julia - Automatic and explicit SIMD (Single Instruction, Multiple Data) is a term for when the processor executes the same operation (like addition) on multiple numbers (data) in one instruction. This can give significant speedups. Julia has many ways to take advantage of SIMD, sometimes it happens automatically, as an optimization, but it is also possible to manually write SIMD code.\r\nThis talk will give an overview of the different ways you can use SIMD in Julia. SIMD (Single Instruction, Multiple Data) is a term for when the processor executes the same operation (like addition) on multiple numbers (data) in one instruction. Recent processor architectures come with the capability of running these SIMD instructions on even larger batches of data, making it more important to make sure that SIMD is used when possible, for best performance.\r\n\r\nFortunately, in many cases, Julia can automatically make code use SIMD. Often this comes from optimizations made by LLVM, the code generation library Julia uses. Some cases of this are in:\r\n\r\n- Loops, where the LLVM Loop Vectorizer can identify patterns where the loop can be unrolled so that multiple iterations can be done When there is a reduction involved, like when summing the elements of an array, the `@simd` macro might be needed.\r\n- Different patterns of scalar operations that can be combined into one SIMD instructions, like when adding two tuples. This is vectorized by the LLVM SLP (Superword-Level Parallelism) vectorizer.\r\n\r\nThere are however cases where auto-vectorization like above doesn’t happen. This can be when LLVM does not recognize the opportunity to use SIMD or when it isn’t valid to do so because it could change the result slightly. In cases like this, it is possible to:\r\n\r\n- Use a “SIMD vector library” like SIMD.jl. This allows one to create a “SIMD Vector” that works similarly to a number but operations on it will work elementwise using SIMD instructions.\r\n- Explicitly call machine instructions specific for a certain CPU architecture. This gives the most control but has the drawback of tying the code the CPU architecture, making it less generic. \r\n\r\nThis talk will show discuss and show examples of the above SIMD cases, giving insight into how to leverage SIMD for greater performance.",
  "url": "/talk/NMGTD9",
  "index": 92,
  "speaker": "Kristoffer Carlsson"
 },
 {
  "start_datetime": "2020-07-30T17:20:00Z",
  "end_datetime": "2020-07-30T17:30:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "PHGCKB",
  "title": "Integrating Julia in R with the JuliaConnectoR",
  "text": "Integrating Julia in R with the JuliaConnectoR Despite the advantages of Julia, there are some hurdles that prevent R users from making the leap and switch to Julia. To bring Julia closer to R, we developed the new [\"JuliaConnectoR\" R package](https://github.com/stefan-m-lenz/JuliaConnectoR) that conveniently integrates Julia in R, allowing R users to harness the power of Julia, and making it easier for Julia developers to share features of their Julia code with R users. R and Julia are two languages that complement each other very well: R has many convenient features from a huge number of packages. Julia brings new possibilities for writing fast code and offers new and innovative packages. Integrating functionality of Julia in R is especially promising due to the many commonalities of Julia and R. We take advantage of these in the design of our \"JuliaConnectoR\" R package (https://github.com/stefan-m-lenz/JuliaConnectoR), which aims at a tight and stable integration of Julia in R.\r\n\r\nThe JuliaConnectoR can import Julia functions, also from whole packages, and make them directly callable in R. Values and data structures are translated between the two languages. Julia objects can be fully translated to R objects or accessed via proxy object that behave like R objects. In addition to directly using features from Julia packages, this also greatly simplifies writing own Julia code for optimizing time critical portions of R code compared to writing C extensions in R.\r\n\r\nThe possibility to pass R functions as arguments to Julia functions makes the JuliaConnectoR a truly functional interface. Such callback functions can, e. g., be used to interactively display the learning process of a neural network in R while it is trained in Julia. This sets the JuliaConnectoR apart from the other R packages for integrating Julia in R, “XRJulia” and “JuliaCall”. Additionally, the JuliaConnectoR offers features that make the interactive use more convenient and stable, such as the redirection of standard (error) output and the ability to interrupt running calls to Julia. These unique features become possible with an optimized communication protocol, based on TCP, which also allows a highly efficient data transfer by leveraging the similarities in the binary representation of values in Julia and R.\r\n\r\nWe show the implementation of the package and demonstrate the features of the JuliaConnectoR with several examples, including deep learning with the Julia package “Flux” in R and analysing large datasets via “JuliaDB”.",
  "url": "/talk/PHGCKB",
  "index": 93,
  "speaker": "Stefan Lenz"
 },
 {
  "start_datetime": "2020-07-30T18:00:00Z",
  "end_datetime": "2020-07-30T18:30:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "7ZJCPC",
  "title": "Causal Bayesian Inference with Soss.jl",
  "text": "Causal Bayesian Inference with Soss.jl [Soss](https://github.com/cscherrer/Soss.jl) is a declarative probabilistic programming language (PPL) that represents statistical models in terms of abstract syntax trees, and uses staged compilation for on-demand code generation for inference primitives. This allows efficient code, while retaining simplicity for casual users. [Soss](https://github.com/cscherrer/Soss.jl) is a declarative probabilistic programming language (PPL) that represents statistical models in terms of abstract syntax trees, and uses staged compilation for on-demand code generation for inference primitives. This allows efficient code, while retaining simplicity for casual users.\r\n\r\nMany characteristics of Soss distinguish it from most other PPLs:\r\n\r\n- Soss models are _function-like_, so a model works as a function from its arguments to a joint distribution. In particular, specification of \"observed variables\" is separated from model definition.\r\n- Soss models are _first-class_; models can be passed as arguments to other models, or used in place of distribution functions like `Normal` within a model.\r\n- Model specification in Soss is _declarative_; statements are represented not by the order entered by the user, but by the partial order given by their variable dependencies. \r\n- Soss adds several of _distribution combinators_ for building new distributions in terms of existing ones.\r\n- Soss supports _causal inference_ through an implementation of [Pearl's `do` operator](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2836213/)\r\n- Values and distributions in Soss are represented internally as _abstract syntax trees_, keeping the internal representation close to that given by the user for maximum flexibility.\r\n- Soss uses _staged compilation_ for inference primitives like `rand` and `logpdf`, using _generalized generated functions_ from [GeneralizedGenerated.jl](https://github.com/thautwarm/GeneralizedGenerated.jl).\r\n- Soss supports _model transformations_, functions that take a model and return another model.\r\n- Soss supports _symbolic simplification_, making it easy to inspect or manipulate a symbolic representation of the log-density, or to use it to generate optimized code.\r\n- Soss is _extensible_; users can define new inference primitives or model transformations externally, and use them as if they had been included in Soss. , and can also also use functions, distributions, or combinators defined locally by users, without modifying the Soss library.\r\n\r\nIn this talk, we'll introduce Soss and describe these features through simplified causal analysis of a small data set.",
  "url": "/talk/7ZJCPC",
  "index": 94,
  "speaker": "Chad Scherrer"
 },
 {
  "start_datetime": "2020-07-31T13:00:00Z",
  "end_datetime": "2020-07-31T13:10:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "DTAFMF",
  "title": "A fast atmospheric radiation code for global circulation models",
  "text": "A fast atmospheric radiation code for global circulation models Global circulation models, for numerical weather and climate prediction, spend about 30% of their time in radiation computations. Hence, the performance of atmospheric radiative transfer models (RTMs) is critically important.\r\n\r\nWe present RRTMGP.jl, a commonly used atmospheric RTM for global circulation models. Translated from Fortran, RRTMGP.jl has new abstractions, CI tests, and will run on GPUs. We will give a quick overview of the problem/equations that are solved and improvements. ",
  "url": "/talk/DTAFMF",
  "index": 95,
  "speaker": "Charlie Kawczynski"
 },
 {
  "start_datetime": "2020-07-31T16:10:00Z",
  "end_datetime": "2020-07-31T16:55:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "CA3SET",
  "title": "Julia & Data: An Evolving Ecosystem",
  "text": "Julia & Data: An Evolving Ecosystem Come join authors and fellow users of many of Julia's most popular data-related packages to discuss what works, what doesn't, and how current roadmaps can reconcile the two. ",
  "url": "/talk/CA3SET",
  "index": 96,
  "speaker": "Jacob Quinn"
 },
 {
  "start_datetime": "2020-07-31T18:00:00Z",
  "end_datetime": "2020-07-31T18:30:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "UPHPAT",
  "title": "GigaSOM.jl: 1 billion cytometry events and beyond with Julia",
  "text": "GigaSOM.jl: 1 billion cytometry events and beyond with Julia Studies in immunology, developmental biology, and medicine use flow and mass cytometry to generate huge amounts of single-cell data. GigaSOM.jl is a high-performance, horizontally scalable implementation of the commonly used clustering and visualization algorithms used in cytometry, designed to handle dataset of sizes inaccessible to currently available tools. We show the structure and design of GigaSOM.jl, and demonstrate the results on recent datasets from a massive immunophenotyping effort. GigaSOM is an implementation of the Self-Organizing-Maps algorithm by Kohonen that facilitates  the clustering and dimension reduction of huge-scale datasets, counting billions of individual data points with tens of dimensions. Its development, showcased at the 2019 JuliaCon conference, is motivated by the needs of flow and mass cytometry data analysis, relevant in immunology, developmental biology and clinical medicine: Individual cells from the measurements need to be precisely categorized (which is currently best done by the self-organizing maps as devised by van Gassen et al. (2015)), and eventually evaluated and visualized.\r\n\r\nGigaSOM is able to perform this precise kind of computation on large compute clusters, and facilitates the analysis to scale horizontally. We will describe a Julia toolkit for map-reduce-style computation and data distribution in the common HPC environments, which we developed for the purposes of GigaSOM. The toolkit cooperates with the Distributed package, and works well within common cluster software, e.g. Slurm. With that in hand, we demonstrate high-level implementation of SOMs and related algorithms (e.g. EmbedSOM (Kratochvíl et al., 2019)) that scale horizontally, show measurements of the performance, and demonstrate the results achievable on several datasets, including the data from International Mouse Phenotyping Consortium (Brown & Moore, 2012). Notably, our testing showed that 1 billion data points can be processed within only minutes using relatively common computer clusters or cloud compute grids, which vastly expands the possibilities of large-scale data analysis.\r\n\r\nThe quality of the software package is assured using ARTENOLIS (https://artenolis.lcsb.uni.lu) (Heirendt et al., 2017). Biological validation of the results is performed by comparison to conventional implementations of the FlowSOM package and manual analysis.",
  "url": "/talk/UPHPAT",
  "index": 97,
  "speaker": "Miroslav Kratochvíl, Oliver Hunewald"
 },
 {
  "start_datetime": "2020-07-31T17:20:00Z",
  "end_datetime": "2020-07-31T17:30:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "ER3ZYC",
  "title": "Changing the immutable",
  "text": "Changing the immutable We discuss the problem of updating immutable objects. The solutions presented are implemented in the [`Setfield.jl`](https://github.com/jw3126/Setfield.jl) package. In Julia, some objects are *mutable* (`Array`, `mutable struct`, `...`), while others are *immutable* (`Tuple`, `struct`, `...`). Neither is strictly better than the other in every situation. However, *immutability* usually leads to code that is easier to reason about, for both humans and compilers. And therefore less buggy and more performant programs.\r\nOne convenience with mutability is, that it makes updating objects very simple:\r\n\r\n`spaceship.captain.name = \"Julia\"`\r\n\r\nThe analogous operation in the immutable case is to create a copy of `spaceship`, with just the captain's name changed to \"Julia\".\r\nJust think for a moment, how would you achieve this? It is a serious obstacle to adopting immutables in practice. The title \"Changing the immutable\" refers to this and similar problems. There are various approaches, for instance, https://github.com/JuliaLang/julia/pull/21912 .\r\n\r\nI would like to talk about this problem and present one solution, namely [`Setfield.jl`](https://github.com/jw3126/Setfield.jl). In the spirit of Julia, it is dirt simple to learn:\r\n\r\n`@set spaceship.captain.name = \"Julia\"`\r\n\r\nyet keeps the most serious hackers happy (as it is built around the beautiful concept of [lenses](https://hackage.haskell.org/package/lens)).",
  "url": "/talk/ER3ZYC",
  "index": 98,
  "speaker": "Jan Weidner"
 },
 {
  "start_datetime": "2020-07-29T13:30:00Z",
  "end_datetime": "2020-07-29T14:00:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "DBGWXK",
  "title": "Salsa.jl: A framework for on-demand, incremental computation",
  "text": "Salsa.jl: A framework for on-demand, incremental computation [Salsa.jl](https://github.com/RelationalAI-oss/Salsa.jl) is a framework for on-demand, incremental computation. This type of incremental computing is seen in modern compilers (for IDEs), database systems (to maintain queries), spreadsheets (to recompute values on edits) and web applications (for UIs). `Salsa` guides and simplifies writing such applications and ensures correctness by construction. We use `Salsa` at RelationalAI as the core of our highly responsive compiler and database product. Incremental computation reframes the way we build responsive systems such as databases, compilers, ML applications, spreadsheets, and web apps. Performing the minimal amount of computation needed to update a result means avoiding re-running a full computation, boosting performance.\r\n\r\nModern compilers are one such challenging responsive system. Programmers expect tools (Atom, VSCode) to understand their programs _while typing_, and to provide syntax highlighting, cross-linking, error indicators, auto-completion and documentation. IDEs essentially need a full-blown compiler front-end. To facilitate this, modern compilers are no longer designed as batch compilers consisting of distinct passes, but rather with on-demand usage as a primary use case (eg by allowing cheaply type-checking a function while accepting errors).\r\n\r\nTo meet this challenge, state-of-the-art compilers employ generic frameworks for incremental computing. Rust uses the [salsa](https://github.com/salsa-rs/salsa) framework (see this [PLISS 2019 recording](https://youtu.be/N6b44kMS6OM) for an in-depth discussion).\r\n\r\nIn this talk, we introduce [Salsa.jl](https://github.com/RelationalAI-oss/Salsa.jl), which is inspired by Rust's salsa. Salsa.jl (like incremental computing frameworks in general) takes away the guesswork in building efficient incremental systems through its automatic dependency tracking and cache invalidation via versioning. Salsa.jl also introduces novel incremental computation features such as _maintaining_ computations, recursion, and improved dependency analysis. For example, thanks to Julia, Salsa is extensible and supports using existing automatic differentiation tools to maintain computations.\r\n\r\nWe use Salsa in production to build a declarative programming language and database system with fast incremental evaluation and immediate feedback. As a novel use-case, we show how Salsa makes it easy to implement a multi-stage language where compilation and evaluation are interleaved.\r\n\r\nWe show how to use Salsa to build a small on-demand compiler and an incremental spreadsheet that is correct by construction.\r\n\r\nSalsa takes advantage of Julia's meta-programming features and design choices, such as macros, dynamic computation, multiple dispatch, excellent performance, and bias towards immutable data structures. This talk demonstrates that Julia is a remarkably pleasant and productive language for implementing compilers and for incremental computation more broadly.",
  "url": "/talk/DBGWXK",
  "index": 99,
  "speaker": "Nathan Daly"
 },
 {
  "start_datetime": "2020-07-29T13:40:00Z",
  "end_datetime": "2020-07-29T13:50:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "87JCMX",
  "title": "Dependency-Aware Jupyter Notebooks",
  "text": "Dependency-Aware Jupyter Notebooks Jupyter notebooks are useful for sharing Julia code. But if collaborators have different package versions, bugs arise and reproducibility is lost. \r\n\r\nWe present two tools that solve this problem, and describe their use in QuantEcon's Julia course. One (InstantiateFromURL.jl) allows binds notebooks to GitHub repositories for TOML, and supports version-controlling notebooks and manifests. The other (PkgUtils.jl) allows for direct pasting of Manifest and Project information into the notebook file. The current method for sharing dependency information with Jupyter is simply to send TOML files along with the notebook. This can be difficult (e.g. for students, who may struggle with Julia environments), and generally hampers mobility.\r\n\r\nThe QuantEcon Julia course uses InstantiateFromURL.jl to have notebooks download (version-controlled) TOML from GitHub. We demonstrate its support for both local machines and JupyterHubs.",
  "url": "/talk/87JCMX",
  "index": 100,
  "speaker": "Arnav Sood"
 },
 {
  "start_datetime": "2020-07-31T18:00:00Z",
  "end_datetime": "2020-07-31T18:30:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "P8D3PF",
  "title": "DynamicGrids.jl: high-performance spatial simulations in Julia",
  "text": "DynamicGrids.jl: high-performance spatial simulations in Julia DynamicGrids.jl is a new framework for constructing, running and visualising gridded spatial simulations, in Julia, developed for organism dispersal modelling with Dispersal.jl, but but generalised to be applicable to a wide range of contexts. DynamicGrids.jl facilitates the easy construction of custom high-performance spatial simulations. It provides tools to construct simple simulations like the game-of-life and other cellular automata, but also complex, multi-rule and even multi-grid simulations that can involve random grid writes and grid interactions. DynamicGridsGtk.jl and DynamicGridsInteract.jl provide live visual interfaces, where simulations can be tweaked in real-time. Dispersal.jl will be used to demonstrate its potential.",
  "url": "/talk/P8D3PF",
  "index": 101,
  "speaker": "Rafael Schouten"
 },
 {
  "start_datetime": "2020-07-31T16:10:00Z",
  "end_datetime": "2020-07-31T16:40:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "HBTFT7",
  "title": "Using VS Code for Julia development",
  "text": "Using VS Code for Julia development This talk will demonstrate how one can use the Julia extension for VS Code effectively. Special emphasis will be given to new features like the debugger, the workspace view, remote scenarios and support for Julia Notebooks (if finished by Juliacon). This talk is targeted as novel and experienced users of the Julia VS Code extension. I will provide an overview of the basic functionality, showcase tricks and good practice. I will also introduce a number of major new features that have been introduced since the last Juliacon:\r\n- the debugger and how to effectively use it.\r\n- the workspace view and how to effectively use it.\r\n- support for Julia Notebooks, how they work and how one can use them.\r\n- how one can use the remote capabilities of VS Code for Julia developments (including VS online).",
  "url": "/talk/HBTFT7",
  "index": 102,
  "speaker": "David Anthoff"
 },
 {
  "start_datetime": "2020-07-30T12:30:00Z",
  "end_datetime": "2020-07-30T12:40:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "KK9S9V",
  "title": "Creating a multichannel wireless speaker setup with Julia",
  "text": "Creating a multichannel wireless speaker setup with Julia The Julia package ecosystem provides a rich trove of useful functionality across a wide range of platforms.  By standing on the shoulders of giants and combining packages such as `ZMQ.jl`, `Opus.jl`, `PortAudio.jl`, `DSP.jl` and more, we are able to build a multichannel, low-latency, intelligent wireless speaker system that runs on cheap single-board linux computers. Taking advantage of some of the strengths of the Julia package ecosystem and tooling, we will demonstrate the ease with which an advanced wireless speaker system can be developed and deployed across heterogenous architectures.  Combining `ZMQ.jl` for easy and fast communication, `DSP.jl` and `PortAudio.jl` for signal processing/audio IO, `Opus.jl` for high-quality compression during transmission and some cheap single-board linux computers, we are able to build a system that performs the kind of realtime audio processing that we crave, all without breaking the bank.  This talk will focus on demonstrating the usefulness of having a single language that can deal with signal processing, low-latency network communication, and cross-platform binaries, all at once.",
  "url": "/talk/KK9S9V",
  "index": 103,
  "speaker": "Elliot Saba"
 },
 {
  "start_datetime": "2020-07-29T18:00:00Z",
  "end_datetime": "2020-07-29T18:45:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "QF8BC7",
  "title": "Project Binder and the Julia Community: Planning for the Future",
  "text": "Project Binder and the Julia Community: Planning for the Future This Birds of Feather session aims to facilitate structured discussion around some of the themes that arose from the mybinder.org user survey (https://mybinder.org). Specifically, which features or improvements would the Julia community like the Project Binder team (https://jupyter.org/binder) to pursue, what roadblocks do they foresee, and what \"on ramps\" are available for community members to become involved in the development and implementation processes. The Binder Project is a collection of tools that rewards best practices in reproducible data science and provides an easy method of sharing computing environments with anyone via a single clickable link. The free and public Binder service, hosted at https://mybinder.org, serves around 100,000 launches per week from over 10,000 individual git repositories in a variety of programming languages, including Julia.\r\n\r\nBinder is a community-driven project, taking the lead from community-developed standards of reproducibility and input from its users via the mybinder.org user survey. The user survey was last conducted at the beginning of 2020 and a summary of the results, both general and specific to the Julia community, will be presented.\r\n\r\nThere are so many fantastic ideas and features the Binder project team (https://jupyterhub-team-compass.readthedocs.io/en/latest/team.html#binder-team) would like to develop but - like many open source projects - we face time restrictions, a low bus factor (https://en.wikipedia.org/wiki/Bus_factor), and often lack domain expertise when developing language-specific features.\r\n\r\nSarah Gibson would like to introduce the Binder Project to the Julia community as an opportunity to shape a tool that would be most useful to them and provide guidance on how to get started with contributing to or joining the project.",
  "url": "/talk/QF8BC7",
  "index": 104,
  "speaker": "Sarah Gibson"
 },
 {
  "start_datetime": "2020-07-30T17:10:00Z",
  "end_datetime": "2020-07-30T17:40:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "WNBYW8",
  "title": "Interactive notebooks ~ Pluto.jl",
  "text": "Interactive notebooks ~ Pluto.jl Introducing a fresh, new notebook system for rapid prototyping! Pluto understands global references between cells, and reactively re-evaluates cells affected by a code change. At JuliaCon, we will show how Pluto can liven up your workflow. Whether you’re a scientist, a finance professional or an engineer, you use notebooks like Jupyter to tell a story. You fiddle a bit with your code, running cells here and there, and when you’re done - you restart the kernel and keep your fingers crossed that it’ll all work together when you press “run all”. \r\n\r\n🙋 **In Pluto, things work differently.** When you change a variable, Pluto automatically re-runs the cells that refer to it. And when you delete a cell, the variables, methods and imports from the old code disappear. Unlike Jupyter or Matlab, there is **no mutable workspace**, but rather a _one-to-one correspondence_ between variables and code. \r\n\r\n🚨 Reactivity is not just fun for mathematical tricks! It guarantees that the code you see exactly matches the variables you're working with, eliminating bugs before you even knew you had them. \r\n\r\n⚡ Your notebook becomes interactive by splitting your code into multiple cells! Changing one cell **instantly shows effects** on all other cells, giving you a fast and fun way to experiment with your model. And to really spice up your notebook, you can use HTML sliders, or even custom JavaScript widgets, to drive your Julia variables. Change `λ = 5` to `@bind λ Slider(1:10)`, and all cells that use `λ` are controlled by a slider.\r\n\r\n💾 Notebooks are **saved as pure Julia files** and can be exported as rich documents with cell output to HTML or PDF. By separating source code and output, you can take full advantage of git for version control and you can import Pluto notebooks as if they are written in a regular editor.\r\n\r\n---\r\n\r\nAfter a live demo, the second part of the talk will unveil some of the tricks that power Pluto. The core concepts are: \r\n- **_static code analysis_** to find global definitions and references in cells;\r\n- **_directed graph_** of cells, which tells Pluto which cells to run, in which order;\r\n- **_managed workspace_** for code to live in, and cleaning the workspace in milliseconds;\r\n- **_responsive connection_** between JavaScript clients and Julia.\r\n\r\nPluto is **written in pure Julia**, which comes with two benefits: first, it’s easily installable as a package without requiring Python - you only need Julia and a web browser. Second, it is ready to be improved by Julia developers who we hope to inspire at the conference. Pluto is an exciting project to work on, and we are eager to hear your ideas!\r\n\r\n[https://github.com/fonsp/Pluto.jl](https://github.com/fonsp/Pluto.jl)",
  "url": "/talk/WNBYW8",
  "index": 105,
  "speaker": "Fons van der Plas"
 },
 {
  "start_datetime": "2020-07-31T13:40:00Z",
  "end_datetime": "2020-07-31T13:50:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "ZMHR9V",
  "title": "A Parallel Time-Domain Power System Simulation Toolbox in Julia",
  "text": "A Parallel Time-Domain Power System Simulation Toolbox in Julia This talk introduces a new flexible and extendable parallel time-domain simulation toolbox developed in Julia for the analysis of power system dynamics in large networks. The simulation algorithm adapts a parallel-in-space decomposition scheme to a sequential algorithm to create parallelizable tasks in the numerical solution of the power system analysis problem. Test simulations using a supercomputing cluster show a huge potential for computational speedup with increasing network complexity. Dynamic simulations are important in the design and operation of power systems in order to ensure grid stability. Traditional simulation tools in research and industry mainly rely on time-domain simulations based on step-by-step numerical integration. The power system, however, has seen an increase in complexity in light of the current operation of large interconnected networks, growth in electricity demand, and the increasing integration of renewable energies. From the power system analysis perspective, the impact of these changes in operating conditions is an increase in computational complexity in the simulation tools applied for stability and control studies. Parallel and distributed computing techniques are frequently applied to improve the computational speed by taking advantage of multi-core processors and cluster computing. However, the analysis methods for time-domain simulations were developed for sequential operation and optimized for running on single-processors, thereby rendering their application for parallel solutions challenging.\r\n\r\nThis talk introduces a new Julia-based parallel simulation algorithm to address the need for efficient computation methods in power system stability analysis. The parallel algorithm achieves computational efficiency by adapting an inherently sequential power system numerical solution to a parallel solution using a parallel-in-space decomposition scheme and the Julia computing environment. This talk will describe the parallel-in-space technique which is applied to restructure the power system problem in such a way that it can be applied for formulation of a parallel algorithm. The in-space decomposition is based on the Block Bordered Diagonal Formulation (BBDF) to divide the network coefficient matrix into submatrices that can be solved in parallel. The talk will show how optimal balancing of tasks in the parallel solution process is achieved using a multi-level graph partitioning technique, which is extended to the dynamic simulation problem to obtain balanced subnetworks to be solved in parallel and only linked via an interconnect partition to share information at every time step.\r\n\r\nSimulation results will be presented using IEEE standard test networks of varying complexity. The results in the parallel simulation toolbox are compared to those obtained from a sequential implementation in order to validate the solution accuracy and to determine performance improvements in terms of computational speedup.",
  "url": "/talk/ZMHR9V",
  "index": 106,
  "speaker": "Michael Kyesswa"
 },
 {
  "start_datetime": "2020-07-30T18:00:00Z",
  "end_datetime": "2020-07-30T18:45:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "9X7V3A",
  "title": "JuliaGPU",
  "text": "JuliaGPU Bird of a feather for the JuliaGPU ecosystem ",
  "url": "/talk/9X7V3A",
  "index": 107,
  "speaker": "Valentin Churavy"
 },
 {
  "start_datetime": "2020-07-31T13:50:00Z",
  "end_datetime": "2020-07-31T14:00:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "JFUJJ7",
  "title": "Evolutionary algorithms for electrical circuit design",
  "text": "Evolutionary algorithms for electrical circuit design The goal of this presentation will be to illustrate how the design\r\nof equivalent electrical circuits for the analysis of electrochemical\r\n(e.g. biological) systems can be optimized with an approach based\r\non evolutionary algorithms. Electrochemical impedance spectroscopy (EIS) is the study of a\r\nsample by measuring its resistance to alternating electrical currents (termed\r\nimpedance) over a range of frequencies. The data arising from these experiments\r\nis commonly analysed by fitting an equivalent electrical circuit (EIC),\r\nwhich consists of resistors, capacitors and possibly other electrical elements.\r\nWhen considering well defined basic electrical systems, the configuration of\r\nthese circuits is relatively straightforward. More complex systems, such as\r\nthose arising in biology, where reasoning about the appropriate configurations\r\nof the circuits becomes more challenging and subjective, can benefit from an\r\nalgorithmic approach.\r\nAn efficient Julia equivalent electrical circuit modelling and fitting module\r\nthat was implemented will be discussed. Next the evolutionary algorithms\r\nused to build optimal circuit designs based on the biological measurement\r\ndata and fit the circuit-element parameters of the design, will be explained\r\nalong with some performance metrics.",
  "url": "/talk/JFUJJ7",
  "index": 108,
  "speaker": "Maxime"
 },
 {
  "start_datetime": "2020-07-31T12:30:00Z",
  "end_datetime": "2020-07-31T12:40:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "TKAXGF",
  "title": "Bringing Julia to the Realm of Electronic Structure Theory",
  "text": "Bringing Julia to the Realm of Electronic Structure Theory This talk introduces JuliaChem.jl, a package designed for performing quantum chemistry calculations via electronic structure theory methods. JuliaChem.jl uses Julia’s features to achieve performance similar to established quantum chemistry codes. Electronic structure theorists love performing novel research in a variety of ways. However, the use of new programming languages remains largely unexplored. Due to its combination of features, Julia could be an extremely useful tool for quantum chemists, enabling high productivity without sacrificing performance. In this talk, we will see how Julia’s potential in electronic structure theory can be realized, by introducing the JuliaChem.jl package.",
  "url": "/talk/TKAXGF",
  "index": 109,
  "speaker": "David Poole"
 },
 {
  "start_datetime": "2020-07-29T13:00:00Z",
  "end_datetime": "2020-07-29T13:30:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "Z8TE39",
  "title": "Shippable apps and custom sysimages with PackageCompiler.jl",
  "text": "Shippable apps and custom sysimages with PackageCompiler.jl This talk presents the new 1.0 release of the Julia package PackageCompiler.jl which allows one to, in addition to create sysimages, also create “apps” or executables which can be run on machines that do not have Julia installed. In addition, it gives a background to the Julia compilation model and how and why one would want to create custom sysimages. When a function is to be executed for the first time in Julia there are several steps that need to happen. The code needs to be parsed, type inference has to run, LLVM has to compile it to machine code etc. Depending on the function, this can take some time giving a bit of a latency to the first call of a function. When packages are loaded, there is a precompilation step that takes place that tries to cache some of this work, but even with that the latency before the function actually runs can be significant.\r\n\r\nJulia comes with a few packages that are already installed and available without having to explicitly add them like normal packages. These are called “standard libraries” and the Julia REPL is one of them. You might have noticed that the Julia REPL loads almost instantly (significantly faster than a “normal” package) even though it is a quite complex package. This is because it is compiled into what is called a “sysimage” which allows more extensive caching of compiled code than the normal package precompilation system.\r\n\r\nPackageCompiler.jl (which recently had its 1.0 release) is a package that makes it easy to create custom sysimages which can include other packages than the default standard libraries. This can be used in cases where a commonly used package is slow to load or has functions with high overhead for the first call.\r\n\r\nIn addition, PackageCompiler.jl can create apps that can be downloaded and directly run on a machine that doesn’t have Julia installed. It works together with [the artifact system](https://julialang.org/blog/2019/11/artifacts/) allowing automatic bundling of external binaries and libraries. This allows one to ship quite sophisticated apps written in Julia in a simple manner.\r\n\r\nThis talk will expand on the points above and show the API of PackageCompiler.jl v1.0.",
  "url": "/talk/Z8TE39",
  "index": 110,
  "speaker": "Kristoffer Carlsson"
 },
 {
  "start_datetime": "2020-07-29T16:20:00Z",
  "end_datetime": "2020-07-29T16:50:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "GALAX8",
  "title": "JuliaCats: Applied Category Theory in Julia",
  "text": "JuliaCats: Applied Category Theory in Julia Applied Category Theory is a new paradigm of applied mathematics that incorporates the advances in type theory to analyze scientific and engineering systems. Our talk will describe the JuliaCats software ecosystem for representing and executing category theoretic computations with applications to numerical linear algebra, scientific modeling, and data science. Applied Category Theory builds on algebraic interpretations of type systems to represent mathematical reasoning in a universal way. This allows the construction of domain specific logics that can capture the reasoning systems employed by programmers, scientists, and engineers in differing applications. The Julia type system is sufficiently sophisticated to support implementations of these domain specific logics, while the metaprogramming facilities support the implementation of domain specific languages for describing systems within these domain specific logics. \r\n\r\nThis talk will illustrate how features of Julia interact to create an ideal environment for implementing such abstract and mathematical structure in code, and feature some specific applications to the technical computing community. Such examples include, reasoning about linear maps graphically, constructing scientific models of chemical or biological systems via model composition, and hierarchical design of complex systems. The algebraic approach used in this ecosystem illustrates how many techniques in computer science that represent processes as graphs with mathematical interpretations are related on a deep level. The generic programming capabilities of julia combined with low cost abstractions allow us to realize this similarity in the structure of our software, which reveals and leverages the similarity between application areas to build cohesive tooling for diverse applications.\r\n\r\nThis talk will present code developed in the Catlab.jl, Petri.jl, and SemanticModels.jl packages.",
  "url": "/talk/GALAX8",
  "index": 111,
  "speaker": "James Fairbanks, Micah Halter"
 },
 {
  "start_datetime": "2020-07-29T18:00:00Z",
  "end_datetime": "2020-07-29T18:30:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "JEWE93",
  "title": "Abstraction without Regret: A Cloud Knowledge Graph DB in Julia",
  "text": "Abstraction without Regret: A Cloud Knowledge Graph DB in Julia We present our use of Julia to build a next-generation knowledge graph database that combines reasoning and learning to solve problems that have historically been intractable. We motivate the need for a database that excels in supporting workloads that mix data management, machine learning, and graph analytics.  We explain how Julia's unique features enabled us to build a high-performance database with less time and effort.  We also discuss how we contribute to and leverage the Julia ecosystem. Since Google unveiled its knowledge graph in 2012 and Amazon released its product graph in 2018, enterprises have been building knowledge graphs to try to leverage their varied collections of big data for predictive analytics and AI projects. There are many roadblocks that stand in the way, including system complexity and development time, but also query performance and scalability issues. In this talk, we explain how a next-generation knowledge graph database -- built entirely in Julia -- is needed for modern machine learning, AI, and graph analysis.\r\n\r\nThis modern knowledge graph database demands combining innovations from the database and programming languages communities.\r\n\r\nWe meet these demanding requirements by relying on Julia's powerful features. We present an overview of our usage of Julia and highlight our experience, in particular: the ability to specialize abstractions to highly efficient code, modularity through multiple-dispatch, and composable multithreading.\r\n\r\nWe discuss key database innovations that we support with this, such as: incrementally maintained views, recursive queries, database extensibility, semantic query optimization, and worst-case optimal join algorithms.\r\n\r\nWe focus on:\r\n\r\nQuery compilation:  We show how Julia makes maintaining a query compiler easier compared to statically compiled languages. New data types can be introduced modularly. We show benchmarks of our Julia-based query compiler vs a state-of-the-art database system. \r\n\r\nEfficient Data structures:  We summarize how Julia is surprisingly suitable for low-level data structures with the excessive performance needs of databases. Before Julia, this prohibited the option of implementing database systems in high-level languages.  We share our productive experience implementing a state-of-the-art write-optimized data structure.  We show how we leverage Julia's bias and optimizations for immutable data structures.\r\n\r\nParallel Query Evaluation: We share experience introducing composable multithreading in our codebase with limited refactoring. We benchmark effectiveness on many-core cloud instances.\r\n\r\nFront-end Compiler:  Julia supports generic traversals over abstract syntax trees. Pattern matching supports concise and comprehensible expression of language semantics.\r\n\r\nSoftware development:  We share experience with building a 100K+ LOC system in a commercial team setting. We discuss guidelines we use to support such a project.",
  "url": "/talk/JEWE93",
  "index": 112,
  "speaker": "Molham Aref"
 },
 {
  "start_datetime": "2020-07-31T13:30:00Z",
  "end_datetime": "2020-07-31T13:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "ELXNUQ",
  "title": "Solving Practical Allotment Problems with Julia",
  "text": "Solving Practical Allotment Problems with Julia Allotting the best possible choice to each individual as per their preferences while adhering to total available positions and satisfying quality constraints is a common practical problem. Using Julia helped us get a tenfold speedup over our previous Python implementation. Allotting interviewers to candidates, teaching assistants to courses, and invigilators to exams are routine problems at our university. These types of problems are combinatorially hard to solve and consumed significant staff-hours for manually coming up with decent allotments. We model such allotment problems as a Bipartite graph matching and develop a stochastic optimization approach to obtain an approximate solution. We developed a computational approach requiring no manual effort, which offers better allotments than previous manual solutions. We initially implemented this in Python, which brought down the time required for obtaining an allotment to a couple of CPU-hours. By reimplementing the solver in Julia, we got a speedup of 13x over the Python implementation. In particular, we were surprised to find how fast Julia is for implementing iterative algorithms.",
  "url": "/talk/ELXNUQ",
  "index": 113,
  "speaker": "Saurabh Kumar"
 },
 {
  "start_datetime": "2020-07-31T13:10:00Z",
  "end_datetime": "2020-07-31T13:20:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "YYWMPR",
  "title": "No-overhead Game Development in Julia",
  "text": "No-overhead Game Development in Julia Game development is a great way to attract beginner programmers. However, they are often dissuaded by the accidental complexity. In this talk, I will show how to easily create a simple game without any framework overheads. Every child who starts programming wants to build games. Evidence of this can be seen in the popularity of block-based languages like Scratch. However, once they move to text-based languages (such as Julia), they struggle with the overheads of game development libraries, rather than being able to simply express their ideas in code. In this talk, I will demonstrate how to build simple games without the difficulties of low-level game-development frameworks, using GameZero.jl, a Julia library inspired by the Pygame Zero package. The talk will describe the library through the use of a series of examples that progressively build games from the simple to the more complicated.",
  "url": "/talk/YYWMPR",
  "index": 114,
  "speaker": "Ahan Sengupta"
 },
 {
  "start_datetime": "2020-07-29T13:40:00Z",
  "end_datetime": "2020-07-29T13:50:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "AKY8V7",
  "title": "EvoTrees for Flexible Gradient Boosting Trees",
  "text": "EvoTrees for Flexible Gradient Boosting Trees Introduction to Evotrees.jl, a package developed to provide a pure Julia implementation of Gradient Boosted Trees with performance competitive with reference C++ implementations. \r\nMain design choices and challenges encountered to achieve a performant solution will be covered. Discussion of the benefits stemming from developing in Julia, notably the ease to extend supported models such as quantile and Gaussian regression, as well as its MLJ ecosystem integration. ",
  "url": "/talk/AKY8V7",
  "index": 115,
  "speaker": "Jeremie Desgagne-Bouchard"
 },
 {
  "start_datetime": "2020-07-31T16:10:00Z",
  "end_datetime": "2020-07-31T16:40:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "B3VAGU",
  "title": "Auto-Optimization and Parallelism in DifferentialEquations.jl",
  "text": "Auto-Optimization and Parallelism in DifferentialEquations.jl You might not know all of the latest methods in differential equations, all of the best knobs to tweak, \r\n how to properly handle sparsity, or how to parallelize your code. Or you might just write bad code. Don't you wish someone would just fix that for you automatically? It turns out that the latest feature of DifferentialEquations.jl, autooptimize, can do just that. This talk is both a demo of this cool new feature and a description of how it was created for other package authors to copy. A general compiler can only have so much knowledge, but when we know that someone is solving a differential equation, there are a million things that we know. We know that different sizes of differential equations will do better/worse with different solver methods, we know that sparsity of the Jacobian will have a large impact on the speed of computation, we know that the user's `f` function describing the ODE can be considered independently from the rest of the program, and so on. In DifferentialEquations.jl, we have codified these ideas in order to build a toolchain that automatically optimizes a user's `f` function in order to spit out a more optimized DEProblem.\r\n\r\nThis works by first tracing to a symbolic sublanguage, ModelingToolkit.jl. By using tasks to time-out, we can try performing an auto-trace which, if successful, gives us a complete symbolic mathematical description of the user's numerical code. We can then proceed to symbolically analyze the function to generate the analytical solution to the user's Jacobian and even symbolically factorize the Jacobian, if doable in the allotted time. From the symbolic world we can then auto-parallelize the generated Julia code, chunking the output into tasks to multithread, or using a cost model determine that the ODE is large enough to automatically distribute (with auto-GPU coming soon).\r\n\r\nIf the system is not symbolically trace-able (there is a while loop depending on an input value, something that is quite uncommon), then we can resort to IR-based and adaptive analysis. We will demonstrate how SparsityDetection.jl can automatically identify the sparsity pattern of the Jacobian for a Julia code and then use SparseDiffTools.jl to accelerate the solve of stiff equations by performing a matrix coloring and optimizing the Jacobian construction for the problem. We will then discuss how DifferentialEquations.jl automatically picks the solver algorithm, defaulting to methods which can automatically switch between stiff and non-stiff integrators, determining stiffness on the fly with heuristics.\r\n\r\nTogether, we have demonstrated that these auto-optimizations can improve the code of even experienced Julia programmers by >100x by enabling sparsity coloring optimizations that they may not have known about, and by parallelizing code that is either difficult to parallelize or is simply automatically generated and thus hard to intervene with.",
  "url": "/talk/B3VAGU",
  "index": 116,
  "speaker": "Chris Rackauckas"
 },
 {
  "start_datetime": "2020-07-31T16:10:00Z",
  "end_datetime": "2020-07-31T17:40:00Z",
  "duration": 90,
  "location": "Track 3",
  "id": "LRRAGD",
  "title": "Poster Session 2",
  "text": "Poster Session 2 This is the second poster session - [\"Control and Automation Software for Chromatographic Processes\" by Tiago Santos](https://pretalx.com/juliacon2020/talk/YDCSNX)\r\n - [\"ContextLib - do you know where you are?\" by Tom Kwong](https://pretalx.com/juliacon2020/talk/G7XNXE)\r\n - [\"Julia for Structural Engineering\" by Henki Ashadi](https://pretalx.com/juliacon2020/talk/ZAGFAM)\r\n - [\"Steel Truss Design using Julia Programming Language\" by Rahma Latifa Dewi](https://pretalx.com/juliacon2020/talk/9JCCV8)\r\n - [\"A two way real time communication for mute and deaf people\" by Nafiz and Saiful Islam](https://pretalx.com/juliacon2020/talk/SEGNUF)\r\n - [\"How to not lose a mind by paralelizing a feedback loop?\" by Janis Erdmanis](https://pretalx.com/juliacon2020/talk/ENRJBB)\r\n - [\"Julia for cryptography, security and voting\" by Janis Erdmanis](https://pretalx.com/juliacon2020/talk/XXUJ9Y)\r\n - [\"Reproducible data science with the RENKU platform\" by Christine Choirat](https://pretalx.com/juliacon2020/talk/UHLCJR)\r\n - [\"Julia Code Generator for Flowgorithm Flow Chart Interpreter\" by Gajendra Deshpande](https://pretalx.com/juliacon2020/talk/AXTMXH)\r\n - [\"How Julia improves the ROI of analytics: A case study of Arthur\" by Eric Torkia and Egan Picken](https://pretalx.com/juliacon2020/talk/BP9HDJ)\r\n - [\"JLBoost.jl: Hackable XGBoost-like Gradient Boosting Tree Package\" by Dai ZJ](https://pretalx.com/juliacon2020/talk/3NWY7V)\r\n - [\"HierarchicalTemporalMemory.jl: a short delta from paper to code\" by Konstantinos Samaras-Tsakiris](https://pretalx.com/juliacon2020/talk/NXKNRM)\r\n - [\"A new Traits.jl: Easily dispatch on whatever you want\" by Stephan Sahm](https://pretalx.com/juliacon2020/talk/B3E8NM)\r\n - [\"Using Julia for User Interface Design\" by Erik Engheim](https://pretalx.com/juliacon2020/talk/CMRXD7)\r\n - [\"Decision Modeling and Simulation with MCHammer.jl\" by Eric Torkia](https://pretalx.com/juliacon2020/talk/NETNQZ)\r\n - [\"Implicit RK solver for high precision numerical integration\" by Mikel](https://pretalx.com/juliacon2020/talk/EZFAJE)\r\n - [\"Bayesian curve reconstruction from noisy streams in Julia\" by Marco Quartulli](https://pretalx.com/juliacon2020/talk/EM8ZK3)\r\n - [\"WaspNet.jl, a Julian Spiking Neural Network Simulator\" by Sam Buercklin](https://pretalx.com/juliacon2020/talk/9JFYBH)\r\n - [\"A Julia coding font\" by cormullion](https://pretalx.com/juliacon2020/talk/BYDSZK)\r\n - [\"Quantum Game Theory with Julia: A computational analysis\" by Indranil Ghosh](https://pretalx.com/juliacon2020/talk/NX33Q8)\r\n - [\"Exposing Julia to the frontend web developer via DanceJL\" by Chris \"Yoh\" Meyers](https://pretalx.com/juliacon2020/talk/VFKAA9)\r\n - [\"Computing on Encrypted Data with  Julia and Friends\" by David W. Archer](https://pretalx.com/juliacon2020/talk/CT9SUU)",
  "url": "/talk/LRRAGD",
  "index": 117,
  "speaker": "JuliaCon Committee"
 },
 {
  "start_datetime": "2020-07-29T16:10:00Z",
  "end_datetime": "2020-07-29T16:55:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "UD7AGC",
  "title": "Fancy Array Indexing",
  "text": "Fancy Array Indexing This is a BoF to talk about cool array types, such as:\r\n - AxisArrays\r\n - AxisRanges\r\n - IndexedDims\r\n - NamedDims\r\n - DimensionalData\r\n - JuMP's DenseAxisArray and SparseAxisArray\r\n - etc \r\n\r\nDo you have or love an array package with fancy indexing? Come chat about it.\r\nMaybe we will even be in a position to kill off some of them, and decide on a rightful successor to AxisArrays;\r\nor at least make a plan for what to decide in the next 12 months. ",
  "url": "/talk/UD7AGC",
  "index": 118,
  "speaker": "Lyndon White (@oxinabox)"
 },
 {
  "start_datetime": "2020-07-29T17:20:00Z",
  "end_datetime": "2020-07-29T17:30:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "CUMDLK",
  "title": "Whole-brain systems neuroscience with Julia",
  "text": "Whole-brain systems neuroscience with Julia We study the larval zebrafish, a vertebrate whose whole brain can be imaged during behavior. In this system, we can observe neural activity underlying computations in visual processing, decision making and adaptive motor control. To analyze terabyte-size imaging data and test a variety of hypotheses about the neural processes, we are using a Julia-based pipeline that takes full advantage of the parallelism, multiple dispatch and flexible package ecosystem of the language. For analysing imaging and behavioral data I am developing two packages: \r\n\r\nCalcium.jl - for extraction of lower-dimensional neuronal signals from dense, volumentric imaging data. It provides non-negative matrix factorization or local correlation-based methods as well as visualization, pre- and postprocessing tools. \r\n\r\nFishyfits.jl - defining interfaces and providing methods for simple models that can be fit and compared across behavioral data and neural activity, building on Julia's extensive model fitting and optimization toolkit. \r\n\r\nI will discuss some challanges on developing codebases that have to interoperate with Python pipelines, as Julia is not yet widespread in our lab or the wider neuroscience community.\r\n\r\nFinally, I will showcase [examples from our publications](https://github.com/portugueslab/Dragomir-et-al-2019-modelfit) on using Binder for sharing reproducible analyses.",
  "url": "/talk/CUMDLK",
  "index": 119,
  "speaker": "Vilim Štih"
 },
 {
  "start_datetime": "2020-07-29T18:30:00Z",
  "end_datetime": "2020-07-29T18:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "XKG7TT",
  "title": "`SymbolicTensors.jl` -- high-level tensor manipulation in Julia",
  "text": "`SymbolicTensors.jl` -- high-level tensor manipulation in Julia Learn how to speed up your tensor calculations with `SymbolicTensors.jl`, a package designed to manipulate and simplify your tensor expressions before rewriting them in performant pure Julia using `ITensors.jl`. Many numerical tensor manipulation packages exist (e.g. `Einsum.jl`), but treating tensors at a purely numeric level throws away a lot of potential optimizations.\r\nOften, it's possible to exploit the symmetries of a problem to dramatically reduce the calculation steps necessary, or perform some tensor contractions symbolically rather than numerically. \r\n\r\n`SymbolicTensors.jl` is designed to exploit these simplifications to generate more efficient input into numeric tensor packages than you would write by hand. It based on `SymPy.jl`, `sympy.tensor.tensor`, and `ITensors.jl`.",
  "url": "/talk/XKG7TT",
  "index": 120,
  "speaker": "Robert Rosati"
 },
 {
  "start_datetime": "2020-07-29T13:50:00Z",
  "end_datetime": "2020-07-29T14:00:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "N39HSX",
  "title": "Julia for scripting",
  "text": "Julia for scripting Julia is often not recommended for a \"scripting workflow\", i.e. starting Julia, execute a code snippet, and exit. This especially applies to short tasks where most of the time will be spent on compiling the code instead of running it. The recommended workflow is instead to keep the Julia session alive for as long as possible in order to benefit from already compiled methods. This talk will discuss how Julia can be used for scripting and, in particular, present some tips and tricks on how to redu The \"scripting workflow\", i.e. starting Julia, execute a code snippet, and then exit, is often not the recommended method for Julia code. One reason for this is that Julia is a just-in-time (JIT) compiled language, and the first call to a function is usually a lot slower than subsequent calls due to compilation. In a setting such as scripting there might only be one call to a function before exiting Julia. Spending time compiling the function might not be worth it in such a case, unless the faster runtime makes up for it. A simple example is a script that defines a single function, calls it, and then exits.\r\n\r\nThe recommended Julia workflow is instead to keep a single Julia session alive for as long as possible, and reuse it for multiple tasks. Even though two tasks A and B are not be directly related, they may both use, for example, arrays. Thus, after performing task A we have already compiled some array methods, and task B will benefit from that, with reduced compilation time as the result. This interaction is something that scripting can not take advantage of, since compiled methods are forgotten when exiting Julia.\r\n\r\nThe problems presented above have two obvious possible solutions: (i) spend less time compiling and (ii) store compiled methods and make them available in future sessions. For the first option we can use Julias interpreter and only compile whats necessary. This is often a great solution for very short-running tasks, and requires nothing extra, just some command line flags to Julia. The second option is a bit more involved (although nowadays pretty easy using the PackageCompiler.jl package), however, it can completely elimitate runtime compilation. The downside is that the compiled and cached methods live in a separate file that needs to be bundled with the script.\r\n\r\nThis talk will discuss how Julia can be used for scripting, present some tips and tricks on how to make scripting more viable, and show some succesful examples of the two solutions presented above.",
  "url": "/talk/N39HSX",
  "index": 121,
  "speaker": "Fredrik Ekre"
 },
 {
  "start_datetime": "2020-07-30T18:30:00Z",
  "end_datetime": "2020-07-30T19:00:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "HWZ38H",
  "title": "DynamicPPL: Stan-like Speed for Dynamic Probabilistic Models",
  "text": "DynamicPPL: Stan-like Speed for Dynamic Probabilistic Models We present DynamicPPL.jl, a modular library providing a lightning-fast infrastructure for probabilistic programming and Bayesian inference, used in Turing.jl. DynamicPPL enables Turing to have C/Stan-like speeds for Bayesian inference involving static and dynamic models alike. Beside run-time speed, DynamicPPL provides a user-friendly domain-specific language for defining and then querying probabilistic models. We present the preliminary high-level design and features of DynamicPPL.jl (https://github.com/TuringLang/DynamicPPL.jl), a modular library providing a lightning-fast infrastructure for probabilistic programming, used as a backend for Turing.jl (https://github.com/TuringLang/Turing.jl). Beside a computational performance that is often close to or better than Stan, DynamicPPL provides an intuitive domain-specific language (DSL) that allows the rapid development of complex dynamic probabilistic programs. Being entirely written in Julia, a high-level dynamic programming language for numerical computing, DynamicPPL inherits a rich set of features available through the Julia ecosystem. Since DynamicPPL is a modular, stand-alone library, any probabilistic programming system written in Julia, such as Turing.jl, can use DynamicPPL to specify models and trace their model parameters. The main features of DynamicPPL are: 1) a meta-programming based DSL for specifying dynamic models using an intuitive tilde-based notation; 2) a tracing data-structure for tracking random variables in dynamic probabilistic models; 3) a rich contextual dispatch system allowing tailored behaviour during model execution; and 4) a user-friendly syntax for probabilistic queries. Finally, we show in a variety of experiments that DynamicPPL, in combination with Turing.jl, achieves computational performance that is often close to or better than Stan.",
  "url": "/talk/HWZ38H",
  "index": 122,
  "speaker": "Mohamed Tarek"
 },
 {
  "start_datetime": "2020-07-30T18:00:00Z",
  "end_datetime": "2020-07-30T18:30:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "M98VVM",
  "title": "Solving Nonlinear Multi-Physics on GPU Supercomputers with Julia",
  "text": "Solving Nonlinear Multi-Physics on GPU Supercomputers with Julia We present a self-contained approach for the development of massively scalable multi-GPU solvers for coupled nonlinear systems of partial differential equations (PDEs) in Julia. The approach encompasses numerics, implementation and performance evaluation. We showcase several 2-D and 3-D Multi-GPU PDE solvers as, e.g., a solver for spontaneous nonlinear porous flow localization in 3-D which scales nearly ideally on thousands of GPUs. The widely applicable approach we present relies on the usage of a powerful **stencil-based iterative method** which enables to efficiently converge to the time-dependent implicit solution for strongly nonlinear problems. The method optimally suits both shared and distributed memory parallelism. \r\n\r\nThe **implementation approach** enables a straightforward development of a single Julia code that can be readily deployed on a single CPU thread or on thousands of GPUs/CPUs. We have instantiated the approach in the Julia packages `ParallelStencil` and `ImplicitGlobalGrid`. `ParallelStencil` empowers domain scientists to write architecture-agnostic high-level code for parallel high-performance stencil computations on GPUs and CPUs. `ParallelStencil` uses `CUDAnative` for computations on GPUs and `Base.Threads` for computations on CPUs. `ImplicitGlobalGrid` renders the distributed parallelization of stencil-based GPU and CPU applications on a regular (staggered) grid nearly trivial. `ImplicitGlobalGrid` relies on the Julia MPI wrapper, `MPI.jl`, to perform halo updates close to hardware limit and leverages CUDA-aware MPI for GPU applications. We have designed both `ParallelStencil` and `ImplicitGlobalGrid` for simplest possible usage by domain-scientists, rendering fast and interactive development of massively scalable high performance Multi-GPU applications readily accessible to them.\r\n\r\nWe conduct the **performance evaluation** with a simple metric for iterative PDE solvers. The metric measures effective memory throughput and is complementary to traditional metrics.\r\n\r\nWe demonstrate the broad applicability of our approach **showcasing multiple 2-D and 3-D Multi-GPU PDE solvers**, as, for instance, a solver for spontaneous nonlinear multi-physics porous flow localization in 3-D. As reference, we ported the latter solver from MPI+CUDA C to Julia and it achieves 95% of the performance of the original solver and a nearly ideal parallel efficiency on thousands of NVIDIA Tesla P100 GPUs on the Piz Daint supercomputer at the Swiss National Supercomputing Centre, CSCS. We evaluate the presented solvers' performance and scalability on Piz Daint. The majority of the presented solvers are being made publicly available as part of the documentation of the packages `ParallelStencil` and `ImplicitGlobalGrid`.\r\n\r\nCo-authors: Ludovic Räss¹ ², Grzegorz Kwasniewski¹, Benjamin Malvoisin³, Yury Podladchikov³\r\n\r\n¹ ETH Zurich | ² Stanford University | ³ University of Lausanne",
  "url": "/talk/M98VVM",
  "index": 123,
  "speaker": "Samuel Omlin"
 },
 {
  "start_datetime": "2020-07-29T19:00:00Z",
  "end_datetime": "2020-07-29T19:30:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "RRNYRW",
  "title": "On the State of Flux",
  "text": "On the State of Flux Machine Learning is more than large complex models, it is moving towards integrating existing domain knowledge to better inform learning processes. See how Flux expresses that problem in the modern machine learning paradigm. [Flux.jl](https://github.com/FluxML/Flux.jl) has been evolving with a host of improvements from the ground up. A major change from last year is that we have officially launched a stable release that uses [Zygote.jl](https://github.com/FluxML/Zygote.jl) as its AD package, opening up a lot more of the ecosystem to take advantage of it. We will show how well it plays with Julia’s existing state-of-the-art packages enabling more kinds of modelling than ever, and show how the community is taking advantage of it.\r\n\r\nWe will also showcase Flux’s new APIs and features that open up the awesome open-source community to express more complex ideas and bring domain skills into their ML stories. We will show how we’ve worked on improving performance through a myriad changes across the ecosystem, while keeping it easy to use as ever.\r\n\r\nWe would also discuss the design patterns that enable users to write elegant and performant Julian code that can best take advantage of the powerful automatic differentiation capabilities that we have built over time.",
  "url": "/talk/RRNYRW",
  "index": 124,
  "speaker": "Dhairya Gandhi"
 },
 {
  "start_datetime": "2020-07-31T12:40:00Z",
  "end_datetime": "2020-07-31T12:50:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "MMJXXC",
  "title": "Interrogating intratumor heterogeneity dynamics with Julia",
  "text": "Interrogating intratumor heterogeneity dynamics with Julia Julia is a great scientific computing language for interrogating ecological and evolutionary dynamics of intratumor heterogeneity and how it changes over time. This talk will appeal to people interested in studying Mathematical Biology and Ecology applications with Julia. Cancer research stipulates that more heterogenous tumor cell populations ultimately drive unfavorable outcomes for patients.  To study this question, we have developed software tools in Julia that harnesses evolutionary game theory methodologies like replicator-mutator dynamics and random walk model simulations through DifferentialEquations.jl and Distributions.jl along with data analysis pipelines for quantifying generalized diversity index (GDI) with DataFrames.jl and Query.jl.  These tools reveal quantitative insights into how GDI changes over time under evolutionary pressures. Julia has solved our two-language problem allowing us to interrogate temporal changes in intratumor heterogeneity by simulating different tumor ecological niches over time and quantifying those changes in diversity to help fight cancer. \r\n\r\nThis talk will present this biological application and discuss how existing Julia packages make this analytical work feasible. I will also highlight some areas of biological science research where there are gaps in Julia tooling relative to other data science ecosystems such as R and Scientific Python.",
  "url": "/talk/MMJXXC",
  "index": 125,
  "speaker": "Meghan Ferrall-Fairbanks"
 },
 {
  "start_datetime": "2020-07-29T16:55:00Z",
  "end_datetime": "2020-07-29T17:40:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "F7DKF8",
  "title": "Moving forward on diversity&inclusion in the Julia community",
  "text": "Moving forward on diversity&inclusion in the Julia community For the past few years JuliaCon has hosted yearly discussions on how to improve diversity and inclusion in the Julia community as well as conducted a survey on how users and developers in the community identify. Many excellent ideas emerged from these sessions, including creating accessible material and targeted outreach and recruitment. In this session we will review our diversity goals, then form affinity groups to accomplish those goals using inspiration from previous brainstorming sessions. ",
  "url": "/talk/F7DKF8",
  "index": 126,
  "speaker": "Huda Nassar, August Guang"
 },
 {
  "start_datetime": "2020-07-31T12:30:00Z",
  "end_datetime": "2020-07-31T13:00:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "79FJUW",
  "title": "Generic Manpower Simulation Engine: a SimJulia case study",
  "text": "Generic Manpower Simulation Engine: a SimJulia case study Proper HR management within an organisation is vital in the current day and age. Because of this task’s complexity, managers should be able to rely on good tools or models to support them, so they can gauge the short and long term impact of their decisions before making them. To this end, we developed a generalised manpower simulation engine in Julia, using SimJulia. We present this tool’s main features, highlight some of the encountered difficulties, and illustrate how it can be employed. Many studies have shown that proper human resource management is vital to the success of any organisation. This means that managers need to balance the needs of the organisation with the needs of their employees, and are required to make well-informed planning decisions. One part of the problem covers short term planning, such as setting up employee rosters to ensure an appropriate distribution of the workload over the employees. The other part deals with long term manpower planning, and usually concerns hiring and promotion policies to meet the organisation’s goals without alienating its employees. Naturally, any of the planning decisions have to be made within a certain legal framework that the organisation cannot influence.\r\nAs such, such decisions are too important to be left to the manager’s \"gut feeling\". Instead, they can rely on a variety of mathematical models to provide invaluable insights to allow them to make the appropriate decisions. These models can be of various types: Markov models, optimisation models using mathematical programming, stochastic simulation models, or system dynamics models, each with their own benefits and drawbacks.\r\nIn particular, we have chosen to develop a tool, the Generic Manpower Simulation Engine (GMSE), based on stochastic simulation, as an organisation’s internal structure and policies are often too complex and varied to be able to estimate all the effects of a particular change. Instead, our tool allows the user to define the structure of the organisation and its policies, entering only the direct effect these policies have on the personnel members of that organisation. Once the system is configured, the user can then run the simulation for the period of interest, and request reports on the state of the organisation at any time point covered by the simulation. This allows the user to get a prediction of the full impact of specific proposed policy changes, among other applications.\r\nThe GMSE is developed entirely in Julia with the SimJulia library at its core, and provides all the necessary methods to fully configure a manpower simulation from within Julia for the expert user, as well as a way to configure one from MS Excel.\r\nIn addition to giving an overview of the GMSE, we will show how we use the SimJulia library, and we illustrate some of the challenges we faced, and how we decided to handle those challenges. Finally, we give a quick overview of how we can use the GMSE to optimise the organisation’s policies.",
  "url": "/talk/79FJUW",
  "index": 127,
  "speaker": "Johan Van Kerckhoven"
 },
 {
  "start_datetime": "2020-07-30T12:50:00Z",
  "end_datetime": "2020-07-30T13:00:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "GDCEYU",
  "title": "Handling large geospatial raster data with the Earth System Data",
  "text": "Handling large geospatial raster data with the Earth System Data Currently, satellites generate data of the Earth in an unprecedented\r\namount.\r\nThese datasets need to be processed in a fast and user friendly way to\r\nderive comprehensive information. This talk shows how we use  the\r\n[Earth System Data\r\nLab](https://github.com/esa-esdl/ESDL.jl) to handle Sentinel-1 time\r\nseries for the detection of deforestation. The EarthSystemDataLab.jl allows you to handle geospatial raster data\r\neasily and fast. You can load  data which is too large for your RAM\r\ndirectly from disk in small enough chunks so that it can be\r\nparalllelized without you thinking too much about it.\r\nThe EarthSystemDataLab establishs a data cube workflow, where low-\r\ndimensional functions are applied  to higher dimensional cubes by\r\nfunctional extension. This means, that user defined functions can act\r\nalong a particular subset of the input dimensions and loop then across\r\nall other input dimensions to get a new data cube which has the\r\nunspecified dimensions as well as the output dimensions of the user\r\ndefined function.\r\nWe are going to show how we used the EarthSystemDataLab.jl package for\r\nthe time series analysis of Sentinel-1 data.",
  "url": "/talk/GDCEYU",
  "index": 128,
  "speaker": "Felix Cremer"
 },
 {
  "start_datetime": "2020-07-29T16:30:00Z",
  "end_datetime": "2020-07-29T16:40:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "LQLP9P",
  "title": "Convex.jl: where are we and where do we want to go?",
  "text": "Convex.jl: where are we and where do we want to go? We will show off some new features in Convex.jl, solve a few example problems, and discuss development plans for the future. Convex.jl is a modelling language for solving convex optimization problems. This is a class of problem that, when modelled correctly, can be efficiently and accurately solved to global optimality. Convex.jl provides a simple and convenient modelling language that transforms user-entered problems into a structured form which, via the intermediary layer MathOptInterface.jl, is passed to solvers which can then exploit the structure to efficiently solve the problem.\r\n\r\nWe will discuss Convex.jl’s recent update from using the deprecated MathProgBase as an intermediary layer to instead using the actively developed MathOptInterface (which also powers JuMP). Among other things, this enables Convex.jl to formulate problems specified using generic numeric types and send problems to high-precision solvers in order to accurately calculate optimal values of optimization problems to many decimal places. We will also see how to build domain-specific abstractions on top of Convex.jl to provide convenient interfaces for formulating problems in field-specific contexts by using custom variable types and a new feature that allows variables to carry around their own constraints.\r\n\r\nWe will also see some new tooling: a library of end-to-end tests for MathOptInterface-compatible optimization solvers, and infrastructure to run the tests in parallel on GitHub Actions and display the results on a convenient webpage. \r\n\r\nLastly, we will discuss plans for Convex.jl’s next steps, to make it more efficient and even easier to extend, and invite the audience to help build that future.",
  "url": "/talk/LQLP9P",
  "index": 129,
  "speaker": "Eric P. Hanson"
 },
 {
  "start_datetime": "2020-07-31T13:10:00Z",
  "end_datetime": "2020-07-31T13:20:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "V3QDAM",
  "title": "Crash Course in Energy Systems Modeling and Analysis with Julia",
  "text": "Crash Course in Energy Systems Modeling and Analysis with Julia Do you want to customize an energy systems market model? Do you have trouble parsing data from various tools? Do you want to interactively explore your model results? This 0-60 crash course will get you up and going on energy systems modeling and analysis with Julia using **PowerSystems.jl**, **PowerSimulations.jl**, **PowerModels.jl**, and **PowerGraphics.jl**. Researchers at the U.S. National Renewable Energy Laboratory (NREL) have developed a new suite of infrastructure modeling capabilities to understand emerging energy systems operations and planning challenges. This talk will introduce the power systems modeling and analysis capabilities enabled by NREL researchers. Basic overviews of the following packages and associated capabilities will be presented:\r\n - **PowerSystems.jl:** Power system data specification, parsing, and analysis.\r\n - **PowerSimulations.jl:** Optimal power system scheduling, production cost modeling, and quasi-static system simulation.\r\n - **PowerGraphics.jl:** Visualization and analysis of power systems simulation results.",
  "url": "/talk/V3QDAM",
  "index": 130,
  "speaker": "Dheepak Krishnamurthy, Clayton Barrows"
 },
 {
  "start_datetime": "2020-07-29T17:30:00Z",
  "end_datetime": "2020-07-29T17:40:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "7MYVV3",
  "title": "Computational tools for designing modular biosystems",
  "text": "Computational tools for designing modular biosystems Living systems, from molecules to ecosystems, are modular, allowing us to engineer them. I develop computational tools to aid bioscience engineering with applications in health, ecology and engineering. The whole chain of modeling, knowledge and decision relies on methods from machine learning, bioinformatics and optimization. Julia has proven to be a useful language for these tasks. In this talk, I will outline how I use Julia for my research through a series of case studies. Biological systems are intrinsically modular: proteins contain functional units, pathways are formed by linking enzymatic steps and, at the highest level, different species form a functional ecosystem. This property allows for engineering those biosystems, from designing new proteins and pathways to selecting organisms to optimize ecosystem function. In our work, we combine tools from machine learning, optimization and bioinformatics to create novel biological entities. We found Julia an excellent language that allows us to rapidly explore ideas while still maintaining computational efficiency. In this talk, we will discuss some case studies, including selecting optimal bacterial co-cultures for BAM demineralization and the design of enzybiotic proteins using Bayesian optimization.",
  "url": "/talk/7MYVV3",
  "index": 131,
  "speaker": "Michiel Stock"
 },
 {
  "start_datetime": "2020-07-29T18:40:00Z",
  "end_datetime": "2020-07-29T18:50:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "3NXGGJ",
  "title": "MPI.jl: Julia meets classic HPC",
  "text": "MPI.jl: Julia meets classic HPC The MPI.jl package provides a standard Julia interface for working with the Message Passing Interface (MPI). In this talk I will introduce the package and illustrate its use with some examples, describe some of the unique challenges it faces, and detail plans for the future to make it easier to use. Over 25 years old, MPI is the stalwart of high-performance computing, supported on everything from single machines to billion-dollar supercomputers. Despite its age, it supports several different modes of communication, and lots of engineering effort goes into optimizing bandwidth and reducing latency. However its use with a dynamic language such as Julia presents certain challenges.\r\n\r\nI’ll start with some simple examples on how its single program, multiple data (SPMD) programming model can be used with Julia. Then I will discuss some implementation details, and highlight some of the unique challenges in supporting this package, from a lack of a standardised application binary interface (ABI), supporting optional CUDA-aware interfaces, and working with specific Julia features, like custom data types and reduction operators. Finally, I’ll describe some additional features and future plans to improve the usability of this venerable library.",
  "url": "/talk/3NXGGJ",
  "index": 132,
  "speaker": "Simon Byrne"
 },
 {
  "start_datetime": "2020-07-30T16:10:00Z",
  "end_datetime": "2020-07-30T16:55:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "N9RVPR",
  "title": "Number Theory and Computer Algebra in Julia",
  "text": "Number Theory and Computer Algebra in Julia We will review existing packages, discuss what new packages could be written, and look at existing C/C++ libraries that we might provide Julia wrappers for. To start, Bill Hart, author of Nemo.jl, AbstractAlgebra.jl Hecke.jl and other computer algebra packages will review his packages and discuss what further steps he and his collaborators plan to make.  We will discuss other computer algebra and number theory packages. Then we'll discuss topics such as:\r\n\r\n* What's missing? Is there important functionality which just don't exist in Julia? \r\n* Which packages do/do not allow composable computation? \r\n* Could the `MatrixSpace` type from AbstractAlgebra.jl be replaced with `AbstractArray`?   Why or why not?\r\n* Is there any interest in participating in wrapping the C++ libraries [NTL](https://www.shoup.net/ntl/) or [fplll](https://github.com/fplll/fplll)?  Or other libraries?",
  "url": "/talk/N9RVPR",
  "index": 133,
  "speaker": "Chris Peel"
 },
 {
  "start_datetime": "2020-07-31T19:00:00Z",
  "end_datetime": "2020-07-31T19:10:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "7XARPV",
  "title": "Makie.jl",
  "text": "Makie.jl All the news about Makie! WebGL, layouts, widgets, recipes and more! ",
  "url": "/talk/7XARPV",
  "index": 134,
  "speaker": "Simon Danisch"
 },
 {
  "start_datetime": "2020-07-29T18:50:00Z",
  "end_datetime": "2020-07-29T19:00:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "JHCWQA",
  "title": "Effectively Using GR",
  "text": "Effectively Using GR GR is a plotting package for creating two- and three-dimensional graphics in Julia that provides basic MATLAB-like plotting functions for visualizing static or dynamic data. In this talk, the most important new features are presented, such as a new meta layer that allows the integration of GR in browser environments and GUI toolkits, or improved output functions for drawing paths and texts to make publication-quality plots. GR is a plotting package for the creation of two- and three-dimensional graphics in Julia and other languages, offering basic MATLAB-like plotting functions to visualize static or dynamic data with minimal overhead. GR is now available for all major platforms and can be easily installed with pre-built binary packages.\r\n\r\nUsing quick practical examples, this talk is going to present the important improvements and features provided by the GR framework for high-performance graphics, in particular when being used for publication-quality Plots in interactive notebooks (Jupyter), development environments (Atom) or terminal programs (iTerm2). One of the often requested innovations in the current GR version is the integrated renderer for scientific formulas in LaTeX format.\r\n\r\nThe presentation also introduces a new meta layer, which provides an interface to interactive backends based on Qt5 or JavaScript. In this context, the improvements in the structure of the GR framework are presented with respect to a more efficient integration into existing plot environments (such as Plots.jl).",
  "url": "/talk/JHCWQA",
  "index": 135,
  "speaker": "Josef Heinen"
 },
 {
  "start_datetime": "2020-07-30T19:20:00Z",
  "end_datetime": "2020-07-30T19:30:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "3ZTCWX",
  "title": "Easy and fast desktop GUIs with QML",
  "text": "Easy and fast desktop GUIs with QML Qt QML is a declarative, javascript-based language to describe graphical user interfaces (GUIs) for desktop and mobile platforms. With the [QML.jl](https://github.com/barche/QML.jl) package it is possible to also use this to create user interfaces for Julia programs, on Linux, Mac and Windows. From a user perspective, the connection between Julia and QML works by exposing Julia functions to be called from QML and/or by using [Observables](https://github.com/JuliaGizmos/Observables.jl) that can be updated and monitored both from QML and Julia. Aside from these standard mechanism, the package also exposes some Julia-specific functionality, such as an [`AbstractDisplay`](https://docs.julialang.org/en/latest/base/io-network/#Multimedia-I/O-1) implementation and integration with [GR.jl](https://github.com/jheinen/GR.jl) and [Makie.jl](https://github.com/JuliaPlots/Makie.jl).\r\n\r\nThe presentation will start off with a description of the Observables integration (new since the 2017 talk about this package) and then discuss more in detail how to combine different elements in Julia and QML to obtain interactive GR and Makie visualizations in a QML window.\r\n\r\nWe will finish with a note on GUI styling and themes, showing how to configure a GUI for either an identical look across platforms, or for integration with the desktop look and feel.",
  "url": "/talk/3ZTCWX",
  "index": 136,
  "speaker": "Bart Janssens"
 },
 {
  "start_datetime": "2020-07-31T16:40:00Z",
  "end_datetime": "2020-07-31T17:10:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "QABEK8",
  "title": "ChainRules.jl",
  "text": "ChainRules.jl The ChainRules project allows package authors to write rules for custom sensitivities (sometimes called custom adjoints) in a way that is not dependent on any particular autodiff (AD) package.\r\nIt allows authors of AD packages to access a wealth of prewritten custom sensitivities, saving them the effort of writing them all out themselves.\r\nChainRules is the successor to DiffRules.jl and is the native rule system currently used by ForwardDiff2, and soon Zygote and Nabla. A perhaps counterintuitive requirement for differentiable programming is easy hand-coded rules for determining derivatives. You might think: “I thought the whole point of differentiable programming was to use AD, so I didn’t have to write all these derivatives by hand.”. Indeed you don’t have to, but that doesn’t mean you shouldn't be allowed to, and it doesn’t mean you can't get advantages out of doing do. Custom sensitivities allow programmers to insert domain knowledge that no autodiff system could ever figure out. Further custom rules, let you work around any bugs in the AD system, and fix performance issues.\r\nSo being able to write custom rules is important, and doing it once for every AD system is win on deduplicating effort.\r\n\r\nA secondary advantage of ChainRules is that it provides a set of differential types to be used by AD systems. The differential types provided by ChainRules are very expressive, more expressive in-fact than is required for any current AD system. These types allow ChainRules to act as a lingua franca between AD systems. If it is advantageous because of some properties of your system to AD one part with ForwardDiff2 (via forward-mode), another part with Zygote (via source code transformation reverse mode) and another via Nabla (via overloading tape-based reverse mode) then you can; and each part can understand the derivative types returned by the other.\r\n\r\nThe ChainRules project has 3 packages:\r\n - ChainRulesCore.jl: the minimum stuff required to implement custom rules for your package. Think of it like RecipesBase for Plots.jl. It should be used by all packages wanting to support rules.\r\n - ChainRules.jl: a repository of rules for functions defined in Base and the Standard Libraries. This was separated out from ChainRulesCore to minimize load time. It should be used by AD packages wanting to consume rules.\r\n - ChainRulesTestUtils.jl: robust testing utilities based on finite differencing. Its a test-time dependency for packages defining rules.\r\n\r\n\r\nThis talk will cover:\r\n - An introduction to AD, including terminology such as pullback, custom sensitivity etc.\r\n - The details the use and design of the ChainRules packages\r\n - An explanation of some of the open questions in autodiff and our resolutions to them including: natural vs structural derivatives, mutating reverse-mode AD, chunked AD / change of basis, one-to-one vs many-to-many relationships between differential and primal types.",
  "url": "/talk/QABEK8",
  "index": 137,
  "speaker": "Lyndon White (@oxinabox)"
 },
 {
  "start_datetime": "2020-07-30T18:00:00Z",
  "end_datetime": "2020-07-30T18:30:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "ELQ8A8",
  "title": "StatsModels.jl: Mistakes were made/A `@formula` for success",
  "text": "StatsModels.jl: Mistakes were made/A `@formula` for success What happens when you re-implement a critical piece of the data science\r\necosystem from what was essentially an R clone to take full advantage of the\r\nJulia language?  You learn a lot about flexibility, composability, and\r\nperformance. Transforming tabular, heterogeneous data into numerical arrays is a critical\r\nfirst step in many data analysis pipelines.  [StatsModels.jl](https://github.com/JuliaStats/StatsModels.jl) provides\r\nfunctionality for this through the `@formula` macro.\r\n\r\nThe earliest implementations of `@formula` in Julia were based on R, which has a\r\nvery different model for metaprogramming and composition across packages.  Over\r\nthe last two years, we re-implemented the `@formula` from the ground up in a\r\nmore Julian fashion, trying to strike a balance between maintaining a\r\ncontinuous, familiar experience for front-end users while also taking advantage\r\nof Julia's many features to create a hackable, flexible, modular, and extensible\r\nplatform that other packages can build on.\r\n\r\nIn this talk, I'll show you how the current implementation achieves these goals,\r\nbut more importantly what we *learned* in the process of rewriting this critical\r\npiece of data science infrastructure.  I'll pay special attention to mistakes we\r\nmade in initial development, lessons we learned from those mistakes about how to\r\nmake a flexible, composable package, and issues for current and future\r\ndevelopment.  You'll learn how [StatsModels.jl](https://github.com/JuliaStats/StatsModels.jl) takes advantage of multiple\r\ndispatch to allow *other* packages to hook into and extend the `@formula` system\r\nwhile still playing nicely together.",
  "url": "/talk/ELQ8A8",
  "index": 138,
  "speaker": "Dave Kleinschmidt"
 },
 {
  "start_datetime": "2020-07-30T16:50:00Z",
  "end_datetime": "2020-07-30T17:35:00Z",
  "duration": 45,
  "location": "BoF",
  "id": "8NDYCT",
  "title": "Julia For Quantum Physics",
  "text": "Julia For Quantum Physics Chat about Yao, ITensor, TensorOperations, OMEinsum and development on common infrastructure such as lattices, sparse tensor, domain specific automatic differentiation etc. in Quantum Physics. # JuliaCon 2020 Quantum BoF Materials\r\nMaterials for Quantum BOF in JuliaCon 2020\r\n\r\n## Abstract\r\n\r\nChat about [Yao](http://yaoquantum.org/), [ITensor](https://github.com/ITensor/ITensors.jl), [TensorOperations](https://github.com/Jutho/TensorOperations.jl), [OMEinsum](https://github.com/under-Peter/OMEinsum.jl) and development on common infrastructure such as lattices, sparse tensor, domain specific automatic differentiation etc. in Quantum Physics.\r\n\r\n## Description\r\n\r\nTopics to discuss:\r\n\r\n- A Julian lattice package\r\n- Status of Julia library support for specialized tensor operation backends\r\n  * CuTensor support in CuArrays\r\n  * Support for TBLIS, GETT and similar?\r\n  * Algorithms people want (TDVP, TEBD, tDMRG, any four letter acronym like this)\r\n- Domain specific automatic differentiation (AD)\r\n  * AD through SVD in Julia libraries such as Zygote\r\n- GPU stuff\r\n  * multi GPU parallelism\r\n  * exploiting mixed precision for some quantum libraries\r\n- Tutorial writing\r\n- Julia quantum as a teaching tool - interactive graph demos?\r\n- Benchmarking within the Julia community and compared to other packages\r\n\r\nSee https://github.com/Roger-luo/juliacon-quantum-bof  for details",
  "url": "/talk/8NDYCT",
  "index": 139,
  "speaker": "Roger Luo, Katharine Hyatt, Matthew Fishman, JinGuo Liu, Matthew Fishman"
 },
 {
  "start_datetime": "2020-07-30T12:50:00Z",
  "end_datetime": "2020-07-30T13:00:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "E98QKR",
  "title": "Comparative study of parallelism in Julia and an HPC environment",
  "text": "Comparative study of parallelism in Julia and an HPC environment We will present a comparative play-by-play walkthrough of how we parallelised a personalised learning object recommender system intended for students based on their performance and individual aptitudes using a computational and Deep Learning model. We show how we leveraged modern Julia constructs and prepared the experiment for both a traditional cluster and a High-Performance Computing (HPC) infrastructure. This talk will provide an in-depth analysis of constructs in Julia to support program parallelism and contrast them with two tools used in high-performance computing (HPC) environments (MPI and OpenMP). First, we present the constructs introduced by Julia to support program parallelism both on a simple computer and on a traditional cluster. Then, we discuss how these constructs can be extended to cope with a software stack in an HPC. Our analysis will focus on both the architectural perspective as well as performance. Throughout our presentation, we will use the case of personalised learning object recommender system intended for students based on their performance and individual aptitudes using a computational and Deep Learning model. We will discuss the challenges for parallelising the recommender system and how we  leveraged modern Julia constructs and prepared the experiment for both a traditional cluster and a High-Performance Computing (HPC) infrastructure.\r\n\r\nThe presentation will be based on practical implementation and experience.",
  "url": "/talk/E98QKR",
  "index": 140,
  "speaker": "Samuel Kapembe"
 },
 {
  "start_datetime": "2020-07-29T19:00:00Z",
  "end_datetime": "2020-07-29T19:30:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "LEADQ7",
  "title": "Accurate and Efficiently Vectorized Sums and Dot Products",
  "text": "Accurate and Efficiently Vectorized Sums and Dot Products This talk will present how basic operations on vectors, like summation and dot products, can be made more accurate with respect to Floating-Point arithmetic by using compensated algorithms. The proposed implementation is available in the [AccurateArithmetic.jl](https://github.com/JuliaMath/AccurateArithmetic.jl) package, and leverages SIMD instructions in order to achieve high performance on modern hardware architectures. Computing the dot product of two vectors and, perhaps to a lesser extent, summing the elements of a vector, are two very common basic building blocks for more complex linear algebra algorithms. As such, any change in their performance is likely to affect the overall performance of scientific computing codes; any change in their accuracy is likely to induce a loss of reproducibility in overall computed results. However, both the performance and accuracy of these algorithms is affected by the use of Floating-Point (FP) arithmetic: on the one hand, using smaller FP numbers tends to increase the performance of the computation (through increased memory bandwidth and wider SIMD registers). On the other hand, decreasing the precision of FP numbers also tends to decrease the accuracy if the results.\r\n\r\nThe work presented in this talk tries to address this issue by efficiently implementing [accurate summation and dot product algorithms in Julia](https://hal.archives-ouvertes.fr/hal-02265534). These implementations are available under an open source license in the [AccurateArithmetic.jl](https://github.com/JuliaMath/AccurateArithmetic.jl) package, and aim at high performance by leveraging the SIMD capabilities of modern hardware (esp. AVX-2 & AVX-512). Besides naive algorithms, compensated algorithms are implemented: the Kahan-Babuška-Neumaier summation algorithm, and the [Ogita-Rump-Oishi](http://dx.doi.org/10.1137/030601818) simply compensated summation and dot product algorithms. These algorithms effectively double the working precision, producing much more accurate results while incurring little to no overhead, especially for large input vectors.\r\n\r\nThis talk also tries to build upon this example to make a case for a more widespread use of Julia in the HPC community. Although the vectorization of compensated algorithms is no particularly simple task, Julia makes it relatively easy and straightforward, particularly thanks to existing building blocks in the eco-system such as [SIMDPirates.jl](https://github.com/chriselrod/SIMDPirates.jl). Relying on generic functions and multiple dispatch also allows structuring the code in small, composable building blocks, closely matching textbook algorithms yet efficiently compiled.",
  "url": "/talk/LEADQ7",
  "index": 141,
  "speaker": "François Févotte, Chris Elrod"
 },
 {
  "start_datetime": "2020-07-29T18:20:00Z",
  "end_datetime": "2020-07-29T18:30:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "MR9QWA",
  "title": "Exploring Disease Vector Dynamics Under Environmental Change",
  "text": "Exploring Disease Vector Dynamics Under Environmental Change As climate change alters the distribution of disease vectors, the prevention of mosquito-borne illnesses like dengue and malaria stand to be complicated by shifting ecological realities. I use DifferentialEquations.jl to gain insights about the population dynamics of disease vectors that are subjected to environmental variation. Improved knowledge of mosquito population dynamics can help control the spread of the diseases they carry. However, the interactions that inform such dynamics are complex. Computational models furnish an effective means for scientists to probe the environmental sensitivities of disease vectors.\r\n\r\nI use DifferentialEquations.jl to develop a metapopulation model parameterized with empirical data, with which I explore the effect of various environmental scenarios on the population dynamics of malarial mosquitos. I briefly distill the entomological and public health implications of my results, and then explicate my approach to applying the DifferentialEquations.jl platform to this scientific question.",
  "url": "/talk/MR9QWA",
  "index": 142,
  "speaker": "Valeri Vasquez"
 },
 {
  "start_datetime": "2020-07-30T17:20:00Z",
  "end_datetime": "2020-07-30T17:30:00Z",
  "duration": 10,
  "location": "Track 2",
  "id": "MGJCGT",
  "title": "Computation Techniques for Encrypted Data",
  "text": "Computation Techniques for Encrypted Data The session begins with a discussion on homomorphic properties of cryptographic algorithms with the demonstration and techniques to reduce computational complexity. The session discusses the concept of recryption for secure computation. This session also discusses a case study on how machine learning techniques can be applied to encrypted data for secure computation and protecting the machine learning model. Finally, the utility of homomorphic encryption for blockchain will be discussed. Imagine you have important documents such as credit card statements of expenditure or other financial documents and you want to protect them from illegal entities. You will store them in safe and lock it with a key. This process is known as encryption. Now if you want to analyze your spending habits or process financial accounts related to your business then you need to take the documents out of safe. This process is known as decryption. This step has a problem i.e.; the moment you take out the documents from the safe they become vulnerable to illegal entities. To avoid such situations, we need a mechanism to process documents without taking them out of the safe. It is possible through homomorphic encryption i.e., by performing computations on encrypted data and this talks addresses techniques to perform computations of encrypted data.<br/>\r\n<br/>\r\nImplementation:<br/>\r\nThe cryptographic algorithms have been implemented in Julia. Also, the Julia code has been written\r\nto verify the homomorphic properties of cryptographic algorithms. Homomorphic encryption techniques are computation intensive. To reduce the number of computations we used the Fast Fourier Transform (FFT) and Karatsuba methods for performing arbitrary computations such as multiplication over large integers. Next to demonstrate the implementation of a secure machine learning model we combined cryptography algorithms implementation in Julia and machine learning toolbox (MLJ.jl). A minimal blockchain was implemented in Julia to perform secure computations in a blockchain environment.<br/><br/>\r\nOutline<br/>\r\n1.Introduction to cryptography and homomorphic encryption(02 Minutes)<br/>\r\n2.Introduction to the Internet of Things and problems of homomorphic encryption(03 Minutes)<br/>\r\n3.Techniques to reduce the complexity of computations on encrypted data(04 Minutes)<br/>\r\n4.Recryption for secure computation(04 Minutes)<br/>\r\n5.Homomorphic encryption and Machine Learning(04 Minutes)<br/>\r\n6.Homomorphic encryption and Blockchain(04 Minutes)<br/>\r\n7.Conclusion and Questions(04 Minutes)<br/>",
  "url": "/talk/MGJCGT",
  "index": 143,
  "speaker": "Gajendra Deshpande"
 },
 {
  "start_datetime": "2020-07-30T12:40:00Z",
  "end_datetime": "2020-07-30T12:50:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "GR9TZH",
  "title": "GeoInterface: bringing geospatial packages together",
  "text": "GeoInterface: bringing geospatial packages together The GeoInterface, a package for interoperability of geospatial geometries, has been completely redesigned. Formerly it forced geometries to subtype abstract interface types. Now it is much more flexible, allowing packages to hook in using traits, and support methods based on the Simple Features standard. This talk will show why this is important for the JuliaGeo ecosystem, and what it enables you to do. In the Julia documentation, the [example of `Point{T}`](https://docs.julialang.org/en/v1.3/manual/types/#Parametric-Composite-Types-1) is used to introduce parametric types. It is easy to implement your own point type, and many packages have done so. For users, having to convert their points from package A to package B can be bothersome. Besides points, the same applies to other geometries such as lines and polygons, which are commonly used in geospatial workflows. Just agreeing on a single set of types for all uses is unlikely, since the diversity stems from different needs. Some may want to match a particular file format, or wrap pointers through a C API, such as GDAL.\r\n\r\nHence, to embrace the diversity and allow smooth workflows involving different geometry representations, we redesigned [GeoInterface.jl](https://github.com/JuliaGeo/GeoInterfaceRFC.jl). It allows you to efficiently convert between any sets of types that implement the interface, without having to know about or depend on the other package. The redesign incorporates many ideas from the Simple Features standard, and was inspired by the success of the [Tables.jl](https://github.com/JuliaData/Tables.jl) interface. Interestingly, we can show examples how these two interfaces can complement each other for tabular data with geometry columns, as seen in [Shapefile.jl](https://github.com/JuliaGeo/Shapefile.jl) and [GeoJSONTables.jl](https://github.com/visr/GeoJSONTables.jl).",
  "url": "/talk/GR9TZH",
  "index": 144,
  "speaker": "Martijn Visser"
 },
 {
  "start_datetime": "2020-07-30T19:10:00Z",
  "end_datetime": "2020-07-30T19:20:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "9RX99T",
  "title": "Bijectors.jl: Transforming probability distributions in Julia",
  "text": "Bijectors.jl: Transforming probability distributions in Julia Transforming one probability distribution to another is a powerful tool in Bayesian inference and machine learning, e.g. constrained-to-unconstrained transformations of distributions for use in Hamiltonian Monte Carlo or constructing flexible and learnable densities such as normalizing flows.\r\n\r\nIn this talk we'll have a look at how we can use Bijectors.jl to do all of the above and more! ",
  "url": "/talk/9RX99T",
  "index": 145,
  "speaker": "Tor Erlend Fjelde"
 },
 {
  "start_datetime": "2020-07-29T19:00:00Z",
  "end_datetime": "2020-07-29T19:30:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "X8LY73",
  "title": "DFTK: A Julian approach for simulating electrons in solids",
  "text": "DFTK: A Julian approach for simulating electrons in solids Density-functional theory (DFT) is a widespread method for simulating the quantum-chemical behaviour of electrons in matter. This talk presents our package DFTK, which aims to provide a joint platform accessible to different scientific communities. The quantum-chemical simulation of electronic structures is an established approach in materials reseach. The desire to tackle even bigger systems and more involved materials, however, keeps posing challenges with respect to physical models, reliablity and performance of methods such as DFT. With DFTK (https://dftk.org) we provide a Julia package for DFT, which aims to be fast enough for practical calculations, but also flexible to support toy problems for mathematical development in the field.",
  "url": "/talk/X8LY73",
  "index": 146,
  "speaker": "Michael Herbst"
 },
 {
  "start_datetime": "2020-07-31T13:40:00Z",
  "end_datetime": "2020-07-31T13:50:00Z",
  "duration": 10,
  "location": "Track 1",
  "id": "Z3RDBQ",
  "title": "Developing an exercise-based Julia curriculum",
  "text": "Developing an exercise-based Julia curriculum We will share our learnings from creating a Julia curriculum on Exercism that teaches Julia to users with previous programming experience based on practice exercises, automated as well as community-sourced and individual human mentoring. Further we will share how Julia users teaching workshops or classes can benefit from our project, and why we think that Exercism benefits the community as a whole. To motivate the development of the new version and curriculum of the Exercism Julia Track (referred to as v3 from now on), we will briefly outline the history of Exercism, and the major problems of previous versions, mainly large amounts of repeated work by mentors and a lack of structured progression through concepts that the student needs to learn when learning Julia. The human interaction and mentoring is the core of Exercism, and the v3 curriculum is built around making these interactions as meaningful as possible.\r\n\r\nDuring the development of v3, we first identified concepts that make Julia unique and that users must know in order to reach “fluency” in the language. Then, we built bite-sized concept exercises that teach these concepts, ideally isolated from other concepts. These will be mentored automatically based on a normalization of the solution and community-sourced feedback. Solving these exercises unlocks practice exercises that can be used to deepen learned concepts and allow many different approaches whose merits can be discussed with a human mentor.\r\n\r\nWhile there are many great resources for learning Julia, information on how to create such resources is scarce. By sharing our experiences, challenges and learnings from creating v3, we hope to encourage others to create learning resources and share our approach to creating one. Additionally, we believe that the tooling, primarily the normalization of solutions, and the exercise pool can be of use to others teaching Julia.",
  "url": "/talk/Z3RDBQ",
  "index": 147,
  "speaker": "Sascha Mann"
 },
 {
  "start_datetime": "2020-07-30T16:40:00Z",
  "end_datetime": "2020-07-30T17:10:00Z",
  "duration": 30,
  "location": "Track 1",
  "id": "QHRQVF",
  "title": "Advanced Metaprogramming Tools",
  "text": "Advanced Metaprogramming Tools Julia provides an intimidating array of ways to write programs that write programs. There are macros, generated functions, custom compiler passes, ASTs, IRs, DSLs and backends galore. This talk is a deep-dive into all of these tools that will hopefully clarify how and when you'd want to use them, with examples from advanced projects across the Julia ecosystem. This talk will try to clarify the relationship between Julia's many metaprogramming tools, showing how you should (and shouldn't) use Julia's metaprogramming to create DSLs, build program transformations like differentiation, SPMD or batching, or apply domain-specific optimisations in areas like differential equations or probabilistic programming. We'll also clarify the relationship Julia's tools have to advanced programming tools from other language communities, like staged programming and algebraic effect handlers.",
  "url": "/talk/QHRQVF",
  "index": 148,
  "speaker": "Mike Innes"
 },
 {
  "start_datetime": "2020-07-30T16:40:00Z",
  "end_datetime": "2020-07-30T17:10:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "JYNERU",
  "title": "Dispatching Design Patterns",
  "text": "Dispatching Design Patterns This talk covers common patterns that have emerged in Julia using multiple dispatch and generic types to create code that is flexible, robust and performs well. A topic which frequently comes up in discussions of Julia is how to solve complex problems without class-based object orientation. We will look at how objects and interfaces are designed in Julia using modules, structs, multiple dispatch and abstract types. We’ll look at how to use generics for more open-ended polymorphism that doesn’t sacrifice performance and how to use the trait pattern to define extensible, overlapping categories of types. We’ll also mention a few anti-patterns that come up in Julia, such as the infamous “type piracy”.\r\n\r\nWe’ll also look at how multiple dispatch can be used as a simple form of pattern matching, similar algebraic data types in functional languages, and how this is useful for traversing recursive data structures like the abstract syntax trees one deals with when writing macros.\r\n\r\nThis talk is for programmers who may be experienced with other languages but are new to Julia and want to see how we design software using Julia’s unique feature set.",
  "url": "/talk/JYNERU",
  "index": 149,
  "speaker": "Aaron Christianson"
 },
 {
  "start_datetime": "2020-07-30T16:20:00Z",
  "end_datetime": "2020-07-30T16:30:00Z",
  "duration": 10,
  "location": "Track 3",
  "id": "DTLBM9",
  "title": "Highly productive Julia web development with Genie 1.0",
  "text": "Highly productive Julia web development with Genie 1.0 A quick tour de force of Genie's most important features, now packed into the stable, mature, performant, and resilient v1 API. The attendees will discover how Genie can help them to productively build and deploy powerful web applications with Julia. With over 800 stars on GitHub and consistently ranking as one of the top 10 most starred Julia packages, Genie is a testament of Julia's great potential as a language for the web. After 5 years in development, over 900 commits and 50 releases, Genie reaches the v1 milestone as a mature, stable, performant, and feature-rich Julia web development framework. \r\n\r\nThe talk will touch upon Genie's most important features, providing a starting point for Julia developers interested in the development of web applications. We will go over features like the HTML templating language, JSON rendering capabilities, input handling, caching, built-in Docker integration, the plugins ecosystem (Genie Authentication and Genie Autoreload), and the built-in deployment adapters for the major hosting platforms. \r\n\r\nWe will close by providing links to Genie resources and documentation so that the interested attendees can dive deeper.",
  "url": "/talk/DTLBM9",
  "index": 150,
  "speaker": "Adrian Salceanu"
 },
 {
  "start_datetime": "2020-07-30T13:30:00Z",
  "end_datetime": "2020-07-30T14:00:00Z",
  "duration": 30,
  "location": "Track 3",
  "id": "38UTLX",
  "title": "Rapid Commercialization of Drone Autonomy using Julia",
  "text": "Rapid Commercialization of Drone Autonomy using Julia In robotics, the two language problem is potentially even more pronounced than in other fields of scientific computing. KEF Robotics is using Julia to tackle this challenge and rapidly develop, field test, and commercialize autonomy software for small multirotor drones. There is currently a very large gap from new robotics research to commercial products. The two language problem contributes to this gap, where research and prototyping often occurs in MATLAB or Python and then field testing and commercialization requires porting to C or C++. The development speed, runtime speed, and scientific computing capabilities of Julia offer a promising solution to this challenge.\r\n\r\nKEF Robotics is developing an attachable autonomy subsystem for small aerial vehicles, allowing us to add navigation, hazard avoidance, and machine learning capabilities to any drone, all with just cameras (no GPS required). Our hazard detection and avoidance module has been developed, tested, fielded, and is now being transitioned into a commercial product, all in Julia. This module combines widely varying components, including image processing, geometric computer vision, splines, and nonlinear optimization, making it a perfect showcase for Julia's unique strength in composability and scientific computing.\r\n\r\nAnother key challenge in robotics is predictable real-time performance, often on embedded computing. These factors are typically not associated with garbage-collected scripting languages. While Julia's tooling and runtime are not perfect for the task, options for allocation management, profiling, and package compilation allow prototype code to be ported to these applications, all in the same language. Also, Julia native CUDA programming is of particular utility for NVIDIA's Jetson products, which are prevalent in robotics research and commercialization.",
  "url": "/talk/38UTLX",
  "index": 151,
  "speaker": "Kerry Snyder"
 },
 {
  "start_datetime": "2020-07-29T12:30:00Z",
  "end_datetime": "2020-07-29T13:00:00Z",
  "duration": 30,
  "location": "Track 2",
  "id": "WGAHCK",
  "title": "When compiler technology meets Market Risk Management",
  "text": "When compiler technology meets Market Risk Management This talk will show a Julia based solution that can automatically create a price function and map the risk factors of a given Financial Contract defined in a domain-specific language. This project applies compiler algorithms to take advantage of context in the pricing formulas so that it is possible to handle big portfolios with a wide variety of financial contracts. This talk tackles the main issue regarding the development of solutions for market risk management: given a financial contract, one must know how to price it, but it is also required to understand how the pricing formula reacts to changes in the market prices.\r\n\r\nThis project was heavily inspired by Julia Computing's [Miletus.jl](https://github.com/JuliaComputing/Miletus.jl), but goes one step further: given a financial contract, it is now possible to automatically map its risk factors. A general solution is based on [ForwardDiff.jl](https://github.com/JuliaDiff/ForwardDiff.jl). Alternative methods can be included in the system by making use of Julia's multiple-dispatch.\r\n\r\nCompiler algorithms were used on top of Julia's [JIT compiler](https://en.wikipedia.org/wiki/Just-in-time_compilation) to generate pricing formulas. Using a customized [IR](https://en.wikipedia.org/wiki/Intermediate_representation) defined in [OptimizingIR.jl](https://github.com/felipenoris/OptimizingIR.jl) it is possible to represent a pricing function that would require a billion nodes on an [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree) with just a few thousand instructions in the optimized IR. With this setting, this solution provides:\r\n\r\n* Scalability: compile millions of pricing functions without breaking Julia.\r\n\r\n* Automated Auditing: automatically generate documentation on how the calculation is performed, as often required by market regulators and auditing firms.\r\n\r\n* Cashflow projection: given that functions are not restricted to return a single number, it is possible to compile pricing functions that also return intermediate results.\r\n\r\n* Take advantage of context: compile a whole portfolio to a single pricing function, and all repeated intermediate steps in the calculation are done only once, without losing detail on pricing results for each contract in the portfolio.",
  "url": "/talk/WGAHCK",
  "index": 152,
  "speaker": "Felipe Noronha Tavares, Lucas Processi"
 }
]
