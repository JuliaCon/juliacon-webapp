[
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "33HMQB",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": null,
    "name": "Michael Kyesswa",
    "code": "ZCE33M",
    "biography": "Michael Kyesswa is a scientific researcher at Karlsruhe Institute of Technology. His main areas of research are modelling, simulation and analysis of power systems, parallel and real-time simulations, and computational methods for power system analysis"
   }
  ],
  "description": "Computational simulations are important in the design, operation and analysis of power systems in order to ensure a secure and stable operation of power grids. The current power system operating environment, however, shows several transformations in the grid structure as a result of increasing operation of large interconnected networks, an increase in electricity demand from e.g. electric vehicles and heat pumps, and the increasing integration of renewable energy sources in the energy transition context. These changes directly impose additional requirements to the stability analysis process, whereby the time-domain simulations widely used for dynamic stability studies are faced with an increase in computational burden due to the increasing complexity of the system under analysis. In order to address the complexity in the analysis of large networks, parallel and distributed computing techniques are frequently applied to improve the computational speed by taking advantage of multi-core processors and cluster computing.\r\n\r\nThis talk presents an extension in a Julia-based parallel simulation algorithm to address the need for improved computation methods in power system stability analysis. The algorithm achieves an improvement in computational speedup by reformulating an inherently sequential numerical solution to a parallel approach using a parallel-in-space decomposition scheme and the Julia computing environment. The talk will focus on the parallelization approach applied to restructure the numerical formulation in order to solve the resulting power system differential and algebraic equations in parallel. The basis of the parallelization is a parallel-in-space decomposition to partition the network into independent subnetworks and the equations of the subnetworks are assigned to different processors. The in-space decomposition uses the branch splitting Multi-Area Thevenin Equivalent (MATE) algorithm to divide the network coefficient matrix into submatrices that can be solved in parallel. \r\n\r\nThe talk will describe the multi-level graph partitioning technique which is used to achieve optimal balancing of tasks in the parallel solution process. The partitions are extended to the dynamic simulation problem to obtain balanced subnetworks that are solved in parallel and only linked via a link subsystem. Furthermore, simulation results will be presented to highlight the difference between the original parallel approach based on the node-splitting Block Bordered Diagonal Formulation (BBDF) and the improved extension of the algorithm based on the branch-splitting MATE algorithm.",
  "image": null,
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T09:55:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:25:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Parallel Power System Dynamics Simulation toolbox in Julia",
  "abstract": "This talk presents performance improvements in a parallel time-domain simulation toolbox under development in Julia for executing simulations of power system dynamics. The algorithm applies a branch splitting parallel-in-space decomposition scheme to create parallelizable subnetworks in the network solution of the power system analysis problem. The performance of the improved algorithm is evaluated on a supercomputing cluster and shows enhanced computation speedup in complex networks."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "A7883T",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": null,
    "name": "Jeffrey Varner",
    "code": "QLXKQ8",
    "biography": "Jeff Varner holds a Ph.D. in Engineering from Purdue University. He spent 18 years as a Professor at the Smith School of Chemical Engineering at Cornell University"
   }
  ],
  "description": "Finance and economic forecasting, modeling, and decision-making are typically not part of a traditional engineering or physical science curriculum. However, many engineers and scientists are migrating toward employment opportunities in the financial and consulting industries. Further, despite increased market access, there remains a significant barrier to entry for many individuals in our society to the wealth-creation opportunities offered by markets. Toward these unmet needs, we developed the [CHEME 5660 Financial Data, Markets, and Mayhem course](https://varnerlab.github.io/CHEME-5660-Markets-Mayhem-Book/infrastructure.html) in collaboration with [Polygon.io](https://polygon.io/), a leading financial market data provider. The class, which introduced financial systems, markets, and the tools to analyze and model financial data to engineers and scientists at Cornell University, had an initial enrollment of 60 students from CHEM, Physics/AEP, Engineering Management, CS/ORIE, CBE, BME, CEE, ECE, AEP, and the Johnson Business School. The course content was delivered via a combination of lectures and guided computational sessions enabled by Pluto and Jupyter notebooks. All course materials are open source, including notes, examples, and labs. \r\n\r\n[CHEME 5660](https://varnerlab.github.io/CHEME-5660-Markets-Mayhem-Book/infrastructure.html) catalyzed the development of multiple Julia packages to support the course's educational goals. For example, [PQPolygonSDK.jl](https://github.com/Paliquant/PQPolygonSDK.jl.git) and [PQEcolaPoint.jl](https://github.com/Paliquant/PQEcolaPoint.jl) were developed to support the class. The [PQPolygonSDK.jl](https://github.com/Paliquant/PQPolygonSDK.jl.git) package is a software development kit for the [Polygon.io](https://polygon.io) financial data platform. [Polygon.io](https://polygon.io) provides real-time and historical data for various assets. A vital component of the success of [CHEME 5660](https://varnerlab.github.io/CHEME-5660-Markets-Mayhem-Book/infrastructure.html) was access to high-quality data sets supplied by [Polygon.io](https://polygon.io). This data allowed us to study the statistical properties of financial data and other topics, such as modeling and analysis tools for describing and ultimately predicting asset pricing dynamics and issues such as portfolio management and hedging. Further, we used tools from artificial intelligence, such as Markov Decision Processes (MDPs) and model-based and model-free reinforcement learning to study optimal decision-making, dynamic hedging, and trade management using actual data sets (including minute-resolution data). Thus, data provided by [Polygon.io](https://polygon.io) through the [PQPolygonSDK.jl](https://github.com/Paliquant/PQPolygonSDK.jl.git) package enabled Cornell students to learn and explore quantitative finance topics with actual data, which was a critical and differentiating feature of the course. Additionally, the [PQEcolaPoint.jl](https://github.com/Paliquant/PQEcolaPoint.jl) package was developed to study the pricing and trade mechanics of equity derivative products, i.e., options, a central topic in the course. Options are a huge market in the United States; the average daily notional value of traded single-stock options rose to more than $450 billion in 2021, compared with about $405 billion for stocks, according to Cboe Global Markets data (2021). To put these values in perspective, the annual global biopharmaceuticals market was valued at USD 401.32 billion in 2021. Thus, in a single day, the options market in the United States trades more than the entire annual global biopharmaceutical market.\r\n\r\nMoving forward, several new packages will be developed to support the course. In particular, we are working on a new portfolio management package that will initially be focused on implementing traditional approaches, such as the data-driven and model-driven Markowitz problem. In addition, we are working on dynamic hedging and high-frequency trading packages that will take advantage of real-time data from [Polygon.io](https://polygon.io/). These packages will support new content in the course in market making, i.e., how leading liquidity providers such as [Citadel Securities](https://www.citadelsecurities.com/) drive efficient markets. \r\n\r\nFinally, we’ll share lessons learned from students in the course, students with no computational background, and students whose primary language was not Julia. Accessible and reliable notebook technologies enabled these students' broad adoption of Julia. However, there was significant resistance in some cases because of the well-known “time to first plot” issue and general configuration headaches, especially on Windows. This was especially true in cases where heavy computation, e.g., Monte-Carlo price simulations or extensive portfolio optimization calculations, were attempted on various student machines.",
  "image": "https://pretalx.com/media/juliacon2023/submissions/A7883T/CHEME-5660-Course-Sell-Sheet-F22_r64CURo.svg",
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T10:50:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T11:20:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Teaching Quantitative Finance to Engineers using Julia",
  "abstract": "There is a compelling opportunity for scientists and engineers to leverage their proficiency in mathematics combined with artificial intelligence and data science tools to drive value creation within businesses and ultimately democratize wealth through quantitive finance approaches. Toward this opportunity, this poster describes a course piloted at the Smith School of Chemical Engineering at Cornell University during Spring 2022 to teach quantitative finance to engineers and scientists in Julia."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "ADLCE8",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/Caira_headshot_spring_2022_axjo7sB.jpg",
    "name": "Caira Anderson",
    "code": "A9RU3G",
    "biography": "I am an applied mathematics graduate student and GEM Fellow. I currently work as a research assistant at the Princeton Plasma Physics Laboratory (PPPL). I am interested in the areas of dynamical systems, numerical analysis, and scientific computing. I am particularly drawn to applications in the areas of environmental sustainability and medicine. In Summer 2021, I interned at PPPL and developed a code using the automatic differentiation packages in Julia to optimize the design of stellarator (a nuclear fusion device) coils. I recently completed the framework of a code in Julia to solve a linear eigenvalue problem for the evaluation of the global stability of a given 3D plasma equilibrium in stellarator geometry."
   }
  ],
  "description": "A stellarator is a nuclear fusion device that uses external non-axisymmetric coils to generate and twist a magnetic field to contain plasma particles. Stable stellarator equilibria are necessary for sustained fusion energy production, but stability evaluation is challenging because of the geometric complexity of stellarators. Ideal Magnetohydrodynamics (MHD) is a model which assumes that the plasma is a perfectly conducting fluid in an electromagnetic field. Linear ideal MHD stability describes the global behavior of the plasma. The linear ideal MHD stability problem can be expressed as a generalized eigenvalue problem involving the ideal MHD force operator.\r\nFor strongly shaped 3D configurations such as stellarators, this problem must be solved numerically. By developing a new numerical tool in Julia for evaluating global (linear) ideal MHD stability in stellarator geometry, we make a vital contribution to the process of optimizing stellarator configurations for fusion energy.",
  "image": "https://pretalx.com/media/juliacon2023/submissions/ADLCE8/Caira_Anderson_JuliaCon_poster_Osu1LfM.jpg",
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T10:55:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T11:25:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Progress on a solver for ideal MHD stability in stellarators",
  "abstract": "In this work, we present progress towards the development of a new code written in the Julia programming language for evaluating global (linear) ideal MHD stability in stellarator geometry. We demonstrate the code’s efficiency and robustness which is achieved through leveraging methods provided by high-performance mathematical libraries from the Julia community, such as Krylov subspace methods. Efficient evaluation of linear ideal MHD stability is crucial for stellarator optimization."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3588,
  "submission_type_id": 2490,
  "code": "AZLD3E",
  "track": {
   "en": "SciML"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": null,
    "name": "Facundo Sapienza",
    "code": "H99MDX",
    "biography": "PhD Student at UC Berkeley interested in Machine Learning and Physics. Previously studied Physics and Mathematics at the University of Buenos Aires."
   }
  ],
  "description": "Global glacier models attempt to simulate different glacier processes, in order to model the evolution and response to climate change of all 200,000 glaciers on Earth. Calibrating the model parameters with noisy and sparse observations coming mostly from satellite data is a very challenging task. Traditionally, this calibration is usually made at a regional or even global level, or sometimes for each glacier individually if enough data is available. However, no global information is used to derive general laws governing the spatiotemporal variability of those parameters. With the increase of remote sensing derived datasets with a global coverage, new opportunities arise to discover empirical laws describing physical processes of climate-glacier interactions. The main reasons why this is technically difficult to achieve are twofold: (1) the computational cost of modelling massive glacier datasets and solving the differential equations that describe their dynamics; and (2) the statistical challenge of making constrained parameter or functional inversions from real satellite observations covering glaciers in widely diverse climates and topographies. Scientific Machine Learning is a modelling framework that can address both limitations. \r\n\r\nWe introduce ODINN.jl, an open-source model for global glacier modelling making use of tools from the Scientific Machine Learning Julia ecosystem. ODINN uses Universal Differential Equations (UDEs) to learn subparts of a differential equation governing glacier ice flow. The full code is differentiable using Zygote.jl, which allows gradient-based optimization for the parameters of the neural network embedded inside the differential equation. ODINN exploits the latest generation of glacier ice surface velocities and geodetic mass balance remote sensing products, as well as many preprocessing tools from the Open Global Glacier Model (OGGM) in Python. The retrieval and preprocessing of these datasets is done in ODINN using PyCall.jl to run Python code from OGGM. \r\n\r\nWe showcase the implementation of a 2D Shallow Ice Approximation for glacier ice dynamics (mathematically equivalent to a 2D heat equation with spatio-temporally dependent diffusivity coefficient) and a temperature-index mass balance model per glacier (i.e. the source). We then show how the model successfully infers parameters of ice rheology based on prescribed synthetic laws. This simple example illustrates the first steps of a new global glacier modelling framework in Julia that allows the estimation of global empirical laws for the physical parameters. Furthermore, the lessons learned on implementing UDEs for stiff nonlinear diffusivity PDEs are applicable to other domains, particularly in Earth sciences where the input data consists of gridded remote sensing products. To conclude, we also discuss some of the main challenges and limitations of the current SciML suite in terms of implementing UDEs for 2D physical processes using real observations.\r\n\r\nWork in collaboration with Jordi Bolibar, Redouane Lguensat, Bert Wouters and Fernando Pérez.",
  "image": "https://pretalx.com/media/juliacon2023/submissions/AZLD3E/ODINN_logo_dtp29qR.png",
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T11:00:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T11:30:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Modeling Glacier Ice Flow with Universal Differential Equations",
  "abstract": "We introduce ODINN.jl, an open-source package that uses Universal Differential Equations to model and discover physical processes of climate-glacier interactions. We show how ODINN incorporates tools from the SciML ecosystem (differential equation solvers, automatic differentiation) to recover prescribed laws inside the differential equation describing glacier ice flow, paving the way for functional inversions of empirical laws governing glacier physical processes at a global scale."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3758,
  "submission_type_id": 2490,
  "code": "DCEGGJ",
  "track": {
   "en": "Julia Base and Tooling"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/jf-work_7Ydxgmb.jpg",
    "name": "Jean-François BAFFIER (azzaare@github)",
    "code": "LZTBFS",
    "biography": "Researcher at *Internet Initiative Japan* (IIJ) research lab, specialized in Optimization, Networks, Data Structures, and Algorithms."
   }
  ],
  "description": "This poster presents an early version of *PerfChecker.jl*, a set of tools made to check the performance of packages over time and versions. Although the general workflow of this package is designed, we expect several changes to take place before a stable release.\r\n\r\nCurrently, we invite the users to use it as follows:\r\n\r\n- Prepare a set of instructions to be evaluated for package **P**\r\n  - Separate instructions for allocations and benchmarks are possible\r\n- For each versions of **P** to be checked *do*\r\n  - Checkout the targeted version of **P**\r\n  - Load *PerfChecker* and *P*\r\n  - Execute the checks\r\n  - Leave the current Julia session (if in REPL)\r\n- Launch a new REPL and compile the checks of all the different versions\r\n\r\nAn example of this workflow is given on the README at https://github.com/JuliaConstraints/PerfChecker.jl\r\n\r\nThe final goal of *PerfChecker.jl* is to have a behavior similar to *Test.jl*. Contributions are more than welcome.",
  "image": "https://pretalx.com/media/juliacon2023/submissions/DCEGGJ/benchmark-evolutions_qV46n83.png",
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T10:05:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:35:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "PerfChecker.jl: tools for performance checking over versions",
  "abstract": "*PerfChecker.jl* is an early version of a set of tools I made to check the performance of the packages in JuliaConstraints over time and versions.\r\n\r\nThe user provides a set of instructions to run in the same vein as Test.jl that can be used for allocation checks and benchmarks. Finally, the results are plotted in function of the versions.\r\n\r\nAn example of the pipeline is available at https://github.com/JuliaConstraints/PerfChecker.jl"
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "DQ9BDU",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/me_crop_eRmmC5s.jpg",
    "name": "Tamás Cserteg",
    "code": "SXBVXD",
    "biography": "I am Tamás Cserteg mechatronical engineer and PhD student at SZTAKI (Institute for Computer Science and Control), Hungary. Most of my time is spent with developing robotic solutions for our industrial partners and research projects. I like to use Julia for every kind of stuff including my research and personal projects as well."
   }
  ],
  "description": "In a drilling application, CNC code is built up from two sections: positions of hole features relative to a workpiece local coordinate frame called part zero, and the coordinates of those part zeros in the workspace of the machining center. Usually, there are different part zeros for different feature groups (e.g., one for each side of the part). For quality control reasons, feature coordinates should not be changed, while part zeros can be modified if there is a good reason for it.\r\n\r\nOne such reason can be the small geometrical deviation between the different lots of cast blanks; using the old CNC code for a new lot may result in tool breakage or producing scrap. To ensure that no time, energy and material is wasted by finding appropriate part zeros with the good old trial-and-error method, an automated optimization-based method is needed.\r\n\r\nOn every new lot, one cast blank is measured with a 3D scanner, and important geometrical features are exported. Rough feature (on the cast blank) and machined feature (CNC code) positions can be compared to ensure that every surface that needs to be machined will be eventually machined. An appropriate machining allowance, i.e., distance between a rough and corresponding machined feature can ensure this. Other aspects that need to be considered are the dimensional tolerances between machined features. Tolerances between features in the same feature group are ensured by the CNC code, while inter-operation tolerances must be overseen when setting the different part zeros.\r\n\r\nWith a proper optimization model, the allowance criteria as well as tolerance requirements can be balanced and optimal part zeros can be computed.\r\n\r\nThis poster showcases how this complex engineering problem can be programmed and solved in Julia. Input geometrical data can be read from files or queried from a database. The JuMP ecosystem is used to implement and solve the optimization problem, and Makie to visualize and interpret the results.\r\n\r\n---\r\n\r\nThe description of this methodology is currently under publication and will be available as an Open Access paper. The implementation is available here: https://github.com/cserteGT3/BlankLocalizationCore.jl",
  "image": "https://pretalx.com/media/juliacon2023/submissions/DQ9BDU/julia-in-machining-poster_w3TYqp3.png",
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T10:00:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:30:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Julia in machining: optimizing drilling positions",
  "abstract": "In the machining of cast blank parts, small geometrical deviations between different lots of blanks can cause serious issues. These differences need to be compensated to 1) make sure that every feature on the blank is properly machined and 2) dimensional tolerances between features are respected. This poster shows via a case study in drilling that Julia is a great tool for solving this problem, including the steps of data processing, optimization, and visualization."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3755,
  "submission_type_id": 2490,
  "code": "ELRURU",
  "track": {
   "en": "Julia Community"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/WhatsApp_Image_2022-01-31_at_10.04.41_HlDmmpo.jpeg",
    "name": "Letícia Madureira",
    "code": "U3WPAA",
    "biography": "I am a first year PhD student at Carnegie Mellon University. I am a Computational Chemist working with Quantum Chemistry and Software Engineering. Some of my goals as a researcher are: exploring chemical space, developing new open source tools for scientists and make this world better and more inclusive for everyone!"
   }
  ],
  "description": "I have an Youtube channel with tutorials about Julia Language, in this poster, I would like to share best practices on creating new videos, the statistics comparing views and likes between Shorts and Long videos (since we are in the Tik Tok era and short videos are taking the attention more), and present how Julia can help to connect people in multiple environments. Sharing experiences and following the changes of the world with Julia is the purpose of having a world conference. The YouTube channel also helped to share Julia Language in Brazil and some other Latin American countries, spreading the power of programming computers to economical minorities and unfavored groups.",
  "image": null,
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T10:00:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:30:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Sharing Julia with the world",
  "abstract": "Julia is a 21st century programming language, and one of the advantages of this is to create a healthy and diverse community and share our experiences and issues and the internet."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "F89ZLV",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/JuliaCon2023_YyZflGM.jpeg",
    "name": "Óscar Alvarado",
    "code": "ZZTWND",
    "biography": "Physicist by day, Data Scientist by night. I like programming, electronics and building Legos."
   }
  ],
  "description": "Julia's community has grown rapidly in recent years, however, it is important to remember what a privilege it is to be able to use these new technologies. For this reason, by expanding the use of Julia to low-cost computers that are easy to transport, it opens the possibilities of who can use and learn about Julia, especially in rural areas or areas with difficult access to technology.\r\nIt is common for museums or science fairs to show interactive projects so that the non-science community has a more realistic approach and not just what is seen in books. This is why we believe that the interaction of Julia and reality could be a great opportunity in terms of education and the dissemination of science and technology.\r\n\r\nIn this project, a package is developed to be able to use the GPIO and camera ports included in the Jetson Nano, from the NVIDIA company.\r\nJulia's interaction with the Jetson Nano's GPIO ports is shown in a variety of ways, including the use of LEDs, buttons, the camera module, and a variety of sensors.\r\nThis small-sized computer was chosen because it includes a graphics card, with which you can interact very easily with Julia, and thus expand the scope of projects carried out.",
  "image": null,
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T09:30:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:00:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Interacting with reality: Julia and Jetson Nano.",
  "abstract": "In this work, the first steps for the creation of a Julia package for the interaction with the GPIO and camera ports of a Jetson Nano are presented.\r\nThe input and output modes of the GPIO ports are addressed, while the problem of reading data using PWM is discussed.\r\nIn addition, interaction with the camera module for the Jetson Nano using the Julia interface is shown."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "GP9DMT",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/Screen_Shot_2022-12-15_at_8.27.09_PM_kBHytkl.png",
    "name": "Will Thompson and Alex Friedrichsen",
    "code": "EVUYHZ",
    "biography": "We are graduate students in complex systems science at the University of Vermont. Our interests include cool data science projects and having fun with epistemology."
   },
   {
    "avatar": "https://pretalx.com/media/avatars/roundSmilingSuit_lgYhqEZ.png",
    "name": "Alex Friedrichsen",
    "code": "M8C8BA",
    "biography": "Alex Friedrichsen is a Master's student in the Complex Systems Center of the University of Vermont studying Data Science and Complex Systems. I graduated with my bachelor's degree in Data Science in the spring of 2022 through the Honors College at UVM while taking accelerated master's classes. I am currently doing research in multiple labs here at UVM including most recently the Social-Ecological Gaming and Simulation (SEGS) lab.\r\n\r\nSome of my interests include game theory, music, agent-based models, evolutionary computation, philosophy of mind and chaos theory! I enjoy both technical and holistic learning experiences. I am a huge proponent of habits and routine to promote daily flexiblity through self-automation. I love to read about self-improvement, behavioral economics, theory versus action, and fantasy! I try to optimize and strategize everything.\r\n\r\nCurrently open to work."
   }
  ],
  "description": "As climate change continues to worsen, natural disasters such as floods, storms, and earthquakes are becoming more frequent and destructive. These disasters often destroy or damage critical infrastructure such as hospitals, schools, and shelters, reducing access to essential services for affected populations. To address this problem, our project focuses on evolving facility placements that are robust to disasters, using evolutionary algorithms and highly optimized tolerance (HOT) as a mechanism for design. We show that our evolved facility layouts are more robust to natural disasters than empirical layouts, providing a potential solution to the challenges posed by climate change and other disasters. Our work also highlights the utility of the Julia programming language in scientific computing and specifically in evolutionary computation.\r\n\r\nOur work draws on two bodies of literature, the p-median problem and highly optimized tolerance (HOT). We formulate the p-median problem as follows: given N facilities and a heterogeneous population distribution across an area, find the optimal placement of facilities that minimizes the average distance to the nearest facility. No exact analytical solution exists, but approximate solutions show that the optimal facility density should scale as the population density to the 2/3rds power.\r\nWe implement an evolutionary algorithm as a metaheuristic solution to the p-median problem. We compare its performance to other metaheuristics found in the literature such as simulated annealing, and show that evolutionary algorithms converge to near-optimal facility locations and follow the analytically predicted 2/3 scaling relationship.\r\nThe second body of literature revolves around HOT, a mechanism through which engineered systems become robust to a pattern of perturbations through design. Previous work by Carlson, Doyle, and Zhou applied evolutionary algorithms to a percolation lattice model to demonstrate how complexity and robustness can arise in biological contexts.\r\nWe extend this work by applying evolutionary algorithms to evolve robust facility locations. We introduce perturbations in the form of catastrophes with locations drawn from a distribution over event locations. All facilities within a specified radius of the catastrophe are eliminated. These catastrophes mimic natural disasters, targeted attacks, or random failures. A robust facility layout minimizes the drop in fitness due to catastrophes. We evolve our facility layout with perturbations. Every generation we apply a set amount of catastrophes to each individual within our population before we evaluate the fitness. We show that the facility layouts evolved with perturbations are more robust than layouts evolved without perturbations. The average decrease in fitness due to a catastrophe is lower in facility layouts evolved with perturbations. We also show that evolutionary algorithms are a viable alternative to simulated annealing in the rugged landscape induced by the stochastic nature of the perturbations. We compare evolution to empirical data and show that our evolved facility layouts are more robust to natural disasters than empirical layouts. This work has the potential to improve the resilience of critical infrastructure to climate change. \r\nWe wrote our own evolutionary framework for this project that allows for the introduction of perturbations to the genome during evolution. While evolutionary computation packages exist in Julia, to our knowledge none allow for perturbation during the evolutionary process. This is a contribution to the community because the framework is general and extensible and could be applied to a diverse array of other problems.\r\nOur project makes novel use of Julia's ecosystem of geospatial packages in its application to evolutionary algorithms. The speed of the Julia language is essential. Our algorithm involves tens of thousands of nearest-neighbor assessments for each individual every generation. This computation is prohibitively slow in Python. By leveraging static arrays and Julia's ample multiprocessing capabilities, we were able to make our code several orders of magnitude faster than its Python equivalent. Julia allowed us to implement a full-scale version of our evolutionary algorithm even though relatively little computational power was available to us. As such, our project is a demonstration of the incredible utility of the Julia programming language in scientific computing and specifically in evolutionary computation.",
  "image": "https://pretalx.com/media/juliacon2023/submissions/GP9DMT/Screen_Shot_2022-12-15_at_8.17.59_PM_1fLmdP0.png",
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T09:30:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:00:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "Evolving Robust Facility Placements",
  "abstract": "Climate change is leading to an increase in natural disasters, such as floods and earthquakes, which can damage critical infrastructure like hospitals and schools. To address this problem, we propose a project that uses evolutionary algorithms to design facility placements that are robust to disaster. By using evolutioanary algorthims as a metaheursitc solution to the p-median problem, we are show that our approach leads to facility layouts that are more robust to natural disasters."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3759,
  "submission_type_id": 2490,
  "code": "LC9AZE",
  "track": {
   "en": "Finance and Economics"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/screen-recording-2023-01-04-at-101505-pm-sctfoqer-jfyrnowu_8ba2zyEE_XRbJIX3.gif",
    "name": "1m1",
    "code": "T8KWMT",
    "biography": "cyborg, technologist, mathematician, philosopher, artist\r\n\r\nlover of julia since v0.3\r\n\r\nbeen coding and doing math 30+ years\r\n\r\nmore at https://1m1.io"
   }
  ],
  "description": "We are going to minimize portfolio risk after applying the following 3 simplifications:\r\n\r\n• consider only 2nd moments (simplification 1)\r\n• homogenize variances (simplification 2)\r\n• algebraically reduce dimension (simplification 3)\r\n\r\nWe assume that we have chosen a list of 𝑛 assets that we want to invest into. Us\r\nchoosing these assets implies that we believe that each of these assets has a long\r\nterm positive return.\r\n\r\nThe above simplifications allow us to analytically derive a formula for the weights of each asset.",
  "image": null,
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T10:00:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:30:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "FairPortfolio ~ simple and stable portfolio optimization",
  "abstract": "Removing sources of large errors in financial data leads to an analytical solution for portfolio optimization that is more stable and performant than several tested alternatives"
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "LUVDCY",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": null,
    "name": "erussell@rff.org",
    "code": "MT3RHA",
    "biography": null
   }
  ],
  "description": "At the heart of E4ST is a detailed engineering representation of the power grid, and an optimization problem that represents the decisions of the system operators, electricity end-users, generators, and generation developers. The model represents these operation, consumption, investment, and retirement decisions by minimizing the sum of generator variable costs, fixed costs, investment costs, and end-user consumer surplus losses. E4ST provides detailed analysis to better inform policymakers, investors, and stakeholders.\r\nThe power sector is increasingly complex, with challenging emission reduction aspirations, new energy technologies, an ever-changing policy backdrop, growing demand, and much uncertainty. Some of the challenges of representing the sector include:\r\n* Regional and national markets for clean electricity credits\r\n* Diverse generation mixes with temporal variations\r\n* Markets for various fuel types and captured CO2\r\n* increasing energy storage requirements\r\n\r\nTo provide relevant analysis for such a complex and dynamic sector, models must to be fast to adapt and use. The previous version of E4ST was written as a wrapper for MATPOWER, a powerful Matlab-language package for solving steady-state power system simulation and optimization problems. However, as powerful as MATPOWER is, we desired the additional flexibility and speed that Julia can provide.\r\n\r\nOur team is in the process of writing E4ST.jl with maximum flexibility and speed in mind. E4ST.jl is a bring-your-own-solver JuMP-based package. We leverage clever interfaces to inject custom modifications into the data loading, model setup, and results processing steps to allow for extreme configurability and extensibility. We allow for flexible time representations and time-varying inputs with space-and-time-efficient data retrieval.\r\n\r\nE4ST.jl uses the speed and extensibility of Julia to enable faster deployment of detailed and adaptable models to inform policy decision-makers and technology developers.",
  "image": "https://pretalx.com/media/juliacon2023/submissions/LUVDCY/E4STLogo_eD8g3Sb.png",
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T10:30:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T11:00:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "E4ST.jl: Policy & Investment Analysis for the Electric Sector",
  "abstract": "The Engineering, Economic, and Environmental Simulation Tool (E4ST) is a detailed power sector model from Resources for the Future for comprehensive cost-benefit analysis of policies and investments in the electricity sector. Originally written in MATLAB on top of MATPOWER, E4ST.jl is the Julia rewrite of the model, using JuMP, and Julia’s multiple dispatch programming paradigm to allow users to specify novel climate policies, introduce new technologies, and change spatial/temporal resolution."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3760,
  "submission_type_id": 2490,
  "code": "QLUH7A",
  "track": {
   "en": "Biology and Medicine"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": null,
    "name": "Fareeda Abdelazeez",
    "code": "NLGXM7",
    "biography": null
   }
  ],
  "description": "Working with the OMOP CDM (Observational Medical Outcomes Partnership Common Data Model) involves handling large datasets that require a set of tools for extracting the necessary data efficiently. The first part of the project focuses on improving JuliaHealth's infrastructure by increasing the range of tools available to users. This involves enabling connections to various databases, and working with observational health data. Our second goal is to leverage the capacity built in the previous phase to develop a comprehensive framework for patient-level prediction. This framework will predict patient cohort outcomes with given treatments and will be tested on mimic data, and potentially on real aggregated and anonymized patient data.",
  "image": null,
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T09:30:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:00:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "JuliaHealth's Tools for Patient-Level Predictions: Strengthening",
  "abstract": "Working with OMOP CDM involves managing large datasets, requiring efficient data extraction tools. To enhance JuliaHealth's infrastructure, we'll expand tools and enable diverse database connections. This aids in developing a patient-level prediction framework for cohort outcomes, tested on mimic and real patient data. The poster is influenced by a Google Summer of Code project, sharing aspects of this journey."
 },
 {
  "content_locale": "en",
  "is_featured": true,
  "track_id": 3245,
  "submission_type_id": 2490,
  "code": "THCJ7H",
  "track": {
   "en": "JuliaCon"
  },
  "state": "confirmed",
  "duration": 30,
  "speakers": [
   {
    "avatar": "https://pretalx.com/media/avatars/propic_91xz2cD.JPG",
    "name": "Evan Gorstein",
    "code": "QTFLUJ",
    "biography": "Evan Gorstein is a 3rd year PhD student in the Department of Statistics at the University of Wisconsin-Madison."
   }
  ],
  "description": "I present on a package currently under development at http://www.github.com/solislemuslab/HighDimMixedModels.jl for fitting high dimensional mixed effect regression models. The original motivation for this package and the mixed-effect sparse learning models it will support comes from the field of microbiology. Microbial communities are among the driving forces of biogeochemical processes, and standard approaches to studying the connection between microbial communities and these biogeochemical phenomena rely on the use of abundance matrices to represent the microbial compositions as the design matrix in a regression or machine learning analysis. \r\n\r\nThese types of regressions present two major challenges. First, there is often inter-sample correlation structure due to a grouping of samples in space—in soil studies, for example, samples may come from one of several different locations—or time. These inter-sample correlation structures lead to under-powered statistical estimators as well as incorrect inferences if not properly accounted for. Secondly, in these models, the number of microbial taxa present across the range of samples to be included in the analysis, which equals the number of regression coefficients to be estimated, is quite high.\r\n\r\nThere are existing Julia packages to deal with each of these problems individually. High dimensional estimation with well-studied guarantees can be done using the Lasso, which has been implemented efficiently in the package Lasso.jl. On the other hand, MixedModels.jl is a popular package for fitting mixed effect models in Julia. The proposed package under development will deal with models that exhibit both at once: that is, they both incorporate random effects and also have a high dimensional vector of fixed effect. In particular, I am implementing the proposed estimator from Schelldorfer et al. (2011), which uses a coordinate-gradient-descent algorithm. The proposed package will be called HighDimMixedModels.jl, and it translates the R package lmmlasso built by Schelldorfer, which was subsequently removed from CRAN. My hope is that by harnessing the speed of Julia, my implementation of Schelldorfer’s model and algorithm will allow researchers in biology to fit high dimensional, mixed-effect regression models more efficiently. The software will be accompanied by step-by-step tutorials and examples similar to the ones found found in the MixedModels.jl documentation.\r\n\r\nWhile at first glance, the intersection of hierarchical/grouped sampling structure with high dimensional feature space might seem like a niche, highly-specialized setting, it may actually be a common occurrence in biology in the age of -omics data. While the impetus for the development of this package is regression analysis for microbial data, the hope is that this package will be useful to researchers working with other types of data, including metagenomic data, metatranscriptomic data, or even continuous measurements like metabolites, methylation or gene expression. For an example of this last category, the model was successfully applied in [1] to a gene expression data matrix in order to identify which genes are most relevant for the production of riboflavin (vitamin B) in the bacterium Bacillus subtillis.\r\n\r\nIn my poster, I will explain how to use my package, its high level API and its implementation details. I will also explain the details of the underlying statistical theory. I hope that by introducing my package at JuliaCon, it can be useful to the many bioinformatics researchers who attend the conference.\r\n\r\nReferences:\r\n\r\n [1] SCHELLDORFER, J., BÜHLMANN, P., & VAN DE GEER, S. (2011). Estimation for High-Dimensional Linear Mixed-Effects Models Using ℓ1-Penalization. Scandinavian Journal of Statistics, 38(2), 197–214. http://www.jstor.org/stable/23015490",
  "image": null,
  "slot_count": 1,
  "slot": {
   "room_id": 2231,
   "start": "2023-07-26T09:30:00-04:00",
   "room": {
    "en": "Online talks and posters"
   },
   "end": "2023-07-26T10:00:00-04:00"
  },
  "submission_type": {
   "en": "Poster"
  },
  "resources": [],
  "do_not_record": false,
  "title": "HighDimMixedModels.jl",
  "abstract": "I present on a package under development, HighDimMixedModels.jl, for fitting high dimensional mixed effect regression models. The motivation comes from analysis of microbial datasets, but the model is well-suited to many settings across bioinformatics. In my poster, I explain the usage of the package as well as the underlying statistical theory."
 }
]
